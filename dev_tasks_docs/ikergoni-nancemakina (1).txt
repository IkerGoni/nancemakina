Directory structure:
└── ikergoni-nancemakina/
    ├── README.md
    ├── Dockerfile
    ├── Project Status Update - May 12 2025 18_02.md
    ├── requirements.txt
    ├── run.sh
    ├── status_update.md
    ├── todo.md
    ├── backtest_results/
    ├── config/
    │   └── config.yaml.example
    ├── dev_tasks_docs/
    │   ├── dev_plan_step_005.md
    │   ├── dev_plan_step_006.md
    │   ├── dev_plan_step_007.md
    │   ├── dev_plan_step_008.md
    │   ├── dev_plan_step_009.md
    │   ├── dev_plan_step_010.md
    │   ├── dev_plan_step_013.md
    │   └── ikergoni-nancemakina.txt
    ├── docs/
    │   ├── ARCHITECTURE.md
    │   ├── CONFIGURATION_GUIDE.md
    │   └── TROUBLESHOOTING.md
    ├── scripts/
    │   ├── __init__.py
    │   └── backtest.py
    ├── src/
    │   ├── __init__.py
    │   ├── config_loader.py
    │   ├── connectors.py
    │   ├── data_processor.py
    │   ├── main.py
    │   ├── models.py
    │   ├── monitoring.py
    │   ├── order_manager.py
    │   ├── position_manager.py
    │   ├── signal_engine copy.py
    │   ├── signal_engine.py
    │   └── utils.py
    ├── tests/
    │   ├── __init__.py
    │   ├── e2e/
    │   │   └── __init__.py
    │   ├── integration/
    │   │   ├── __init__.py
    │   │   └── test_main_flow.py
    │   └── unit/
    │       ├── __init__.py
    │       ├── test_config_loader.py
    │       ├── test_connectors.py
    │       ├── test_data_processor.py
    │       ├── test_models.py
    │       ├── test_monitoring.py
    │       ├── test_order_manager.py
    │       ├── test_position_manager.py
    │       └── test_signal_engine.py
    └── .cursor/
        └── rules/
            └── projectrules.mdc

================================================
FILE: README.md
================================================
# Binance Futures Trading Bot

A robust, configurable trading bot for Binance Futures markets (USDT-M and COIN-M) with a focus on reliability, configurability, and extensibility.

## Features

- **Multi-Market Support**: Trade on both USDT-M and COIN-M Binance Futures markets
- **Configurable Strategy**: SMA crossover strategy (21 SMA crossing 200 SMA) with configurable parameters
- **Real-time Data Processing**: WebSocket connections for live market data
- **Risk Management**: Configurable position sizing, stop-loss, and take-profit
- **Monitoring**: Prometheus metrics for monitoring bot performance and health
- **Hot-reload Configuration**: Update trading parameters without restarting the bot
- **Extensible Architecture**: Modular design for easy addition of new strategies and features

## Installation

### Prerequisites

- Python 3.8+
- Binance Futures account with API keys
- (Optional) Docker for containerized deployment

### Setup

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/binance-futures-bot.git
   cd binance-futures-bot
   ```

2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

3. Create configuration file:
   ```bash
   cp config/config.yaml.example config/config.yaml
   ```

4. Edit the configuration file with your Binance API keys and trading preferences:
   ```bash
   nano config/config.yaml
   ```

## Configuration

The bot is configured through the `config/config.yaml` file. See [Configuration Guide](docs/CONFIGURATION_GUIDE.md) for detailed options.

Basic configuration example:

```yaml
api:
  binance_api_key: "YOUR_BINANCE_API_KEY"
  binance_api_secret: "YOUR_BINANCE_API_SECRET"

global_settings:
  v1_strategy:
    sma_short_period: 21
    sma_long_period: 200
    min_signal_interval_minutes: 60
    tp_sl_ratio: 2.0
    default_margin_usdt: 50.0
    default_leverage: 10
    margin_mode: "ISOLATED"
    indicator_timeframes: ["1m", "5m", "15m", "1h", "4h"]

pairs:
  BTC_USDT:
    enabled: true
    contract_type: "USDT_M"
    leverage: 5
    margin_usdt: 100.0
  ETH_USDT:
    enabled: true
    contract_type: "USDT_M"
  BTCUSD_PERP:
    enabled: false
    contract_type: "COIN_M"
    margin_coin: 0.001

logging:
  level: "INFO"
  file: "logs/bot.log"

monitoring:
  prometheus_port: 8000
```

## Running the Bot

### Standard Mode

Run the bot with:

```bash
python -m src.main
```

### Development Mode

For development with hot-reloading of code changes:

```bash
python -m src.main --dev
```

### Docker

Build and run with Docker:

```bash
docker build -t binance-futures-bot .
docker run -v $(pwd)/config:/app/config -v $(pwd)/logs:/app/logs binance-futures-bot
```

## Monitoring

The bot exposes Prometheus metrics on port 8000 (configurable). You can use Grafana or other Prometheus-compatible tools to visualize these metrics.

Default metrics endpoint: `http://localhost:8000/metrics`

## Architecture

The bot follows a modular architecture with clear separation of concerns. See [Architecture Overview](docs/ARCHITECTURE.md) for details on the system design.

Key components:
- **Config Manager**: Handles configuration loading and hot-reloading
- **WebSocket Connector**: Manages real-time data streams from Binance
- **REST Client**: Handles API calls for account data and order execution
- **Data Processor**: Processes market data and calculates indicators
- **Signal Engine**: Generates trade signals based on strategy rules
- **Order Manager**: Executes trades with proper position sizing
- **Position Manager**: Tracks open positions and their status

## Testing

Run the test suite with:

```bash
pytest
```

For specific test categories:

```bash
pytest tests/unit/  # Unit tests only
pytest tests/integration/  # Integration tests only
```

## Troubleshooting

See [Troubleshooting Guide](docs/TROUBLESHOOTING.md) for common issues and solutions.

## Disclaimer

This software is for educational purposes only. Use at your own risk. The authors are not responsible for any financial losses incurred from using this software. Always test thoroughly on testnet before using with real funds.

## License

MIT License



================================================
FILE: Dockerfile
================================================



================================================
FILE: Project Status Update - May 12 2025 18_02.md
================================================
# Project Status Update - May 12 2025 18:02

**Current Phase:** Pre-Testnet Validation - Codebase Cleanup and Packaging

**Overall Progress:**
- All core modules for the Binance Futures Trading Bot MVP (V1 Strategy) have been developed.
- Initial unit tests have been created for most modules.
- Documentation structure is in place (README, Configuration Guide, Architecture, Troubleshooting).
- The codebase has undergone several rounds of cleanup to remove non-production code, fix syntax errors, and ensure Pydantic V2 compatibility for data models.

**Last Completed Steps:**
- Refactored enum-like classes in `src/models.py` to use Python's `Enum` for Pydantic V2 compatibility.
- Thoroughly scanned and cleaned all Python modules (`src/connectors.py`, `src/data_processor.py`, `src/signal_engine.py`, etc.) to remove leftover test/example code, fix improper line continuations, and resolve syntax errors.

**Current State of `todo.md`:**
- Most development steps for Phase 1 (MVP) are marked as complete or in the final stages of cleanup/testing.
- The next major step after your review will be "Step 018: Validate end-to-end functionality on Testnet."

**Files Included in this Archive (`binance_bot_snapshot_20250512_1802.zip`):**
- The entire `/home/ubuntu/binance_futures_bot` project directory, containing all source code, configuration examples, tests, and documentation.
- `/home/ubuntu/todo.md` (current task checklist).
- This `status_update.md` file.

**Next Steps (Pending Your Review):**
1.  **User Review:** You review the provided codebase and status.
2.  **Testnet Validation:** Proceed with running the bot on the Binance Testnet to validate end-to-end functionality, including:
    - WebSocket connections and data reception.
    - Kline processing and indicator calculation.
    - Signal generation based on the V1 SMA crossover strategy.
    - Order placement, management, and position tracking (simulated if live testnet keys are not immediately available/configured by the user).
    - Logging and basic monitoring.
3.  **Bug Fixing:** Address any issues identified during Testnet validation.
4.  **Final Packaging:** Prepare the final functional application for delivery.

**Notes:**
- The `config/config.yaml` is currently set up with placeholder API keys for Testnet. You will need to replace `YOUR_TESTNET_API_KEY` and `YOUR_TESTNET_API_SECRET` with your actual Binance Testnet API keys to perform live trading tests on the Testnet.
- The bot is designed to be run using `python3.11 -m src.main` from the `/home/ubuntu/binance_futures_bot` directory after installing dependencies from `requirements.txt`.

We are now pausing development to await your review of the current project state. Please let us know if you have any questions or feedback before we proceed to the Testnet validation phase.



================================================
FILE: requirements.txt
================================================
aiodns==3.4.0
aiohappyeyeballs==2.6.1
aiohttp==3.10.11
aiosignal==1.3.2
annotated-types==0.7.0
APScheduler==3.11.0
attrs==25.3.0
ccxt==4.4.80
certifi==2025.4.26
cffi==1.17.1
charset-normalizer==3.4.2
contourpy==1.3.2
cryptography==44.0.3
cycler==0.12.1
fonttools==4.58.0
frozenlist==1.6.0
idna==3.10
iniconfig==2.1.0
kiwisolver==1.4.8
matplotlib==3.10.3
multidict==6.4.3
numpy==2.2.5
packaging==25.0
pandas==2.2.3
pillow==11.2.1
pluggy==1.5.0
prometheus_client==0.21.1
propcache==0.3.1
pycares==4.8.0
pycparser==2.22
pydantic==2.11.4
pydantic_core==2.33.2
pyparsing==3.2.3
pytest==8.3.5
pytest-asyncio==0.26.0
python-dateutil==2.9.0.post0
python-dotenv==1.1.0
pytz==2025.2
PyYAML==6.0.2
requests==2.32.3
setuptools==80.4.0
six==1.17.0
tenacity==9.1.2
typing-inspection==0.4.0
typing_extensions==4.13.2
tzdata==2025.2
tzlocal==5.3.1
urllib3==2.4.0
watchdog==6.0.0
websockets==15.0.1
yarl==1.20.0



================================================
FILE: run.sh
================================================



================================================
FILE: status_update.md
================================================
# Project Status Update - May 12 2025 18:02

**Current Phase:** Pre-Testnet Validation - Codebase Cleanup and Packaging

**Overall Progress:**
- All core modules for the Binance Futures Trading Bot MVP (V1 Strategy) have been developed.
- Initial unit tests have been created for most modules.
- Documentation structure is in place (README, Configuration Guide, Architecture, Troubleshooting).
- The codebase has undergone several rounds of cleanup to remove non-production code, fix syntax errors, and ensure Pydantic V2 compatibility for data models.

**Last Completed Steps:**
- Refactored enum-like classes in `src/models.py` to use Python's `Enum` for Pydantic V2 compatibility.
- Thoroughly scanned and cleaned all Python modules (`src/connectors.py`, `src/data_processor.py`, `src/signal_engine.py`, etc.) to remove leftover test/example code, fix improper line continuations, and resolve syntax errors.

**Current State of `todo.md`:**
- Most development steps for Phase 1 (MVP) are marked as complete or in the final stages of cleanup/testing.
- The next major step after your review will be "Step 018: Validate end-to-end functionality on Testnet."

**Files Included in this Archive (`binance_bot_snapshot_20250512_1802.zip`):**
- The entire `/home/ubuntu/binance_futures_bot` project directory, containing all source code, configuration examples, tests, and documentation.
- `/home/ubuntu/todo.md` (current task checklist).
- This `status_update.md` file.

**Next Steps (Pending Your Review):**
1.  **User Review:** You review the provided codebase and status.
2.  **Testnet Validation:** Proceed with running the bot on the Binance Testnet to validate end-to-end functionality, including:
    - WebSocket connections and data reception.
    - Kline processing and indicator calculation.
    - Signal generation based on the V1 SMA crossover strategy.
    - Order placement, management, and position tracking (simulated if live testnet keys are not immediately available/configured by the user).
    - Logging and basic monitoring.
3.  **Bug Fixing:** Address any issues identified during Testnet validation.
4.  **Final Packaging:** Prepare the final functional application for delivery.

**Notes:**
- The `config/config.yaml` is currently set up with placeholder API keys for Testnet. You will need to replace `YOUR_TESTNET_API_KEY` and `YOUR_TESTNET_API_SECRET` with your actual Binance Testnet API keys to perform live trading tests on the Testnet.
- The bot is designed to be run using `python3.11 -m src.main` from the `/home/ubuntu/binance_futures_bot` directory after installing dependencies from `requirements.txt`.

We are now pausing development to await your review of the current project state. Please let us know if you have any questions or feedback before we proceed to the Testnet validation phase.



================================================
FILE: todo.md
================================================
# Binance Futures Trading Bot - Development Checklist

## Phase 1: Core Infrastructure & MVP (V1 Strategy)

- [ ] **Step 001: Initialize Project Repository and Directory Structure**
    - [x] Create main project directory `binance_futures_bot`.
    - [x] Create subdirectories: `.github/workflows`, `config`, `data`, `docs`, `src`, `tests/unit`, `tests/integration`, `tests/e2e`.
    - [x] Create initial empty files: `src/__init__.py`, `src/main.py`, `src/config_loader.py`, `src/connectors.py`, `src/data_processor.py`, `src/signal_engine.py`, `src/order_manager.py`, `src/position_manager.py`, `src/models.py`, `src/utils.py`, `src/monitoring.py`, `tests/__init__.py`, `tests/unit/__init__.py`, `tests/integration/__init__.py`, `tests/e2e/__init__.py`, `Dockerfile`, `README.md`, `.gitignore`, `run.sh`, `config/config.yaml.example`, `docs/ARCHITECTURE.md`, `docs/CONFIGURATION_GUIDE.md`, `.github/workflows/ci.yml`.
    - [x] Create initial `requirements.txt` with basic dependencies.
    - [x] Create initial `.gitignore`.
- [x] **Step 002: Implement Core Configuration Management Module (`src/config_loader.py`)**
    - [x] Define `config.yaml` structure (API keys, global V1 params, pair-specific settings, logging, monitoring).
    - [x] Implement `ConfigManager` class: load, validate, provide access to configuration.
    - [x] Implement hot-reloading of `config.yaml` using `watchdog`.
    - [x] Add unit tests for `ConfigManager`.
- [x] **Step 003: Implement Data Models (`src/models.py`)**
    - [x] Define Pydantic or dataclass models for `Kline`, `TradeSignal`, `Order`, `Position`, `PairConfig`.
    - [x] Add unit tests for data models.
- [x] **Step 004: Develop Binance WebSocket and REST Connectors (`src/connectors.py`)**
    - [x] Implement `BinanceWebSocketConnector`: connect, subscribe (1m, 5m, 15m, 1h, 4h), handle messages, reconnect logic for USDⓈ-M and COIN-M.
    - [x] Implement `BinanceRESTClient` (using `ccxt`): fetch exchange info, balance, place/cancel orders, fetch open orders/positions, set margin/leverage for USDⓈ-M and COIN-M.
    - [x] Add unit tests for connectors (mocking external calls)- [x] **Step 005: Implement Data Processing and Indicator Calculation (`src/data_processor.py`)**
    - [x] Receive k-line data from WebSocket.
    - [x] Store k-lines in buffers (per pair, per timeframe).
    - [x] Calculate SMAs (21, 200) for all configured timeframes (1m, 5m, 15m, 1h, 4h) using `pandas`.
    - [ ] Add unit tests for data processing and SMA calculation.dd unit tests for data processing and SMA calculation.
- [x] **Step 006: Develop Signal Engine V1 (`src/signal_engine.py`)**
    - [x] Implement `SignalEngineV1` class.
    - [x] Detect 1-minute SMA crossovers (21/200).
    - [x] Implement significance filter (configurable buffer time).
    - [x] Calculate SL (recent pivot lows/highs) and TP (fixed R:R ratio).
    - [x] Output `TradeSignal` object.
    - [ ] Add unit tests for V1 signal logic, SL/TP calculation.
- [x] **Step 007: Implement Order Manager (`src/order_manager.py`)**
    - [x] Receive `TradeSignal`.
    - [x] Set margin type and leverage.
    - [x] Implement position sizing (MVP: fixed margin allocation).
    - [x] Place MARKET entry, STOP_MARKET SL, TAKE_PROFIT_MARKET TP orders (with `reduceOnly=true`).
    - [x] Handle USDⓈ-M and COIN-M specifics.
    - [ ] Add unit tests for order manager logic (mocking API calls).
- [x] **Step 008: Implement Basic Position Manager (`src/position_manager.py`)**
    - [x] Track open positions (symbol, side, entry, size, SL/TP order IDs).
    - [x] Update status based on order fills/cancellations.
    - [ ] Add unit tests for position manager.- [x] **Step 009: Build Main Application Logic and Orchestration (`src/main.py`)**
    - [x] Initialize and orchestrate all modules.
    - [x] Manage data flow: WebSocket -> DataProcessor -> SignalEngine -> OrderManager.
    - [x] Handle startup, shutdown, config hot-reloads..
    - [ ] Implement main asynchronous loop.- [x] **Step 010: Add Basic Monitoring (`src/monitoring.py`)**
    - [x] Expose basic Prometheus metrics (uptime, WebSocket status, signals, errors).
    - [ ] Add unit tests for metrics exposure..
- [x] **Step 011: Write Unit and Integration Tests for MVP Scope**
    - [x] Ensure comprehensive unit test coverage for all new modules.
    - [x] Develop integration tests for key data flows (e.g., signal to order) with mocked Binance services- [x] **Step 012: Document Setup, Configuration, and Usage**
    - [x] Update `README.md` with setup, configuration, and running instructions.
    - [x] Create `docs/CONFIGURATION_GUIDE.md` detailing `config.yaml` options.
    - [x] Create `docs/ARCHITECTURE.md` with an overview of the system design.
    - [x] Create `docs/TROUBLESHOOTING.md` for common issues.net**
    - [ ] Configure bot for Binance Futures Testnet.
    - [ ] Run the bot and monitor its behavior for V1 strategy.
    - [ ] Verify signal generation, order placement (entry, SL, TP), and position tracking.
    - [ ] Debug and refine based on Testnet observations.
- [ ] **Step 014: Report and Send Functional App to User**
    - [ ] Package the application (e.g., as a zip archive with instructions or Docker image details).
    - [ ] Provide the functional app and necessary documentation to the user.

## Phase 2: Enhancements, V2 Strategy Foundation & Robustness (Post-MVP)
- [ ] Advanced V1 Filters (Volume, Volatility)
- [ ] Enhanced Risk Management for V1 (Dynamic Position Sizing, Trailing SL)
- [ ] COIN-M Full Support Refinement
- [ ] Signal Engine V2 Foundation (Multi-TF data, EMA cross, StochRSI, ATR SL/TP)
- [ ] Backtesting Framework (Initial)
- [ ] Improved Error Handling & Resilience
- [ ] Expanded Testing

## Phase 3: Full V2 Strategy & Advanced Features (Post-Phase 2)
- [ ] Signal Engine V2 Completion
- [ ] Advanced Filters for V2 (BTC Correlation, Funding Rate)
- [ ] Advanced Risk & Exit Strategies (Adaptive TP, Volatility-Based Leverage, Time-Based/Reversal Exits)
- [ ] Dynamic Pair Selection (Optional)
- [ ] Backtesting Optimization
- [ ] Advanced Monitoring & Alerting

## Phase 4: Deployment & Maintenance (Post-Phase 3)
- [ ] Dockerization (`Dockerfile`, `run.sh`)
- [ ] Deployment Strategy for 24/7 Free Operation
- [ ] CI/CD Pipeline (`.github/workflows/ci.yml`)
- [ ] Comprehensive Documentation Finalization
- [ ] Ongoing Maintenance Plan




================================================
FILE: config/config.yaml.example
================================================
# Binance Futures Trading Bot - Example Configuration
# Copy this file to config.yaml and edit with your settings.

api:
  binance_api_key: "YOUR_BINANCE_API_KEY" # Your Binance API Key (ensure only Futures trading is enabled)
  binance_api_secret: "YOUR_BINANCE_API_SECRET" # Your Binance API Secret
  # For COIN-M, if different keys are needed, this structure might need adjustment or separate sections.
  # For now, assuming same keys for USD-M and COIN-M or that ccxt handles it.

global_settings:
  # V1 Strategy Defaults (SMA Crossover)
  v1_strategy:
    sma_short_period: 21
    sma_long_period: 200
    # Minimum time in minutes between signals for the same pair to reduce noise
    min_signal_interval_minutes: 15
    # Take Profit = Risk * tp_sl_ratio. SL is based on recent support/resistance.
    tp_sl_ratio: 3.0
    # Default margin to use per trade if not specified per pair (for fixed margin allocation)
    default_margin_usdt: 50.0 # For USDT-M pairs
    # default_margin_coin: 0.1 # Example for COIN-M pairs (e.g., 0.1 BTC for BTCUSD_PERP)
    # Default leverage if not specified per pair
    default_leverage: 10
    # Default margin mode: "ISOLATED" or "CROSSED"
    margin_mode: "ISOLATED"
    # Timeframes to calculate SMAs on (e.g., 1m, 5m, 15m, 1h, 4h). V1 uses 1m for signals.
    # The data_processor will calculate for all these, signal_engine_v1 will use 1m.
    indicator_timeframes: ["1m", "5m", "15m", "1h", "4h"]

  # V2 Strategy Defaults (to be detailed in Phase 2/3)
  # v2_strategy:
    # strategy_v2_enabled: false
    # ... other V2 parameters ...

  # General Risk Management (some may be V2 specific or advanced V1)
  risk_management:
    # For dynamic position sizing: risk this percentage of available balance per trade
    dynamic_sizing_risk_percent: 1.0 # e.g., 1% of balance
    # Enable dynamic position sizing (true/false). If false, uses fixed margin from v1_strategy.
    dynamic_sizing_enabled: false
    # volatility_based_leverage_enabled: false # Future enhancement

  # Optional Filters (can be enabled/disabled globally or per pair)
  filters:
    volume_filter_enabled: false
    # volume_avg_period: 50
    # volume_threshold_ratio: 1.5 # Signal candle volume must be 1.5x the average

    volatility_filter_enabled: false # Bollinger Bands width filter
    # bb_period: 20
    # bb_std_dev: 2
    # bb_min_width_percentage: 0.5 # Min BB width as % of price to trade

    # btc_correlation_filter_enabled: false # For altcoins, future enhancement
    # max_funding_rate_threshold: 0.001 # Skip if abs(funding_rate) > 0.1%, future enhancement

  # Exit Strategies (beyond SL/TP, future enhancements)
  # exit_strategies:
    # time_based_exit_enabled: false
    # max_trade_duration_hours: 4
    # reversal_exit_enabled: false

pairs:
  # USD-M Perpetual Contracts (Examples)
  BTC_USDT:
    enabled: true
    # Override global V1 settings if needed
    # sma_short_period: 10
    # margin_mode: "CROSSED"
    # leverage: 20
    # margin_usdt: 100 # Specific margin for this USDT-M pair
    # dynamic_sizing_enabled: true # Override global dynamic sizing
    # risk_percent_per_trade: 0.5 # Override global risk percent

  ETH_USDT:
    enabled: true
    # leverage: 15
    # margin_usdt: 75

  # COIN-M Perpetual Contracts (Examples)
  # Note: For COIN-M, margin is specified in the base currency (e.g., BTC for BTCUSD_PERP)
  # The bot will need to handle this distinction for position sizing and P&L.
  BTCUSD_PERP: # Binance symbol for BTC/USD COIN-M Perpetual
    enabled: false
    # margin_coin: 0.01 # e.g., 0.01 BTC for this pair
    # leverage: 10
    # contract_type: "COIN_M" # Explicitly marking, though symbol format might imply it

  ETHUSD_PERP:
    enabled: false
    # margin_coin: 0.1 # e.g., 0.1 ETH
    # leverage: 10
    # contract_type: "COIN_M"

logging:
  # Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
  level: "INFO"
  # Log file path (optional, if not specified, logs to console and default app.log)
  # log_file: "/path/to/your/custom_app.log"

monitoring:
  prometheus_port: 8000 # Port for Prometheus metrics endpoint

backtesting: # Configuration for backtesting module (future phase)
  initial_balance_usdt: 10000
  fee_percent: 0.04    # 0.04% trading fee (taker)
  slippage_percent: 0.01 # 0.01% slippage
  # start_date: "2023-01-01T00:00:00Z"
  # end_date: "2023-12-31T23:59:59Z"
  # initial_balance_coin: { "BTC": 1, "ETH": 10 } # For COIN-M backtesting




================================================
FILE: dev_tasks_docs/dev_plan_step_005.md
================================================
# Development Plan: Step 005 - Add Unit Tests for `data_processor.py`

**Task:** Step 005 - Add comprehensive unit tests for the `DataProcessor` module (`src/data_processor.py`).

**Objective:** Ensure the `DataProcessor` class correctly initializes based on configuration, processes incoming Kline data, manages internal buffers (deques and DataFrames), calculates SMA indicators accurately, handles edge cases, and responds to configuration updates.

**Target File(s):**
*   `tests/unit/test_data_processor.py` (Primary file to create/modify)

**Context:**
*   `src/data_processor.py` exists with the `DataProcessor` class implementation.
*   It uses `pandas` for DataFrames and indicator calculations (SMA).
*   It uses `collections.deque` for Kline buffering.
*   It registers a callback with `ConfigManager` for hot-reloading.
*   A basic `tests/unit/test_data_processor.py` file exists but needs comprehensive test cases.

**Detailed Plan:**

1.  **Setup Test Fixtures:**
    *   Create a `pytest` fixture (`mock_config_manager_for_dp`) using `unittest.mock.MagicMock` or a helper class to simulate `ConfigManager`. This fixture should provide different mock configurations for various test scenarios (e.g., different enabled pairs, timeframes, SMA periods).
    *   Create a `pytest` fixture (`data_processor`) that initializes `DataProcessor` with the mock config manager. Ensure each test gets a fresh instance.
    *   Use `pytest.mark.asyncio` for all test functions as `process_kline` is async.

2.  **Test Initialization (`__init__` & `_initialize_buffers_from_config`):**
    *   **Test Case:** Verify buffer creation based on `enabled` pairs and `indicator_timeframes` in config.
        *   **Action:** Initialize `DataProcessor` with a mock config having a mix of enabled/disabled pairs and global/specific timeframes.
        *   **Assert:** Check `data_processor._active_pairs_timeframes` dict matches the expected enabled pairs and their associated timeframes. Assert that `data_processor.kline_buffers[symbol][timeframe]` exists and is a `deque` for all active combinations. Assert that buffers for *disabled* pairs are *not* present or are empty. Assert deque `maxlen` is `MAX_KLINE_BUFFER_LENGTH`.
    *   **Test Case:** Verify initialization with empty `pairs` configuration.
        *   **Action:** Initialize `DataProcessor` with a mock config where `pairs` is empty or missing.
        *   **Assert:** `_active_pairs_timeframes`, `kline_buffers`, and `indicator_data` should be empty.

3.  **Test Kline Processing (`process_kline`):**
    *   **Test Case:** Process a single *closed* Kline for an active pair/timeframe.
        *   **Action:** Call `await data_processor.process_kline(kline_closed)` with a sample `Kline` object.
        *   **Assert:** Check the kline is appended to the correct `kline_buffers[symbol][timeframe]` deque. Verify `_update_indicators` was implicitly called (e.g., by checking if `indicator_data` DataFrame is updated).
    *   **Test Case:** Process a single *unclosed* Kline for an active pair/timeframe.
        *   **Action:** Call `await data_processor.process_kline(kline_unclosed)`.
        *   **Assert:** Check the kline is appended. Verify `_update_indicators` might *not* have been called yet (depending on implementation, but typically only runs on closed candles). Check `indicator_data` state.
    *   **Test Case:** Update the last *unclosed* Kline.
        *   **Action:** Process `kline_unclosed_t1`. Process `kline_unclosed_t1_update` (same timestamp, different data).
        *   **Assert:** The deque should still contain only one element, and it should be `kline_unclosed_t1_update`.
    *   **Test Case:** Replace the last *unclosed* Kline with its *closed* version.
        *   **Action:** Process `kline_unclosed_t1`. Process `kline_closed_t1` (same timestamp).
        *   **Assert:** The deque should contain one element (`kline_closed_t1`). Verify `_update_indicators` was called.
    *   **Test Case:** Process Kline for an *inactive* pair/timeframe.
        *   **Action:** Create a Kline for a pair/timeframe *not* enabled in the mock config. Call `process_kline`.
        *   **Assert:** Verify the kline was *not* added to any buffer and `indicator_data` remains unchanged for that symbol/tf.
    *   **Test Case:** Buffer limit enforcement.
        *   **Action:** Process `MAX_KLINE_BUFFER_LENGTH + 5` klines.
        *   **Assert:** The length of the deque should be exactly `MAX_KLINE_BUFFER_LENGTH`. Verify the oldest klines were discarded.

4.  **Test Indicator Calculation (`_update_indicators`):**
    *   **Test Case:** Insufficient data for SMAs.
        *   **Action:** Process fewer klines than `sma_short_period`. Call `_update_indicators` directly (or process a closed kline).
        *   **Assert:** The resulting DataFrame in `indicator_data` should have `sma_short` and `sma_long` columns filled with `pd.NA` or appropriate null values.
    *   **Test Case:** Correct SMA calculation (short period).
        *   **Action:** Process exactly `sma_short_period` klines. Process one more *closed* kline.
        *   **Assert:** Fetch the DataFrame using `get_indicator_dataframe`. Verify the `sma_short` value for the last row matches the manually calculated SMA. `sma_long` should still be NA.
    *   **Test Case:** Correct SMA calculation (long period).
        *   **Action:** Process exactly `sma_long_period` klines. Process one more *closed* kline.
        *   **Assert:** Fetch the DataFrame. Verify both `sma_short` and `sma_long` values for the last row match manually calculated SMAs.
    *   **Test Case:** SMA calculation with duplicate timestamps (ensure last update is used).
        *   **Action:** Process klines including updates with the same timestamp.
        *   **Assert:** Verify the DataFrame used for SMA calculation does not contain duplicate indices and uses the final update for that timestamp. Check SMA correctness.

5.  **Test Getter Methods (`get_latest_kline`, `get_indicator_dataframe`, `get_latest_indicators`):**
    *   **Test Case:** Getters return correct data after processing.
        *   **Action:** Process some klines.
        *   **Assert:** `get_latest_kline` returns the last processed Kline object. `get_indicator_dataframe` returns a DataFrame copy. `get_latest_indicators` returns the last row (Series) of the indicator DataFrame.
    *   **Test Case:** Getters return `None` or empty DataFrame for non-existent symbol/timeframe.
        *   **Action:** Call getters with invalid symbols/timeframes.
        *   **Assert:** Verify `None` or empty `pd.DataFrame` is returned as appropriate.

6.  **Test Configuration Hot-Reload (`_handle_config_update`):**
    *   **Test Case:** Adding a new active pair via config update.
        *   **Action:** Initialize `DataProcessor`. Simulate a config update callback (`_handle_config_update`) with a new config dictionary where a previously disabled pair is now enabled.
        *   **Assert:** Check `_active_pairs_timeframes` now includes the new pair. Verify that corresponding buffers have been created in `kline_buffers` and `indicator_data`.
    *   **Test Case:** Disabling an existing active pair via config update.
        *   **Action:** Initialize `DataProcessor`. Simulate a config update callback disabling an active pair.
        *   **Assert:** Check `_active_pairs_timeframes` no longer includes the disabled pair. (Note: The current implementation might not *remove* old buffers, just stop processing for them. Assert behavior based on implementation).
    *   **Test Case:** Changing `indicator_timeframes` for a pair.
        *   **Action:** Initialize `DataProcessor`. Simulate a config update changing the timeframes list for an active pair.
        *   **Assert:** Check `_active_pairs_timeframes` reflects the new timeframes. Verify necessary buffers exist/are managed.

**Acceptance Criteria:**
*   All test cases described above pass.
*   Test coverage for `src/data_processor.py` is significantly increased.
*   Tests use mocked dependencies (`ConfigManager`) and do not rely on external systems.
*   Tests adhere to PEP 8, use type hints, and follow async patterns correctly.
*   Edge cases like empty data, NA values, and buffer limits are handled.


================================================
FILE: dev_tasks_docs/dev_plan_step_006.md
================================================
# Development Plan: Step 006 - Add Unit Tests for `signal_engine.py`

**Task:** Step 006 - Add comprehensive unit tests for the `SignalEngineV1` module (`src/signal_engine.py`), focusing on V1 signal logic and SL/TP calculation.

**Objective:** Ensure the `SignalEngineV1` class correctly identifies SMA crossover conditions, applies filters (like minimum signal interval), calculates Stop Loss (SL) based on pivot points, calculates Take Profit (TP) based on the configured Risk/Reward ratio, and generates accurate `TradeSignal` objects or `None`.

**Target File(s):**
*   `tests/unit/test_signal_engine.py` (Primary file to create/modify)

**Context:**
*   `src/signal_engine.py` exists with the `SignalEngineV1` class implementation.
*   It depends on `ConfigManager` for strategy parameters (SMA periods, R:R ratio, interval filter) and `DataProcessor` for accessing indicator DataFrames.
*   The V1 strategy involves checking the last two data points for SMA crossover.
*   SL calculation involves finding recent pivot lows/highs from the indicator DataFrame.
*   TP is calculated based on SL distance and R:R ratio.
*   `src/models.py` defines the `TradeSignal` object returned.
*   A basic `tests/unit/test_signal_engine.py` file exists but needs comprehensive test cases.

**Detailed Plan:**

1.  **Setup Test Fixtures:**
    *   Create a `pytest` fixture (`mock_config_manager_for_se`) providing mock configurations, including different SMA periods, R:R ratios, and `min_signal_interval_minutes`.
    *   Create a `pytest` fixture (`mock_data_processor_for_se`) using `unittest.mock.MagicMock`. Mock its `get_indicator_dataframe` method to return controlled `pd.DataFrame` objects for specific test scenarios.
    *   Create a `pytest` fixture (`signal_engine_v1`) that initializes `SignalEngineV1` with the mock config manager and data processor.
    *   Use `pytest.mark.asyncio` for all test functions as `check_signal` is async.
    *   Create helper functions (e.g., `create_mock_df`) within the test file to easily generate DataFrames representing specific market conditions (crossovers, no crossovers, specific pivot points).

2.  **Test Signal Generation Logic (`check_signal`):**
    *   **Test Case:** No signal when data is insufficient.
        *   **Action:** Configure `mock_data_processor_for_se.get_indicator_dataframe` to return `None`, an empty DataFrame, or a DataFrame with only one row. Call `check_signal`.
        *   **Assert:** `check_signal` should return `None`.
    *   **Test Case:** No signal when SMA values are NA.
        *   **Action:** Return a DataFrame where the latest or previous SMA values are `pd.NA`. Call `check_signal`.
        *   **Assert:** `check_signal` should return `None`.
    *   **Test Case:** No signal when no crossover occurs (e.g., SMAs diverging, moving parallel).
        *   **Action:** Return a DataFrame where `sma_short > sma_long` in both the previous and current row. Call `check_signal`.
        *   **Action:** Return a DataFrame where `sma_short < sma_long` in both the previous and current row. Call `check_signal`.
        *   **Assert:** `check_signal` should return `None` in both cases.
    *   **Test Case:** Generate a LONG signal on valid bullish crossover.
        *   **Action:** Return a DataFrame representing `prev: short <= long`, `curr: short > long`. Call `check_signal`.
        *   **Assert:** `check_signal` should return a `TradeSignal` object. Verify `signal.direction == TradeDirection.LONG`. Verify `signal.symbol`, `config_symbol`, `contract_type` are correctly populated. Verify `signal.entry_price` matches the `close` of the last row in the DataFrame.
    *   **Test Case:** Generate a SHORT signal on valid bearish crossover.
        *   **Action:** Return a DataFrame representing `prev: short >= long`, `curr: short < long`. Call `check_signal`.
        *   **Assert:** `check_signal` should return a `TradeSignal` object. Verify `signal.direction == TradeDirection.SHORT`. Verify other fields as above.

3.  **Test SL/TP Calculation:**
    *   **Test Case:** Correct SL calculation for LONG signal (pivot low).
        *   **Action:** Use the LONG signal scenario. Ensure the mock DataFrame provided has identifiable recent low points *before* the signal candle.
        *   **Assert:** Verify `signal.stop_loss_price` matches the expected minimum low from the lookback period defined in `_find_recent_pivot` (e.g., 30 candles before the signal candle by default).
    *   **Test Case:** Correct SL calculation for SHORT signal (pivot high).
        *   **Action:** Use the SHORT signal scenario. Ensure the mock DataFrame has identifiable recent high points *before* the signal candle.
        *   **Assert:** Verify `signal.stop_loss_price` matches the expected maximum high from the lookback period.
    *   **Test Case:** No signal if pivot point cannot be determined (e.g., insufficient historical data in DataFrame).
        *   **Action:** Provide a DataFrame that triggers a crossover but is too short for the pivot lookback.
        *   **Assert:** `check_signal` should return `None` (and log a warning).
    *   **Test Case:** Correct TP calculation based on SL and R:R ratio (LONG).
        *   **Action:** Use the LONG signal scenario. Manually calculate `expected_tp = entry + (entry - sl) * rr_ratio`.
        *   **Assert:** `signal.take_profit_price` should be close to `expected_tp` (allow for float precision).
    *   **Test Case:** Correct TP calculation based on SL and R:R ratio (SHORT).
        *   **Action:** Use the SHORT signal scenario. Manually calculate `expected_tp = entry - (sl - entry) * rr_ratio`.
        *   **Assert:** `signal.take_profit_price` should be close to `expected_tp`.
    *   **Test Case:** No signal if calculated SL results in zero or negative risk (e.g., SL >= entry for LONG, SL <= entry for SHORT).
        *   **Action:** Craft DataFrame data where the calculated pivot leads to invalid risk.
        *   **Assert:** `check_signal` should return `None`.
    *   **Test Case:** Verify `signal.signal_kline` content matches the last row of the input DataFrame.
        *   **Action:** Check the `signal.signal_kline` attribute when a valid signal is generated.
        *   **Assert:** The `Kline` object's fields (`timestamp`, `open`, `high`, `low`, `close`, etc.) match the data from the last row of the DataFrame used for signal generation.

4.  **Test Filters:**
    *   **Test Case:** Minimum signal interval filter prevents rapid signals.
        *   **Action:** Configure mock config with a non-zero `min_signal_interval_minutes` (e.g., 15). Call `check_signal` for a symbol to generate a first signal. Immediately call `check_signal` again for the *same symbol* with data that would otherwise generate a signal.
        *   **Assert:** The first call returns a `TradeSignal`. The second call returns `None`.
    *   **Test Case:** Minimum signal interval filter allows signal after interval passes.
        *   **Action:** Generate the first signal. Manually manipulate `signal_engine_v1.last_signal_time[symbol]` using `time.time()` to simulate the interval having passed. Call `check_signal` again.
        *   **Assert:** The second call should now return a `TradeSignal`.
    *   **Test Case:** Minimum signal interval is pair-specific.
        *   **Action:** Use a config where Pair A has interval > 0, Pair B has interval = 0. Generate signal for Pair A. Immediately generate signal for Pair B.
        *   **Assert:** Signal for Pair A prevents immediate repeat. Signal for Pair B is generated successfully right after.

5.  **Test Helper Methods (Optional but Recommended):**
    *   **Test Case:** Direct test for `_get_pair_specific_config`.
        *   **Action:** Call `_get_pair_specific_config` with different `config_symbol` values.
        *   **Assert:** Verify it correctly merges global and pair-specific settings from the mock config.
    *   **Test Case:** Direct test for `_find_recent_pivot`.
        *   **Action:** Create various DataFrames and call `_find_recent_pivot` directly for LONG and SHORT directions with different lookback values.
        *   **Assert:** Verify it correctly identifies the min low / max high within the specified lookback window (excluding the last row). Test edge cases like flat lines or insufficient data.

**Acceptance Criteria:**
*   All test cases described above pass.
*   Test coverage for `src/signal_engine.py` is significantly increased, covering crossover logic, SL/TP calculation, and filters.
*   Tests use mocked dependencies (`ConfigManager`, `DataProcessor`).
*   Tests accurately simulate different market data scenarios using controlled DataFrames.
*   Generated `TradeSignal` objects contain correct data based on inputs.
*   Edge cases for SL/TP calculation and filters are handled correctly.


================================================
FILE: dev_tasks_docs/dev_plan_step_007.md
================================================
# Development Plan: Step 007 - Add Unit Tests for `order_manager.py`

**Task:** Step 007 - Add comprehensive unit tests for the `OrderManager` module (`src/order_manager.py`).

**Objective:** Ensure the `OrderManager` class correctly receives `TradeSignal` objects, calculates position size based on configuration (fixed margin MVP), fetches and applies exchange filters (precision, min notional), places the correct entry, Stop Loss (SL), and Take Profit (TP) orders via the `BinanceRESTClient`, and handles specifics for USDT-M and COIN-M contracts.

**Target File(s):**
*   `tests/unit/test_order_manager.py` (Primary file to create/modify)

**Context:**
*   `src/order_manager.py` exists with the `OrderManager` class implementation.
*   It depends on `ConfigManager` for parameters (leverage, fixed margin amounts) and `BinanceRESTClient` for executing orders and fetching exchange info.
*   MVP focuses on fixed margin sizing (USDT amount for USDT-M, potentially number of contracts for COIN-M as per current simple implementation).
*   Places MARKET entry, STOP_MARKET SL, and TAKE_PROFIT_MARKET TP orders.
*   Includes logic for adjusting quantity and price to meet exchange precision rules.
*   Includes a basic min_notional value check.
*   A basic `tests/unit/test_order_manager.py` file exists but needs comprehensive test cases.

**Detailed Plan:**

1.  **Setup Test Fixtures:**
    *   Create a `pytest` fixture (`mock_config_manager_for_om`) providing mock configurations, including USDT-M and COIN-M pairs with different leverage and fixed margin settings.
    *   Create a `pytest` fixture (`mock_rest_client_for_om`) using `unittest.mock.AsyncMock`.
        *   Mock `rest_client.fetch_exchange_info` to return realistic market data including `precision` (amount, price) and `limits` (cost/min_notional) for test symbols (e.g., BTCUSDT, ETHUSD_PERP).
        *   Mock `rest_client.create_order` to simulate successful order placement, returning a mock order dictionary with an ID and status. It should also capture the arguments it was called with for verification.
        *   Mock other methods if needed (e.g., `set_leverage`, `set_margin_mode`), although the current `handle_trade_signal` assumes these are pre-set.
    *   Create a `pytest` fixture (`order_manager`) that initializes `OrderManager` with the mock config manager and rest client. Prime the exchange info cache within the fixture using `await order_manager._get_exchange_info_for_symbol(symbol)`.
    *   Use `pytest.mark.asyncio` for all test functions as `handle_trade_signal` and underlying REST calls are async.

2.  **Test Precision and Filter Logic:**
    *   **Test Case:** `_adjust_quantity_to_precision`.
        *   **Action:** Call `order_manager._adjust_quantity_to_precision` directly with various quantities and step sizes (e.g., 0.001, 0.1, 1).
        *   **Assert:** Verify the returned quantity is correctly floored to the specified step size precision.
    *   **Test Case:** `_adjust_price_to_precision`.
        *   **Action:** Call `order_manager._adjust_price_to_precision` directly with various prices and tick sizes (e.g., 0.01, 0.5, 10).
        *   **Assert:** Verify the returned price is correctly rounded to the specified tick size precision.
    *   **Test Case:** `_get_symbol_filters` retrieves correct filters.
        *   **Action:** Call `await order_manager._get_symbol_filters(symbol)`.
        *   **Assert:** Verify it returns the correct tuple `(lot_step_size, price_tick_size, min_notional)` based on the mocked `fetch_exchange_info` data. Test that the cache prevents repeated `fetch_exchange_info` calls.
    *   **Test Case:** `_get_symbol_filters` handles missing filter data gracefully.
        *   **Action:** Mock `fetch_exchange_info` to return data missing certain precision/limits fields. Call `_get_symbol_filters`.
        *   **Assert:** Verify it returns `None` for the missing values and logs appropriate warnings.

3.  **Test Position Sizing (Fixed Margin MVP):**
    *   **Test Case:** Correct quantity calculation for USDT-M pair.
        *   **Action:** Create a `TradeSignal` for a configured USDT-M pair. Call `await order_manager.handle_trade_signal(signal)`.
        *   **Assert:** Manually calculate the expected quantity: `(margin_usdt * leverage) / entry_price`, adjusted to the mocked `lot_step_size`. Verify the `amount` passed to `mock_rest_client.create_order` for the entry order matches this expected quantity.
    *   **Test Case:** Correct quantity calculation for COIN-M pair (MVP assumption: `margin_coin` is number of contracts).
        *   **Action:** Create a `TradeSignal` for a configured COIN-M pair where `margin_coin` is set. Call `await order_manager.handle_trade_signal(signal)`.
        *   **Assert:** Verify the `amount` passed to `create_order` matches the `margin_coin` value from the config, adjusted to the mocked `lot_step_size`. Add a note acknowledging this is a simplification.
    *   **Test Case:** Handling missing margin configuration.
        *   **Action:** Create a signal for a pair where `margin_usdt` (for USDT-M) or `margin_coin` (for COIN-M) is missing in both pair-specific and global config. Call `handle_trade_signal`.
        *   **Assert:** Verify that `create_order` is *not* called and an error is logged.
    *   **Test Case:** Handling zero or invalid entry price.
        *   **Action:** Create a signal with `entry_price=0`. Call `handle_trade_signal`.
        *   **Assert:** Verify `create_order` is not called.

4.  **Test Order Placement Logic:**
    *   **Test Case:** Correct parameters for MARKET entry order (LONG).
        *   **Action:** Handle a LONG `TradeSignal`. Inspect the first call to `mock_rest_client.create_order`.
        *   **Assert:** Verify `symbol`, `order_type=OrderType.MARKET`, `side=OrderSide.BUY`, and calculated `amount` are correct.
    *   **Test Case:** Correct parameters for MARKET entry order (SHORT).
        *   **Action:** Handle a SHORT `TradeSignal`. Inspect the first call.
        *   **Assert:** Verify `symbol`, `order_type=OrderType.MARKET`, `side=OrderSide.SELL`, and calculated `amount` are correct.
    *   **Test Case:** Correct parameters for STOP_MARKET SL order (for LONG entry).
        *   **Action:** Handle a LONG `TradeSignal`. Inspect the second call.
        *   **Assert:** Verify `symbol`, `order_type=OrderType.STOP_MARKET`, `side=OrderSide.SELL`, `amount` (same as entry), `params['stopPrice']` (adjusted SL price), and `params['reduceOnly'] == 'true'`.
    *   **Test Case:** Correct parameters for STOP_MARKET SL order (for SHORT entry).
        *   **Action:** Handle a SHORT `TradeSignal`. Inspect the second call.
        *   **Assert:** Verify `symbol`, `order_type=OrderType.STOP_MARKET`, `side=OrderSide.BUY`, `amount`, `params['stopPrice']` (adjusted SL price), and `params['reduceOnly'] == 'true'`.
    *   **Test Case:** Correct parameters for TAKE_PROFIT_MARKET TP order (for LONG entry).
        *   **Action:** Handle a LONG `TradeSignal`. Inspect the third call.
        *   **Assert:** Verify `symbol`, `order_type=OrderType.TAKE_PROFIT_MARKET`, `side=OrderSide.SELL`, `amount`, `params['stopPrice']` (adjusted TP price), and `params['reduceOnly'] == 'true'`.
    *   **Test Case:** Correct parameters for TAKE_PROFIT_MARKET TP order (for SHORT entry).
        *   **Action:** Handle a SHORT `TradeSignal`. Inspect the third call.
        *   **Assert:** Verify `symbol`, `order_type=OrderType.TAKE_PROFIT_MARKET`, `side=OrderSide.BUY`, `amount`, `params['stopPrice']` (adjusted TP price), and `params['reduceOnly'] == 'true'`.
    *   **Test Case:** Min Notional check prevents order placement.
        *   **Action:** Configure mock exchange info with a `min_notional` value higher than the calculated notional value (`quantity * entry_price` for USDT-M). Handle a relevant `TradeSignal`.
        *   **Assert:** Verify `mock_rest_client.create_order` is *not* called and a warning is logged.
    *   **Test Case:** Calculated quantity is zero or negative.
        *   **Action:** Contrive a scenario (e.g., via precision adjustment or bad input signal) where the final calculated quantity is <= 0. Call `handle_trade_signal`.
        *   **Assert:** Verify `create_order` is not called.

5.  **Test Error Handling:**
    *   **Test Case:** Failure to fetch exchange info.
        *   **Action:** Mock `rest_client.fetch_exchange_info` to return `None` or raise an exception. Clear the cache (`order_manager.exchange_info_cache = {}`) Call `handle_trade_signal`.
        *   **Assert:** Verify `create_order` is not called and an error is logged.
    *   **Test Case:** Entry order placement fails.
        *   **Action:** Mock `rest_client.create_order` for the first call to return `None` or an error response (e.g., `{"status": "REJECTED"}`). Handle a `TradeSignal`.
        *   **Assert:** Verify only the first call to `create_order` is made. Verify subsequent SL/TP orders are *not* placed. Verify an error is logged.
    *   **Test Case:** SL or TP order placement fails.
        *   **Action:** Mock `rest_client.create_order` to succeed for entry but fail for SL (return `None`). Handle a `TradeSignal`.
        *   **Assert:** Verify entry and SL calls are made. Verify TP call is still attempted (or not, depending on desired logic - current code attempts TP even if SL fails). Verify an error is logged regarding the failed SL order.

**Acceptance Criteria:**
*   All test cases described above pass.
*   Test coverage for `src/order_manager.py` is significantly increased, covering sizing, precision adjustment, order parameters, and basic error handling.
*   Tests use mocked dependencies (`ConfigManager`, `BinanceRESTClient`).
*   Order parameters (`symbol`, `type`, `side`, `amount`, `price`, `stopPrice`, `reduceOnly`) are validated for entry, SL, and TP orders in different scenarios.
*   Fixed margin position sizing logic for USDT-M and the simplified COIN-M approach are tested.
*   Precision adjustments and min_notional checks are verified.


================================================
FILE: dev_tasks_docs/dev_plan_step_008.md
================================================
# Development Plan: Step 008 - Add Unit Tests for `position_manager.py`

**Task:** Step 008 - Add comprehensive unit tests for the `PositionManager` module (`src/position_manager.py`).

**Objective:** Ensure the `PositionManager` class correctly tracks open positions (adds, updates, removes), provides accurate status information (`get_position`, `get_all_positions`, `has_open_position`), and updates position state correctly based on simulated order update events. Also, test the basic reconciliation logic.

**Target File(s):**
*   `tests/unit/test_position_manager.py` (Primary file to create/modify)

**Context:**
*   `src/position_manager.py` exists with the `PositionManager` class implementation.
*   It stores `Position` objects (defined in `src/models.py`) in a dictionary keyed by symbol.
*   It uses a `threading.RLock` for basic thread safety.
*   The core logic involves CRUD operations on the internal `_positions` dictionary and updating state based on `Order` objects passed to `update_position_on_order_update`.
*   Includes a `reconcile_positions_with_exchange` method requiring a `BinanceRESTClient` instance.
*   A basic `tests/unit/test_position_manager.py` file exists but needs comprehensive test cases.

**Detailed Plan:**

1.  **Setup Test Fixtures:**
    *   Create a `pytest` fixture (`mock_config_manager_for_pm`) - can be a simple mock as `PositionManager` doesn't heavily rely on config in its current form.
    *   Create a `pytest` fixture (`position_manager`) that initializes `PositionManager` with the mock config manager. Ensure each test gets a fresh instance.
    *   Use `pytest.mark.asyncio` for all test functions as methods like `add_or_update_position` and `update_position_on_order_update` are async.

2.  **Test Basic Position Management:**
    *   **Test Case:** Add a new position.
        *   **Action:** Create a sample `Position` object. Call `await position_manager.add_or_update_position(pos_data)`.
        *   **Assert:** `position_manager.get_position(symbol)` returns the added position object. `position_manager.has_open_position(symbol)` returns `True`. `position_manager.get_all_positions()` returns a list containing the position.
    *   **Test Case:** Update an existing position.
        *   **Action:** Add a position. Create a second `Position` object for the same symbol with modified data (e.g., updated `sl_order_id`, `unrealized_pnl`). Call `add_or_update_position` with the updated data.
        *   **Assert:** `position_manager.get_position(symbol)` returns the *updated* position object. `len(position_manager.get_all_positions())` should remain 1.
    *   **Test Case:** Remove an existing position.
        *   **Action:** Add a position. Call `await position_manager.remove_position(symbol)`.
        *   **Assert:** `position_manager.has_open_position(symbol)` returns `False`. `position_manager.get_position(symbol)` returns `None`. `position_manager.get_all_positions()` is empty.
    *   **Test Case:** Remove a non-existent position.
        *   **Action:** Call `remove_position` for a symbol not in the manager.
        *   **Assert:** No error occurs. State remains unchanged.
    *   **Test Case:** Getters return correct values when empty.
        *   **Action:** Initialize a fresh `PositionManager`.
        *   **Assert:** `get_position(symbol)` returns `None`. `get_all_positions()` returns `[]`. `has_open_position(symbol)` returns `False`.

3.  **Test `update_position_on_order_update` Logic:**
    *   **Test Case:** Entry order FILLED.
        *   **Action:** Add a `Position` with `entry_order_id="E1"`. Create an `Order` object for order "E1" with `status=OrderStatus.FILLED` and a specific `avg_fill_price`. Call `await position_manager.update_position_on_order_update(order)`.
        *   **Assert:** The position should still exist. Verify `position.entry_price` is updated to the `avg_fill_price` from the order. Verify `position.quantity` is updated if `filled_quantity` is present in the order.
    *   **Test Case:** Stop Loss order FILLED.
        *   **Action:** Add a `Position` with `sl_order_id="S1"`. Create an `Order` object for order "S1" with `status=OrderStatus.FILLED`. Call `update_position_on_order_update`.
        *   **Assert:** The position for that symbol should be removed (`get_position` returns `None`).
    *   **Test Case:** Take Profit order FILLED.
        *   **Action:** Add a `Position` with `tp_order_id="T1"`. Create an `Order` object for order "T1" with `status=OrderStatus.FILLED`. Call `update_position_on_order_update`.
        *   **Assert:** The position for that symbol should be removed.
    *   **Test Case:** Entry order CANCELED.
        *   **Action:** Add a `Position` with `entry_order_id="E1"`. Create an `Order` object for order "E1" with `status=OrderStatus.CANCELED`. Call `update_position_on_order_update`.
        *   **Assert:** The position for that symbol should be removed.
    *   **Test Case:** SL order CANCELED.
        *   **Action:** Add a `Position` with `sl_order_id="S1"`. Create an `Order` object for order "S1" with `status=OrderStatus.CANCELED`. Call `update_position_on_order_update`.
        *   **Assert:** The position should still exist, but `position.sl_order_id` should be set to `None`.
    *   **Test Case:** TP order CANCELED.
        *   **Action:** Add a `Position` with `tp_order_id="T1"`. Create an `Order` object for order "T1" with `status=OrderStatus.CANCELED`. Call `update_position_on_order_update`.
        *   **Assert:** The position should still exist, but `position.tp_order_id` should be set to `None`.
    *   **Test Case:** Order REJECTED (e.g., SL order).
        *   **Action:** Add a `Position` with `sl_order_id="S1"`. Create an `Order` object for "S1" with `status=OrderStatus.REJECTED`. Call `update_position_on_order_update`.
        *   **Assert:** Position exists, `position.sl_order_id` is `None`.
    *   **Test Case:** Order update for an unrelated order ID.
        *   **Action:** Add a `Position` with specific order IDs. Create an `Order` object with a different `order_id`. Call `update_position_on_order_update`.
        *   **Assert:** The position state should remain unchanged.
    *   **Test Case:** Order update for a symbol with no tracked position.
        *   **Action:** Ensure no position exists for "XYZUSDT". Create an `Order` for "XYZUSDT". Call `update_position_on_order_update`.
        *   **Assert:** No error occurs, internal state remains unchanged.

4.  **Test `reconcile_positions_with_exchange` Logic:**
    *   **Setup:** Create a mock `rest_client` using `unittest.mock.AsyncMock`. Mock its `fetch_positions` method.
    *   **Test Case:** Sync positions from exchange to empty manager.
        *   **Action:** Mock `fetch_positions` to return a list of position dictionaries (simulating ccxt response). Call `await position_manager.reconcile_positions_with_exchange(mock_rest_client)`.
        *   **Assert:** Verify internal `_positions` dict contains `Position` objects corresponding to the data returned by `fetch_positions`. Check key fields like `symbol`, `side`, `quantity`, `entry_price`.
    *   **Test Case:** Remove stale positions from manager not present on exchange.
        *   **Action:** Add a position manually to the manager (e.g., "STALEUSDT"). Mock `fetch_positions` to return an empty list or a list *without* "STALEUSDT". Call `reconcile_positions_with_exchange`.
        *   **Assert:** Verify the "STALEUSDT" position is removed from the manager.
    *   **Test Case:** Update existing positions in manager based on exchange data.
        *   **Action:** Add a position for "BTCUSDT" to the manager with quantity 0.01. Mock `fetch_positions` to return "BTCUSDT" data with quantity 0.05. Call `reconcile_positions_with_exchange`.
        *   **Assert:** Verify the "BTCUSDT" position in the manager now reflects the data from `fetch_positions` (quantity 0.05).
    *   **Test Case:** Handle exchange position with zero quantity.
        *   **Action:** Add a position for "ETHUSDT". Mock `fetch_positions` to return data for "ETHUSDT" but with quantity/contracts = 0. Call `reconcile_positions_with_exchange`.
        *   **Assert:** Verify the "ETHUSDT" position is removed from the manager.
    *   **Test Case:** Handle errors during `fetch_positions`.
        *   **Action:** Mock `fetch_positions` to return `None` or raise an exception. Call `reconcile_positions_with_exchange`.
        *   **Assert:** Verify internal state is unchanged and an error is logged.

5.  **Test Thread Safety (Conceptual):**
    *   **Test Case:** Verify lock object existence and type.
        *   **Assert:** Check `position_manager._lock` exists and is an instance of `threading.RLock`. (Direct testing of locking behavior is hard in unit tests but verifies setup).

**Acceptance Criteria:**
*   All test cases described above pass.
*   Test coverage for `src/position_manager.py` is significantly increased.
*   Tests verify adding, updating, retrieving, and removing positions.
*   Tests confirm correct state changes based on simulated `Order` updates for various statuses (FILLED, CANCELED, REJECTED).
*   Reconciliation logic correctly syncs internal state with mocked exchange data.
*   Basic thread safety setup is confirmed.


================================================
FILE: dev_tasks_docs/dev_plan_step_009.md
================================================
# Development Plan: Step 009 - Refine Main Application Logic (`main.py`)

**Task:** Step 009 - Review and refine the main application logic and orchestration in `src/main.py`. While the basic structure exists, ensure robustness, proper asynchronous handling, and clear data flow management.

**Objective:** Solidify the main application entry point (`TradingBot` class), ensuring all components are initialized correctly, data flows smoothly between them (especially WebSocket -> DataProcessor -> SignalEngine -> OrderManager), configuration updates are handled appropriately by the main application if needed, and graceful startup/shutdown procedures are robust.

**Target File(s):**
*   `src/main.py` (Primary file to review/modify)

**Context:**
*   `src/main.py` defines the `TradingBot` class orchestrating other modules.
*   It initializes `ConfigManager`, `BinanceRESTClient`, `PositionManager`, `OrderManager`, `DataProcessor`, `BinanceWebSocketConnector`, and `SignalEngineV1`.
*   It defines `_handle_kline_data` as the callback for the WebSocket connector, which processes klines and triggers signal checks.
*   It includes basic startup (`start`) and shutdown (`stop`) logic using `asyncio`.
*   It registers a callback (`_handle_app_config_update`) for config changes.
*   A placeholder `_periodic_tasks` method exists but isn't used in the primary event-driven flow.

**Detailed Plan:**

1.  **Review Initialization (`__init__`):**
    *   **Action:** Verify the order of initialization makes sense (e.g., `ConfigManager` first).
    *   **Action:** Confirm all necessary dependencies are passed correctly between components (e.g., `rest_client` to `OrderManager`).
    *   **Action:** Check if `PositionManager` needs to be passed to `OrderManager` or if position updates should be handled via events/callbacks routed through `main.py`. *Decision: For MVP, keep it simple. Assume `OrderManager` might eventually update `PositionManager`, or rely on `update_position_on_order_update` driven by user data stream later. No immediate changes needed unless a direct link is required now.*
    *   **Action:** Ensure logging is configured early based on the loaded config.

2.  **Review Kline Handling (`_handle_kline_data`):**
    *   **Action:** Verify robust error handling within the callback. What happens if `data_processor.process_kline` or `signal_engine.check_signal` raises an exception? Ensure exceptions are caught and logged without crashing the main loop or the WebSocket connection handler.
        *   *Refinement:* Wrap calls to `process_kline` and `check_signal` / `handle_trade_signal` in `try...except` blocks, logging errors appropriately.
    *   **Action:** Confirm the logic for triggering `signal_engine.check_signal` is correct (e.g., only on closed 1-minute candles for V1).
    *   **Action:** Double-check the mapping from API symbol (e.g., "BTCUSDT") back to the `config_symbol` (e.g., "BTC_USDT") needed for `signal_engine.check_signal`.
    *   **Action:** Re-evaluate the check `if not self.position_manager.has_open_position(kline.symbol):` before calling `check_signal`. Is this sufficient? Should it check the *intended direction* vs. existing position? *Decision: For V1 (no hedge mode), checking if *any* position exists for the symbol is a reasonable simplification to prevent conflicting signals on the same pair.* Keep as is for MVP.
    *   **Action:** Review the flow after a signal is generated and `order_manager.handle_trade_signal` is called. How is the `PositionManager` updated? *Decision: Currently, there's no explicit update call in `main`. This relies on a future User Data Stream integration or manual reconciliation. Add a log message indicating a signal was passed to OrderManager, but position tracking update relies on other mechanisms.*

3.  **Review Startup Logic (`start`):**
    *   **Action:** Ensure `_handle_app_config_update` is called initially to set up active pairs.
    *   **Action:** Review the position reconciliation call. Is it necessary for MVP startup? *Decision: It's good practice. Keep the placeholder call `await self.position_manager.reconcile_positions_with_exchange(self.rest_client)` but ensure `rest_client` is correctly passed. Add logging around it.*
    *   **Action:** Verify WebSocket connector is started (`await self.ws_connector.start()`).
    *   **Action:** Review the main `while self.running: await asyncio.sleep(1)` loop. Is it necessary if all logic is event-driven via `_handle_kline_data`? *Decision: Yes, it keeps the main application alive to receive signals (like SIGTERM) and allows background tasks (like WebSocket handlers) to run. Keep it.*
    *   **Action:** Ensure comprehensive logging during startup phases.

4.  **Review Shutdown Logic (`stop`):**
    *   **Action:** Verify the order of stopping components (e.g., WebSocket connector before REST client, config watcher last).
    *   **Action:** Ensure all awaited stop methods (`ws_connector.stop`, `rest_client.close_exchange`, `config_manager.stop_watcher`) are actually called.
    *   **Action:** Add error handling around the `stop` calls in case a component fails to stop gracefully.
    *   **Action:** Ensure `self.running` flag is set to `False` early in the `stop` sequence.

5.  **Review Asynchronous Loop (`_periodic_tasks`):**
    *   **Action:** This task seems commented out or not actively used in the event-driven flow.
    *   *Decision:* Remove the unused `self.main_loop_task = asyncio.create_task(self._periodic_tasks())` line from `start` and the `_periodic_tasks` method itself if it's not required for the V1 event-driven strategy. This simplifies the main loop. If periodic checks (like reconciliation) are needed *during* runtime, this structure could be revived.

6.  **Review Configuration Handling (`_handle_app_config_update`):**
    *   **Action:** Confirm that changes relevant to `main.py` itself (like logging level, active pairs list) are handled correctly.
    *   **Action:** Ensure changes handled by other modules via their own callbacks (e.g., WebSocket subscriptions, DataProcessor buffers) don't need redundant handling here.

7.  **Review Signal Handling (`handle_sigterm`):**
    *   **Action:** Verify the logic correctly finds the running event loop and schedules the `bot_instance.stop()` coroutine.
    *   **Action:** Test the `loop.run_until_complete(bot_instance.stop())` approach. Does it block the signal handler? Is it safe? *Alternative:* A common pattern is to set `bot_instance.running = False` in the signal handler and let the main `while self.running:` loop break naturally, triggering the `finally` block where `stop()` is called. This is often cleaner.
        *   *Refinement:* Modify `handle_sigterm` to just set `bot_instance.running = False`. Ensure the main `try...finally` block in `main()` calls `await bot_instance.stop()` if `bot_instance` exists. Remove `run_until_complete` from the handler.

**Acceptance Criteria:**
*   `src/main.py` code is reviewed and potentially refactored for clarity and robustness.
*   Error handling in `_handle_kline_data` is implemented.
*   Startup and shutdown sequences are verified and logged clearly.
*   Signal handling (`handle_sigterm`) uses a non-blocking approach by setting the `running` flag.
*   Unnecessary code (like the unused `_periodic_tasks` loop) is removed.
*   Data flow between components within `main.py` is clear and logical.
*   Interaction with `PositionManager` post-signal handling is clarified (acknowledged as dependent on future steps for full automation).


================================================
FILE: dev_tasks_docs/dev_plan_step_010.md
================================================
# Development Plan: Step 010 - Add Unit Tests for `monitoring.py`

**Task:** Step 010 - Add unit tests for the basic Prometheus metrics exposure in `src/monitoring.py`.

**Objective:** Ensure the `PrometheusMonitor` class correctly initializes Prometheus metrics (Counters, Gauges, Enums, Info), updates their values via helper methods, and handles the start/stop logic conceptually (actual server start/stop is hard to unit test cleanly).

**Target File(s):**
*   `tests/unit/test_monitoring.py` (Primary file to create/modify)

**Context:**
*   `src/monitoring.py` defines the `PrometheusMonitor` class using the `prometheus_client` library.
*   It defines various metrics types (Counter, Gauge, Enum, Info).
*   It provides helper methods (e.g., `inc_bot_error`, `set_websocket_status`) to update metric values with labels.
*   The `start` method uses `prometheus_client.start_http_server`.
*   An async task `_update_uptime_periodically` is used for the uptime gauge.
*   Stopping the server relies on process exit as `prometheus_client` doesn't offer a clean stop function.

**Detailed Plan:**

1.  **Setup Test Fixtures:**
    *   Create a `pytest` fixture (`monitor`) that initializes `PrometheusMonitor` with a test port.
    *   Use `pytest.mark.asyncio` as `_update_uptime_periodically` is async.
    *   **Mocking `start_http_server`:** Since we don't want to start a real HTTP server during unit tests, patch `prometheus_client.start_http_server`.
        *   `@patch('src.monitoring.start_http_server')`

2.  **Test Initialization:**
    *   **Test Case:** Verify metric objects are created correctly.
        *   **Action:** Initialize `PrometheusMonitor`.
        *   **Assert:** Check that attributes like `monitor.bot_uptime_seconds`, `monitor.bot_errors_total`, `monitor.websocket_connection_status`, etc., exist and are instances of the correct `prometheus_client` metric types (Gauge, Counter, Enum).

3.  **Test Metric Update Methods:**
    *   **Test Case:** Update Counter metrics (`inc_` methods).
        *   **Action:** Call methods like `monitor.inc_bot_error("moduleA", "type1")`, `monitor.inc_kline_processed("BTCUSDT", "1m")`, etc. Call them multiple times with the same and different labels.
        *   **Assert:** Use `prometheus_client.REGISTRY.get_sample_value` to retrieve the current value of the counter for specific label combinations and verify they increment as expected.
            *   Example: `assert REGISTRY.get_sample_value('trading_bot_errors_total', {'module': 'moduleA', 'error_type': 'type1'}) == 1`
    *   **Test Case:** Update Gauge metrics (`set_` methods).
        *   **Action:** Call methods like `monitor.set_indicator_calculation_duration("ETHUSDT", "5m", 0.123)`, `monitor.set_active_positions_count("USDT_M", 5)`. Call again with different values.
        *   **Assert:** Use `REGISTRY.get_sample_value` to verify the gauge reflects the *last* set value for the given labels.
    *   **Test Case:** Update Enum metrics (`set_websocket_status`).
        *   **Action:** Call `monitor.set_websocket_status("USDT_M", "connected")`, then `monitor.set_websocket_status("USDT_M", "disconnected")`. Call with an invalid state.
        *   **Assert:** Use `REGISTRY.get_sample_value` for the Enum metric. Enums expose multiple gauges (`<metric_name>{<label>=<value>} == 1`). Verify the gauge corresponding to the *last valid state* is 1 and others are 0. Verify that setting an invalid state logs a warning and potentially sets an 'error' state if implemented.
            *   Example: `assert REGISTRY.get_sample_value('trading_bot_websocket_connection_status', {'market_type': 'USDT_M', 'trading_bot_websocket_connection_status': 'disconnected'}) == 1`
            *   `assert REGISTRY.get_sample_value('trading_bot_websocket_connection_status', {'market_type': 'USDT_M', 'trading_bot_websocket_connection_status': 'connected'}) == 0`
    *   **Test Case:** Update Info metric (`bot_info`).
        *   **Action:** Call `monitor.start()` (with `start_http_server` mocked). The `info` metric is set within `start`.
        *   **Assert:** Use `REGISTRY.get_sample_value('trading_bot_info_info')` to check the labels set (version, name).

4.  **Test Start/Stop Logic (Conceptual):**
    *   **Test Case:** `start` calls `start_http_server` and sets info.
        *   **Action:** Call `monitor.start()` with `start_http_server` patched.
        *   **Assert:** Verify the mocked `start_http_server` was called once with the correct port. Verify the `bot_info` metric was populated. Verify `monitor._server_started` is `True`.
    *   **Test Case:** `start` handles `OSError` if server start fails.
        *   **Action:** Configure the patched `start_http_server` to raise `OSError`. Call `monitor.start()`.
        *   **Assert:** Verify an error is logged and `monitor._server_started` remains `False`.
    *   **Test Case:** `_update_uptime_periodically` updates the uptime gauge.
        *   **Action:** Call `monitor.start()`. Wait briefly using `asyncio.sleep`.
        *   **Assert:** Get the value of `trading_bot_uptime_seconds` using `REGISTRY.get_sample_value`. Verify it's a small positive number. Wait again, verify the value increases. (This requires careful handling of the async task lifecycle in tests, potentially mocking `asyncio.create_task` or running the loop briefly). *Alternative:* Test the update logic directly by calling the method once manually.
    *   **Test Case:** `stop` method (conceptual check).
        *   **Action:** Call `monitor.start()`, then `monitor.stop()`.
        *   **Assert:** Verify `monitor._server_started` is set to `False`. Verify a log message indicates shutdown. (Actual server stop cannot be tested here).

5.  **Cleanup:**
    *   **Action:** Ensure Prometheus registry is cleared between tests if necessary, although `get_sample_value` usually works on the current state. Using separate processes or carefully managing the global registry might be needed if tests interfere. For basic unit tests, checking values immediately after setting them should be sufficient. *Consider using `prometheus_client.REGISTRY.clear()` in test setup/teardown if interference occurs.*

**Acceptance Criteria:**
*   All test cases described above pass.
*   Test coverage for `src/monitoring.py` is significantly increased.
*   Tests verify the correct initialization and update of different Prometheus metric types (Counter, Gauge, Enum, Info) via the helper methods.
*   Labels are correctly applied and verified in assertions.
*   Conceptual testing of `start` and `stop` logic confirms expected behavior (mocked server start, flag setting).
*   Tests use mocked dependencies (`start_http_server`).


================================================
FILE: dev_tasks_docs/dev_plan_step_013.md
================================================
# Development Plan: Step 013 - Validate End-to-End Functionality on Testnet

**Task:** Step 013 - Configure and run the bot on the Binance Futures Testnet to validate end-to-end functionality of the V1 Strategy MVP.

**Objective:** Verify that the integrated system works correctly in a simulated live environment, including WebSocket data reception, indicator calculation, signal generation, order placement (Entry, SL, TP), position tracking (manual observation), logging, and basic monitoring. Identify and document any bugs or discrepancies.

**Target File(s):**
*   `config/config.yaml` (To be configured for Testnet)
*   Bot logs (output during Testnet run)
*   (Potentially) `docs/TROUBLESHOOTING.md` (To update with findings)

**Context:**
*   All core modules have initial implementations and unit/integration tests.
*   The bot is designed to run via `python -m src.main`.
*   Configuration is handled via `config/config.yaml`.
*   The bot supports connecting to Testnet via the `api.testnet: true` flag.
*   Requires Binance Futures Testnet API Keys.

**Prerequisites:**
*   User must obtain API Key and Secret from the [Binance Futures Testnet website](https://testnet.binancefuture.com/).
*   Testnet account needs sufficient test funds (usually provided automatically or via a faucet on the Testnet site).

**Detailed Plan:**

1.  **Configure for Testnet:**
    *   **Action:** Copy `config/config.yaml.example` to `config/config.yaml`.
    *   **Action:** Edit `config/config.yaml`:
        *   Enter the obtained **Testnet** API Key and Secret under the `api` section.
        *   Add or set `testnet: true` under the `api` section.
        *   Enable at least one or two **USDT-M perpetual** pairs commonly available on Testnet (e.g., `BTC_USDT`, `ETH_USDT`) under the `pairs` section. Set `enabled: true`.
        *   Configure `leverage` and `margin_usdt` for the chosen pairs to reasonable test values (e.g., 5x leverage, 50 USDT margin). Ensure the margin is small relative to available Testnet funds.
        *   Set `global_settings.v1_strategy.min_signal_interval_minutes` to a low value (e.g., 1 or 5) for faster testing, but be aware this might increase noise.
        *   Set `logging.level` to `INFO` or `DEBUG` for detailed observation.
        *   Ensure `monitoring.prometheus_port` is set if monitoring is desired.
    *   **Action:** Verify Python environment has all dependencies installed from `requirements.txt`.

2.  **Run the Bot:**
    *   **Action:** Open a terminal in the project's root directory.
    *   **Action:** Execute the bot: `python -m src.main`
    *   **Action:** Monitor the console output / log file (`logs/bot.log` if configured) for startup messages, connection status, and errors.

3.  **Monitor Bot Behavior & Verify Functionality:**
    *   **Verification:** **WebSocket Connection & Data:**
        *   Check logs for successful connection messages to the *Testnet* WebSocket endpoints (e.g., `stream.binancefuture.com`).
        *   Check logs for confirmation of subscriptions to the kline streams for the enabled pairs/timeframes (e.g., `btcusdt@kline_1m`).
        *   Observe if kline data appears to be processing (debug logs might show this, or inferred if signals occur).
    *   **Verification:** **Indicator Calculation:**
        *   (Difficult to verify directly without DEBUG logs showing calculated SMAs). Infer correctness if sensible signals are generated based on visible chart patterns on the Testnet trading interface.
    *   **Verification:** **Signal Generation (V1 SMA Crossover):**
        *   Observe the Testnet chart for the enabled pair(s) on the 1-minute timeframe.
        *   Watch for potential SMA 21 / SMA 200 crossovers.
        *   Check bot logs for messages indicating a "Signal generated" (LONG or SHORT) when a crossover appears to occur on the chart. Note the signal details logged (entry, SL, TP).
    *   **Verification:** **Order Placement:**
        *   When a signal is logged, check the logs for messages indicating "Placing entry order", "Placing SL order", "Placing TP order".
        *   Log in to the Binance Futures Testnet web interface.
        *   Check the "Open Orders" tab for the corresponding pair. Verify that a MARKET order executed (check Trade History), and that corresponding STOP_MARKET (SL) and TAKE_PROFIT_MARKET (TP) orders were created with `reduceOnly` flag set and prices matching (or very close due to precision) the logged SL/TP values.
        *   Verify the quantities match the expected calculated size based on config (margin * leverage / entry).
    *   **Verification:** **Position Tracking (Manual):**
        *   After the entry order fills, check the "Positions" tab on the Testnet interface.
        *   Verify a position exists for the pair with the correct side (Long/Short), entry price, and quantity.
        *   Observe if the position closes when price hits the SL or TP level (check trade history and open orders again). *Note: Automated position tracking within the bot via `PositionManager` relies heavily on User Data Stream (not in MVP) or reconciliation, so internal state might lag the exchange.*
    *   **Verification:** **Logging:**
        *   Review the log output for clarity, appropriate levels (INFO/DEBUG), and useful information regarding bot status, signals, orders, and potential errors.
    *   **Verification:** **Monitoring (Optional):**
        *   If monitoring is enabled, access the Prometheus endpoint (`http://localhost:PORT/metrics`).
        *   Check if metrics like uptime, WebSocket status, klines processed, signals generated, orders placed are updating.

4.  **Identify and Document Issues:**
    *   **Action:** Keep detailed notes of any unexpected behavior, errors in logs, discrepancies between bot actions and Testnet interface state, or crashes.
    *   **Action:** Note specific conditions or sequences of events that trigger issues.
    *   **Action:** If issues are found, attempt to reproduce them.
    *   **Action:** Update `docs/TROUBLESHOOTING.md` with common problems encountered and their solutions/workarounds found during Testnet.

5.  **Refine and Debug (Iterative):**
    *   **Action:** Based on findings, stop the bot (`Ctrl+C`).
    *   **Action:** Modify the code (`src/...`) to fix identified bugs.
    *   **Action:** Restart the bot and re-verify the specific functionality that failed previously.
    *   **Action:** Repeat the monitoring and verification process until the core V1 strategy flow operates reliably on Testnet.

**Acceptance Criteria:**
*   The bot successfully connects to the Binance Futures Testnet WebSocket and REST APIs using provided testnet credentials.
*   Kline data is received and processed for configured pairs.
*   The bot generates V1 SMA crossover signals (both LONG and SHORT) based on observed chart patterns on Testnet.
*   Upon signal generation, the bot successfully places MARKET entry orders and corresponding STOP_MARKET (SL) / TAKE_PROFIT_MARKET (TP) orders with `reduceOnly=true` on the Testnet exchange.
*   Order details (prices, quantities) on Testnet match the bot's calculations and logs (considering precision adjustments).
*   The bot runs stably for a reasonable test period (e.g., several hours) without crashing.
*   Logs provide clear information about the bot's state and actions.
*   Any critical bugs identified during Testnet validation are fixed.


================================================
FILE: dev_tasks_docs/ikergoni-nancemakina.txt
================================================
Directory structure:
└── ikergoni-nancemakina/
    ├── README.md
    ├── Dockerfile
    ├── Project Status Update - May 12 2025 18_02.md
    ├── requirements.txt
    ├── run.sh
    ├── status_update.md
    ├── todo.md
    ├── config/
    │   └── config.yaml.example
    ├── dev_tasks_docs/
    │   ├── dev_plan_step_005.md
    │   ├── dev_plan_step_006.md
    │   ├── dev_plan_step_007.md
    │   ├── dev_plan_step_008.md
    │   ├── dev_plan_step_009.md
    │   ├── dev_plan_step_010.md
    │   └── dev_plan_step_013.md
    ├── docs/
    │   ├── ARCHITECTURE.md
    │   ├── CONFIGURATION_GUIDE.md
    │   └── TROUBLESHOOTING.md
    ├── src/
    │   ├── __init__.py
    │   ├── config_loader.py
    │   ├── connectors.py
    │   ├── data_processor.py
    │   ├── main.py
    │   ├── models.py
    │   ├── monitoring.py
    │   ├── order_manager.py
    │   ├── position_manager.py
    │   ├── signal_engine.py
    │   └── utils.py
    ├── tests/
    │   ├── __init__.py
    │   ├── e2e/
    │   │   └── __init__.py
    │   ├── integration/
    │   │   ├── __init__.py
    │   │   └── test_main_flow.py
    │   └── unit/
    │       ├── __init__.py
    │       ├── test_config_loader.py
    │       ├── test_connectors.py
    │       ├── test_data_processor.py
    │       ├── test_models.py
    │       ├── test_monitoring.py
    │       ├── test_order_manager.py
    │       ├── test_position_manager.py
    │       └── test_signal_engine.py
    └── .cursor/
        └── rules/
            └── projectrules.mdc

================================================
FILE: README.md
================================================
# Binance Futures Trading Bot

A robust, configurable trading bot for Binance Futures markets (USDT-M and COIN-M) with a focus on reliability, configurability, and extensibility.

## Features

- **Multi-Market Support**: Trade on both USDT-M and COIN-M Binance Futures markets
- **Configurable Strategy**: SMA crossover strategy (21 SMA crossing 200 SMA) with configurable parameters
- **Real-time Data Processing**: WebSocket connections for live market data
- **Risk Management**: Configurable position sizing, stop-loss, and take-profit
- **Monitoring**: Prometheus metrics for monitoring bot performance and health
- **Hot-reload Configuration**: Update trading parameters without restarting the bot
- **Extensible Architecture**: Modular design for easy addition of new strategies and features

## Installation

### Prerequisites

- Python 3.8+
- Binance Futures account with API keys
- (Optional) Docker for containerized deployment

### Setup

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/binance-futures-bot.git
   cd binance-futures-bot
   ```

2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

3. Create configuration file:
   ```bash
   cp config/config.yaml.example config/config.yaml
   ```

4. Edit the configuration file with your Binance API keys and trading preferences:
   ```bash
   nano config/config.yaml
   ```

## Configuration

The bot is configured through the `config/config.yaml` file. See [Configuration Guide](docs/CONFIGURATION_GUIDE.md) for detailed options.

Basic configuration example:

```yaml
api:
  binance_api_key: "YOUR_BINANCE_API_KEY"
  binance_api_secret: "YOUR_BINANCE_API_SECRET"

global_settings:
  v1_strategy:
    sma_short_period: 21
    sma_long_period: 200
    min_signal_interval_minutes: 60
    tp_sl_ratio: 2.0
    default_margin_usdt: 50.0
    default_leverage: 10
    margin_mode: "ISOLATED"
    indicator_timeframes: ["1m", "5m", "15m", "1h", "4h"]

pairs:
  BTC_USDT:
    enabled: true
    contract_type: "USDT_M"
    leverage: 5
    margin_usdt: 100.0
  ETH_USDT:
    enabled: true
    contract_type: "USDT_M"
  BTCUSD_PERP:
    enabled: false
    contract_type: "COIN_M"
    margin_coin: 0.001

logging:
  level: "INFO"
  file: "logs/bot.log"

monitoring:
  prometheus_port: 8000
```

## Running the Bot

### Standard Mode

Run the bot with:

```bash
python -m src.main
```

### Development Mode

For development with hot-reloading of code changes:

```bash
python -m src.main --dev
```

### Docker

Build and run with Docker:

```bash
docker build -t binance-futures-bot .
docker run -v $(pwd)/config:/app/config -v $(pwd)/logs:/app/logs binance-futures-bot
```

## Monitoring

The bot exposes Prometheus metrics on port 8000 (configurable). You can use Grafana or other Prometheus-compatible tools to visualize these metrics.

Default metrics endpoint: `http://localhost:8000/metrics`

## Architecture

The bot follows a modular architecture with clear separation of concerns. See [Architecture Overview](docs/ARCHITECTURE.md) for details on the system design.

Key components:
- **Config Manager**: Handles configuration loading and hot-reloading
- **WebSocket Connector**: Manages real-time data streams from Binance
- **REST Client**: Handles API calls for account data and order execution
- **Data Processor**: Processes market data and calculates indicators
- **Signal Engine**: Generates trade signals based on strategy rules
- **Order Manager**: Executes trades with proper position sizing
- **Position Manager**: Tracks open positions and their status

## Testing

Run the test suite with:

```bash
pytest
```

For specific test categories:

```bash
pytest tests/unit/  # Unit tests only
pytest tests/integration/  # Integration tests only
```

## Troubleshooting

See [Troubleshooting Guide](docs/TROUBLESHOOTING.md) for common issues and solutions.

## Disclaimer

This software is for educational purposes only. Use at your own risk. The authors are not responsible for any financial losses incurred from using this software. Always test thoroughly on testnet before using with real funds.

## License

MIT License



================================================
FILE: Dockerfile
================================================



================================================
FILE: Project Status Update - May 12 2025 18_02.md
================================================
# Project Status Update - May 12 2025 18:02

**Current Phase:** Pre-Testnet Validation - Codebase Cleanup and Packaging

**Overall Progress:**
- All core modules for the Binance Futures Trading Bot MVP (V1 Strategy) have been developed.
- Initial unit tests have been created for most modules.
- Documentation structure is in place (README, Configuration Guide, Architecture, Troubleshooting).
- The codebase has undergone several rounds of cleanup to remove non-production code, fix syntax errors, and ensure Pydantic V2 compatibility for data models.

**Last Completed Steps:**
- Refactored enum-like classes in `src/models.py` to use Python's `Enum` for Pydantic V2 compatibility.
- Thoroughly scanned and cleaned all Python modules (`src/connectors.py`, `src/data_processor.py`, `src/signal_engine.py`, etc.) to remove leftover test/example code, fix improper line continuations, and resolve syntax errors.

**Current State of `todo.md`:**
- Most development steps for Phase 1 (MVP) are marked as complete or in the final stages of cleanup/testing.
- The next major step after your review will be "Step 018: Validate end-to-end functionality on Testnet."

**Files Included in this Archive (`binance_bot_snapshot_20250512_1802.zip`):**
- The entire `/home/ubuntu/binance_futures_bot` project directory, containing all source code, configuration examples, tests, and documentation.
- `/home/ubuntu/todo.md` (current task checklist).
- This `status_update.md` file.

**Next Steps (Pending Your Review):**
1.  **User Review:** You review the provided codebase and status.
2.  **Testnet Validation:** Proceed with running the bot on the Binance Testnet to validate end-to-end functionality, including:
    - WebSocket connections and data reception.
    - Kline processing and indicator calculation.
    - Signal generation based on the V1 SMA crossover strategy.
    - Order placement, management, and position tracking (simulated if live testnet keys are not immediately available/configured by the user).
    - Logging and basic monitoring.
3.  **Bug Fixing:** Address any issues identified during Testnet validation.
4.  **Final Packaging:** Prepare the final functional application for delivery.

**Notes:**
- The `config/config.yaml` is currently set up with placeholder API keys for Testnet. You will need to replace `YOUR_TESTNET_API_KEY` and `YOUR_TESTNET_API_SECRET` with your actual Binance Testnet API keys to perform live trading tests on the Testnet.
- The bot is designed to be run using `python3.11 -m src.main` from the `/home/ubuntu/binance_futures_bot` directory after installing dependencies from `requirements.txt`.

We are now pausing development to await your review of the current project state. Please let us know if you have any questions or feedback before we proceed to the Testnet validation phase.



================================================
FILE: requirements.txt
================================================
ccxt
websockets
PyYAML
watchdog
pandas
numpy
python-dotenv
prometheus_client
pytest
tenacity
apscheduler
pydantic # For data models, if chosen




================================================
FILE: run.sh
================================================



================================================
FILE: status_update.md
================================================
# Project Status Update - May 12 2025 18:02

**Current Phase:** Pre-Testnet Validation - Codebase Cleanup and Packaging

**Overall Progress:**
- All core modules for the Binance Futures Trading Bot MVP (V1 Strategy) have been developed.
- Initial unit tests have been created for most modules.
- Documentation structure is in place (README, Configuration Guide, Architecture, Troubleshooting).
- The codebase has undergone several rounds of cleanup to remove non-production code, fix syntax errors, and ensure Pydantic V2 compatibility for data models.

**Last Completed Steps:**
- Refactored enum-like classes in `src/models.py` to use Python's `Enum` for Pydantic V2 compatibility.
- Thoroughly scanned and cleaned all Python modules (`src/connectors.py`, `src/data_processor.py`, `src/signal_engine.py`, etc.) to remove leftover test/example code, fix improper line continuations, and resolve syntax errors.

**Current State of `todo.md`:**
- Most development steps for Phase 1 (MVP) are marked as complete or in the final stages of cleanup/testing.
- The next major step after your review will be "Step 018: Validate end-to-end functionality on Testnet."

**Files Included in this Archive (`binance_bot_snapshot_20250512_1802.zip`):**
- The entire `/home/ubuntu/binance_futures_bot` project directory, containing all source code, configuration examples, tests, and documentation.
- `/home/ubuntu/todo.md` (current task checklist).
- This `status_update.md` file.

**Next Steps (Pending Your Review):**
1.  **User Review:** You review the provided codebase and status.
2.  **Testnet Validation:** Proceed with running the bot on the Binance Testnet to validate end-to-end functionality, including:
    - WebSocket connections and data reception.
    - Kline processing and indicator calculation.
    - Signal generation based on the V1 SMA crossover strategy.
    - Order placement, management, and position tracking (simulated if live testnet keys are not immediately available/configured by the user).
    - Logging and basic monitoring.
3.  **Bug Fixing:** Address any issues identified during Testnet validation.
4.  **Final Packaging:** Prepare the final functional application for delivery.

**Notes:**
- The `config/config.yaml` is currently set up with placeholder API keys for Testnet. You will need to replace `YOUR_TESTNET_API_KEY` and `YOUR_TESTNET_API_SECRET` with your actual Binance Testnet API keys to perform live trading tests on the Testnet.
- The bot is designed to be run using `python3.11 -m src.main` from the `/home/ubuntu/binance_futures_bot` directory after installing dependencies from `requirements.txt`.

We are now pausing development to await your review of the current project state. Please let us know if you have any questions or feedback before we proceed to the Testnet validation phase.



================================================
FILE: todo.md
================================================
# Binance Futures Trading Bot - Development Checklist

## Phase 1: Core Infrastructure & MVP (V1 Strategy)

- [ ] **Step 001: Initialize Project Repository and Directory Structure**
    - [x] Create main project directory `binance_futures_bot`.
    - [x] Create subdirectories: `.github/workflows`, `config`, `data`, `docs`, `src`, `tests/unit`, `tests/integration`, `tests/e2e`.
    - [x] Create initial empty files: `src/__init__.py`, `src/main.py`, `src/config_loader.py`, `src/connectors.py`, `src/data_processor.py`, `src/signal_engine.py`, `src/order_manager.py`, `src/position_manager.py`, `src/models.py`, `src/utils.py`, `src/monitoring.py`, `tests/__init__.py`, `tests/unit/__init__.py`, `tests/integration/__init__.py`, `tests/e2e/__init__.py`, `Dockerfile`, `README.md`, `.gitignore`, `run.sh`, `config/config.yaml.example`, `docs/ARCHITECTURE.md`, `docs/CONFIGURATION_GUIDE.md`, `.github/workflows/ci.yml`.
    - [x] Create initial `requirements.txt` with basic dependencies.
    - [x] Create initial `.gitignore`.
- [x] **Step 002: Implement Core Configuration Management Module (`src/config_loader.py`)**
    - [x] Define `config.yaml` structure (API keys, global V1 params, pair-specific settings, logging, monitoring).
    - [x] Implement `ConfigManager` class: load, validate, provide access to configuration.
    - [x] Implement hot-reloading of `config.yaml` using `watchdog`.
    - [x] Add unit tests for `ConfigManager`.
- [x] **Step 003: Implement Data Models (`src/models.py`)**
    - [x] Define Pydantic or dataclass models for `Kline`, `TradeSignal`, `Order`, `Position`, `PairConfig`.
    - [x] Add unit tests for data models.
- [x] **Step 004: Develop Binance WebSocket and REST Connectors (`src/connectors.py`)**
    - [x] Implement `BinanceWebSocketConnector`: connect, subscribe (1m, 5m, 15m, 1h, 4h), handle messages, reconnect logic for USDⓈ-M and COIN-M.
    - [x] Implement `BinanceRESTClient` (using `ccxt`): fetch exchange info, balance, place/cancel orders, fetch open orders/positions, set margin/leverage for USDⓈ-M and COIN-M.
    - [x] Add unit tests for connectors (mocking external calls)- [x] **Step 005: Implement Data Processing and Indicator Calculation (`src/data_processor.py`)**
    - [x] Receive k-line data from WebSocket.
    - [x] Store k-lines in buffers (per pair, per timeframe).
    - [x] Calculate SMAs (21, 200) for all configured timeframes (1m, 5m, 15m, 1h, 4h) using `pandas`.
    - [ ] Add unit tests for data processing and SMA calculation.dd unit tests for data processing and SMA calculation.
- [x] **Step 006: Develop Signal Engine V1 (`src/signal_engine.py`)**
    - [x] Implement `SignalEngineV1` class.
    - [x] Detect 1-minute SMA crossovers (21/200).
    - [x] Implement significance filter (configurable buffer time).
    - [x] Calculate SL (recent pivot lows/highs) and TP (fixed R:R ratio).
    - [x] Output `TradeSignal` object.
    - [ ] Add unit tests for V1 signal logic, SL/TP calculation.
- [x] **Step 007: Implement Order Manager (`src/order_manager.py`)**
    - [x] Receive `TradeSignal`.
    - [x] Set margin type and leverage.
    - [x] Implement position sizing (MVP: fixed margin allocation).
    - [x] Place MARKET entry, STOP_MARKET SL, TAKE_PROFIT_MARKET TP orders (with `reduceOnly=true`).
    - [x] Handle USDⓈ-M and COIN-M specifics.
    - [ ] Add unit tests for order manager logic (mocking API calls).
- [x] **Step 008: Implement Basic Position Manager (`src/position_manager.py`)**
    - [x] Track open positions (symbol, side, entry, size, SL/TP order IDs).
    - [x] Update status based on order fills/cancellations.
    - [ ] Add unit tests for position manager.- [x] **Step 009: Build Main Application Logic and Orchestration (`src/main.py`)**
    - [x] Initialize and orchestrate all modules.
    - [x] Manage data flow: WebSocket -> DataProcessor -> SignalEngine -> OrderManager.
    - [x] Handle startup, shutdown, config hot-reloads..
    - [ ] Implement main asynchronous loop.- [x] **Step 010: Add Basic Monitoring (`src/monitoring.py`)**
    - [x] Expose basic Prometheus metrics (uptime, WebSocket status, signals, errors).
    - [ ] Add unit tests for metrics exposure..
- [x] **Step 011: Write Unit and Integration Tests for MVP Scope**
    - [x] Ensure comprehensive unit test coverage for all new modules.
    - [x] Develop integration tests for key data flows (e.g., signal to order) with mocked Binance services- [x] **Step 012: Document Setup, Configuration, and Usage**
    - [x] Update `README.md` with setup, configuration, and running instructions.
    - [x] Create `docs/CONFIGURATION_GUIDE.md` detailing `config.yaml` options.
    - [x] Create `docs/ARCHITECTURE.md` with an overview of the system design.
    - [x] Create `docs/TROUBLESHOOTING.md` for common issues.net**
    - [ ] Configure bot for Binance Futures Testnet.
    - [ ] Run the bot and monitor its behavior for V1 strategy.
    - [ ] Verify signal generation, order placement (entry, SL, TP), and position tracking.
    - [ ] Debug and refine based on Testnet observations.
- [ ] **Step 014: Report and Send Functional App to User**
    - [ ] Package the application (e.g., as a zip archive with instructions or Docker image details).
    - [ ] Provide the functional app and necessary documentation to the user.

## Phase 2: Enhancements, V2 Strategy Foundation & Robustness (Post-MVP)
- [ ] Advanced V1 Filters (Volume, Volatility)
- [ ] Enhanced Risk Management for V1 (Dynamic Position Sizing, Trailing SL)
- [ ] COIN-M Full Support Refinement
- [ ] Signal Engine V2 Foundation (Multi-TF data, EMA cross, StochRSI, ATR SL/TP)
- [ ] Backtesting Framework (Initial)
- [ ] Improved Error Handling & Resilience
- [ ] Expanded Testing

## Phase 3: Full V2 Strategy & Advanced Features (Post-Phase 2)
- [ ] Signal Engine V2 Completion
- [ ] Advanced Filters for V2 (BTC Correlation, Funding Rate)
- [ ] Advanced Risk & Exit Strategies (Adaptive TP, Volatility-Based Leverage, Time-Based/Reversal Exits)
- [ ] Dynamic Pair Selection (Optional)
- [ ] Backtesting Optimization
- [ ] Advanced Monitoring & Alerting

## Phase 4: Deployment & Maintenance (Post-Phase 3)
- [ ] Dockerization (`Dockerfile`, `run.sh`)
- [ ] Deployment Strategy for 24/7 Free Operation
- [ ] CI/CD Pipeline (`.github/workflows/ci.yml`)
- [ ] Comprehensive Documentation Finalization
- [ ] Ongoing Maintenance Plan



================================================
FILE: config/config.yaml.example
================================================
# Binance Futures Trading Bot - Example Configuration
# Copy this file to config.yaml and edit with your settings.

api:
  binance_api_key: "YOUR_BINANCE_API_KEY" # Your Binance API Key (ensure only Futures trading is enabled)
  binance_api_secret: "YOUR_BINANCE_API_SECRET" # Your Binance API Secret
  # For COIN-M, if different keys are needed, this structure might need adjustment or separate sections.
  # For now, assuming same keys for USD-M and COIN-M or that ccxt handles it.

global_settings:
  # V1 Strategy Defaults (SMA Crossover)
  v1_strategy:
    sma_short_period: 21
    sma_long_period: 200
    # Minimum time in minutes between signals for the same pair to reduce noise
    min_signal_interval_minutes: 15
    # Take Profit = Risk * tp_sl_ratio. SL is based on recent support/resistance.
    tp_sl_ratio: 3.0
    # Default margin to use per trade if not specified per pair (for fixed margin allocation)
    default_margin_usdt: 50.0 # For USDT-M pairs
    # default_margin_coin: 0.1 # Example for COIN-M pairs (e.g., 0.1 BTC for BTCUSD_PERP)
    # Default leverage if not specified per pair
    default_leverage: 10
    # Default margin mode: "ISOLATED" or "CROSSED"
    margin_mode: "ISOLATED"
    # Timeframes to calculate SMAs on (e.g., 1m, 5m, 15m, 1h, 4h). V1 uses 1m for signals.
    # The data_processor will calculate for all these, signal_engine_v1 will use 1m.
    indicator_timeframes: ["1m", "5m", "15m", "1h", "4h"]

  # V2 Strategy Defaults (to be detailed in Phase 2/3)
  # v2_strategy:
    # strategy_v2_enabled: false
    # ... other V2 parameters ...

  # General Risk Management (some may be V2 specific or advanced V1)
  risk_management:
    # For dynamic position sizing: risk this percentage of available balance per trade
    dynamic_sizing_risk_percent: 1.0 # e.g., 1% of balance
    # Enable dynamic position sizing (true/false). If false, uses fixed margin from v1_strategy.
    dynamic_sizing_enabled: false
    # volatility_based_leverage_enabled: false # Future enhancement

  # Optional Filters (can be enabled/disabled globally or per pair)
  filters:
    volume_filter_enabled: false
    # volume_avg_period: 50
    # volume_threshold_ratio: 1.5 # Signal candle volume must be 1.5x the average

    volatility_filter_enabled: false # Bollinger Bands width filter
    # bb_period: 20
    # bb_std_dev: 2
    # bb_min_width_percentage: 0.5 # Min BB width as % of price to trade

    # btc_correlation_filter_enabled: false # For altcoins, future enhancement
    # max_funding_rate_threshold: 0.001 # Skip if abs(funding_rate) > 0.1%, future enhancement

  # Exit Strategies (beyond SL/TP, future enhancements)
  # exit_strategies:
    # time_based_exit_enabled: false
    # max_trade_duration_hours: 4
    # reversal_exit_enabled: false

pairs:
  # USD-M Perpetual Contracts (Examples)
  BTC_USDT:
    enabled: true
    # Override global V1 settings if needed
    # sma_short_period: 10
    # margin_mode: "CROSSED"
    # leverage: 20
    # margin_usdt: 100 # Specific margin for this USDT-M pair
    # dynamic_sizing_enabled: true # Override global dynamic sizing
    # risk_percent_per_trade: 0.5 # Override global risk percent

  ETH_USDT:
    enabled: true
    # leverage: 15
    # margin_usdt: 75

  # COIN-M Perpetual Contracts (Examples)
  # Note: For COIN-M, margin is specified in the base currency (e.g., BTC for BTCUSD_PERP)
  # The bot will need to handle this distinction for position sizing and P&L.
  BTCUSD_PERP: # Binance symbol for BTC/USD COIN-M Perpetual
    enabled: false
    # margin_coin: 0.01 # e.g., 0.01 BTC for this pair
    # leverage: 10
    # contract_type: "COIN_M" # Explicitly marking, though symbol format might imply it

  ETHUSD_PERP:
    enabled: false
    # margin_coin: 0.1 # e.g., 0.1 ETH
    # leverage: 10
    # contract_type: "COIN_M"

logging:
  # Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
  level: "INFO"
  # Log file path (optional, if not specified, logs to console and default app.log)
  # log_file: "/path/to/your/custom_app.log"

monitoring:
  prometheus_port: 8000 # Port for Prometheus metrics endpoint

backtesting: # Configuration for backtesting module (future phase)
  # start_date: "2023-01-01T00:00:00Z"
  # end_date: "2023-12-31T23:59:59Z"
  # initial_balance_usdt: 10000
  # initial_balance_coin: { "BTC": 1, "ETH": 10 } # For COIN-M backtesting
  # slippage_percent: 0.01 # 0.01% slippage
  # fee_percent: 0.04    # 0.04% trading fee (taker)




================================================
FILE: dev_tasks_docs/dev_plan_step_005.md
================================================
# Development Plan: Step 005 - Add Unit Tests for `data_processor.py`

**Task:** Step 005 - Add comprehensive unit tests for the `DataProcessor` module (`src/data_processor.py`).

**Objective:** Ensure the `DataProcessor` class correctly initializes based on configuration, processes incoming Kline data, manages internal buffers (deques and DataFrames), calculates SMA indicators accurately, handles edge cases, and responds to configuration updates.

**Target File(s):**
*   `tests/unit/test_data_processor.py` (Primary file to create/modify)

**Context:**
*   `src/data_processor.py` exists with the `DataProcessor` class implementation.
*   It uses `pandas` for DataFrames and indicator calculations (SMA).
*   It uses `collections.deque` for Kline buffering.
*   It registers a callback with `ConfigManager` for hot-reloading.
*   A basic `tests/unit/test_data_processor.py` file exists but needs comprehensive test cases.

**Detailed Plan:**

1.  **Setup Test Fixtures:**
    *   Create a `pytest` fixture (`mock_config_manager_for_dp`) using `unittest.mock.MagicMock` or a helper class to simulate `ConfigManager`. This fixture should provide different mock configurations for various test scenarios (e.g., different enabled pairs, timeframes, SMA periods).
    *   Create a `pytest` fixture (`data_processor`) that initializes `DataProcessor` with the mock config manager. Ensure each test gets a fresh instance.
    *   Use `pytest.mark.asyncio` for all test functions as `process_kline` is async.

2.  **Test Initialization (`__init__` & `_initialize_buffers_from_config`):**
    *   **Test Case:** Verify buffer creation based on `enabled` pairs and `indicator_timeframes` in config.
        *   **Action:** Initialize `DataProcessor` with a mock config having a mix of enabled/disabled pairs and global/specific timeframes.
        *   **Assert:** Check `data_processor._active_pairs_timeframes` dict matches the expected enabled pairs and their associated timeframes. Assert that `data_processor.kline_buffers[symbol][timeframe]` exists and is a `deque` for all active combinations. Assert that buffers for *disabled* pairs are *not* present or are empty. Assert deque `maxlen` is `MAX_KLINE_BUFFER_LENGTH`.
    *   **Test Case:** Verify initialization with empty `pairs` configuration.
        *   **Action:** Initialize `DataProcessor` with a mock config where `pairs` is empty or missing.
        *   **Assert:** `_active_pairs_timeframes`, `kline_buffers`, and `indicator_data` should be empty.

3.  **Test Kline Processing (`process_kline`):**
    *   **Test Case:** Process a single *closed* Kline for an active pair/timeframe.
        *   **Action:** Call `await data_processor.process_kline(kline_closed)` with a sample `Kline` object.
        *   **Assert:** Check the kline is appended to the correct `kline_buffers[symbol][timeframe]` deque. Verify `_update_indicators` was implicitly called (e.g., by checking if `indicator_data` DataFrame is updated).
    *   **Test Case:** Process a single *unclosed* Kline for an active pair/timeframe.
        *   **Action:** Call `await data_processor.process_kline(kline_unclosed)`.
        *   **Assert:** Check the kline is appended. Verify `_update_indicators` might *not* have been called yet (depending on implementation, but typically only runs on closed candles). Check `indicator_data` state.
    *   **Test Case:** Update the last *unclosed* Kline.
        *   **Action:** Process `kline_unclosed_t1`. Process `kline_unclosed_t1_update` (same timestamp, different data).
        *   **Assert:** The deque should still contain only one element, and it should be `kline_unclosed_t1_update`.
    *   **Test Case:** Replace the last *unclosed* Kline with its *closed* version.
        *   **Action:** Process `kline_unclosed_t1`. Process `kline_closed_t1` (same timestamp).
        *   **Assert:** The deque should contain one element (`kline_closed_t1`). Verify `_update_indicators` was called.
    *   **Test Case:** Process Kline for an *inactive* pair/timeframe.
        *   **Action:** Create a Kline for a pair/timeframe *not* enabled in the mock config. Call `process_kline`.
        *   **Assert:** Verify the kline was *not* added to any buffer and `indicator_data` remains unchanged for that symbol/tf.
    *   **Test Case:** Buffer limit enforcement.
        *   **Action:** Process `MAX_KLINE_BUFFER_LENGTH + 5` klines.
        *   **Assert:** The length of the deque should be exactly `MAX_KLINE_BUFFER_LENGTH`. Verify the oldest klines were discarded.

4.  **Test Indicator Calculation (`_update_indicators`):**
    *   **Test Case:** Insufficient data for SMAs.
        *   **Action:** Process fewer klines than `sma_short_period`. Call `_update_indicators` directly (or process a closed kline).
        *   **Assert:** The resulting DataFrame in `indicator_data` should have `sma_short` and `sma_long` columns filled with `pd.NA` or appropriate null values.
    *   **Test Case:** Correct SMA calculation (short period).
        *   **Action:** Process exactly `sma_short_period` klines. Process one more *closed* kline.
        *   **Assert:** Fetch the DataFrame using `get_indicator_dataframe`. Verify the `sma_short` value for the last row matches the manually calculated SMA. `sma_long` should still be NA.
    *   **Test Case:** Correct SMA calculation (long period).
        *   **Action:** Process exactly `sma_long_period` klines. Process one more *closed* kline.
        *   **Assert:** Fetch the DataFrame. Verify both `sma_short` and `sma_long` values for the last row match manually calculated SMAs.
    *   **Test Case:** SMA calculation with duplicate timestamps (ensure last update is used).
        *   **Action:** Process klines including updates with the same timestamp.
        *   **Assert:** Verify the DataFrame used for SMA calculation does not contain duplicate indices and uses the final update for that timestamp. Check SMA correctness.

5.  **Test Getter Methods (`get_latest_kline`, `get_indicator_dataframe`, `get_latest_indicators`):**
    *   **Test Case:** Getters return correct data after processing.
        *   **Action:** Process some klines.
        *   **Assert:** `get_latest_kline` returns the last processed Kline object. `get_indicator_dataframe` returns a DataFrame copy. `get_latest_indicators` returns the last row (Series) of the indicator DataFrame.
    *   **Test Case:** Getters return `None` or empty DataFrame for non-existent symbol/timeframe.
        *   **Action:** Call getters with invalid symbols/timeframes.
        *   **Assert:** Verify `None` or empty `pd.DataFrame` is returned as appropriate.

6.  **Test Configuration Hot-Reload (`_handle_config_update`):**
    *   **Test Case:** Adding a new active pair via config update.
        *   **Action:** Initialize `DataProcessor`. Simulate a config update callback (`_handle_config_update`) with a new config dictionary where a previously disabled pair is now enabled.
        *   **Assert:** Check `_active_pairs_timeframes` now includes the new pair. Verify that corresponding buffers have been created in `kline_buffers` and `indicator_data`.
    *   **Test Case:** Disabling an existing active pair via config update.
        *   **Action:** Initialize `DataProcessor`. Simulate a config update callback disabling an active pair.
        *   **Assert:** Check `_active_pairs_timeframes` no longer includes the disabled pair. (Note: The current implementation might not *remove* old buffers, just stop processing for them. Assert behavior based on implementation).
    *   **Test Case:** Changing `indicator_timeframes` for a pair.
        *   **Action:** Initialize `DataProcessor`. Simulate a config update changing the timeframes list for an active pair.
        *   **Assert:** Check `_active_pairs_timeframes` reflects the new timeframes. Verify necessary buffers exist/are managed.

**Acceptance Criteria:**
*   All test cases described above pass.
*   Test coverage for `src/data_processor.py` is significantly increased.
*   Tests use mocked dependencies (`ConfigManager`) and do not rely on external systems.
*   Tests adhere to PEP 8, use type hints, and follow async patterns correctly.
*   Edge cases like empty data, NA values, and buffer limits are handled.


================================================
FILE: dev_tasks_docs/dev_plan_step_006.md
================================================
# Development Plan: Step 006 - Add Unit Tests for `signal_engine.py`

**Task:** Step 006 - Add comprehensive unit tests for the `SignalEngineV1` module (`src/signal_engine.py`), focusing on V1 signal logic and SL/TP calculation.

**Objective:** Ensure the `SignalEngineV1` class correctly identifies SMA crossover conditions, applies filters (like minimum signal interval), calculates Stop Loss (SL) based on pivot points, calculates Take Profit (TP) based on the configured Risk/Reward ratio, and generates accurate `TradeSignal` objects or `None`.

**Target File(s):**
*   `tests/unit/test_signal_engine.py` (Primary file to create/modify)

**Context:**
*   `src/signal_engine.py` exists with the `SignalEngineV1` class implementation.
*   It depends on `ConfigManager` for strategy parameters (SMA periods, R:R ratio, interval filter) and `DataProcessor` for accessing indicator DataFrames.
*   The V1 strategy involves checking the last two data points for SMA crossover.
*   SL calculation involves finding recent pivot lows/highs from the indicator DataFrame.
*   TP is calculated based on SL distance and R:R ratio.
*   `src/models.py` defines the `TradeSignal` object returned.
*   A basic `tests/unit/test_signal_engine.py` file exists but needs comprehensive test cases.

**Detailed Plan:**

1.  **Setup Test Fixtures:**
    *   Create a `pytest` fixture (`mock_config_manager_for_se`) providing mock configurations, including different SMA periods, R:R ratios, and `min_signal_interval_minutes`.
    *   Create a `pytest` fixture (`mock_data_processor_for_se`) using `unittest.mock.MagicMock`. Mock its `get_indicator_dataframe` method to return controlled `pd.DataFrame` objects for specific test scenarios.
    *   Create a `pytest` fixture (`signal_engine_v1`) that initializes `SignalEngineV1` with the mock config manager and data processor.
    *   Use `pytest.mark.asyncio` for all test functions as `check_signal` is async.
    *   Create helper functions (e.g., `create_mock_df`) within the test file to easily generate DataFrames representing specific market conditions (crossovers, no crossovers, specific pivot points).

2.  **Test Signal Generation Logic (`check_signal`):**
    *   **Test Case:** No signal when data is insufficient.
        *   **Action:** Configure `mock_data_processor_for_se.get_indicator_dataframe` to return `None`, an empty DataFrame, or a DataFrame with only one row. Call `check_signal`.
        *   **Assert:** `check_signal` should return `None`.
    *   **Test Case:** No signal when SMA values are NA.
        *   **Action:** Return a DataFrame where the latest or previous SMA values are `pd.NA`. Call `check_signal`.
        *   **Assert:** `check_signal` should return `None`.
    *   **Test Case:** No signal when no crossover occurs (e.g., SMAs diverging, moving parallel).
        *   **Action:** Return a DataFrame where `sma_short > sma_long` in both the previous and current row. Call `check_signal`.
        *   **Action:** Return a DataFrame where `sma_short < sma_long` in both the previous and current row. Call `check_signal`.
        *   **Assert:** `check_signal` should return `None` in both cases.
    *   **Test Case:** Generate a LONG signal on valid bullish crossover.
        *   **Action:** Return a DataFrame representing `prev: short <= long`, `curr: short > long`. Call `check_signal`.
        *   **Assert:** `check_signal` should return a `TradeSignal` object. Verify `signal.direction == TradeDirection.LONG`. Verify `signal.symbol`, `config_symbol`, `contract_type` are correctly populated. Verify `signal.entry_price` matches the `close` of the last row in the DataFrame.
    *   **Test Case:** Generate a SHORT signal on valid bearish crossover.
        *   **Action:** Return a DataFrame representing `prev: short >= long`, `curr: short < long`. Call `check_signal`.
        *   **Assert:** `check_signal` should return a `TradeSignal` object. Verify `signal.direction == TradeDirection.SHORT`. Verify other fields as above.

3.  **Test SL/TP Calculation:**
    *   **Test Case:** Correct SL calculation for LONG signal (pivot low).
        *   **Action:** Use the LONG signal scenario. Ensure the mock DataFrame provided has identifiable recent low points *before* the signal candle.
        *   **Assert:** Verify `signal.stop_loss_price` matches the expected minimum low from the lookback period defined in `_find_recent_pivot` (e.g., 30 candles before the signal candle by default).
    *   **Test Case:** Correct SL calculation for SHORT signal (pivot high).
        *   **Action:** Use the SHORT signal scenario. Ensure the mock DataFrame has identifiable recent high points *before* the signal candle.
        *   **Assert:** Verify `signal.stop_loss_price` matches the expected maximum high from the lookback period.
    *   **Test Case:** No signal if pivot point cannot be determined (e.g., insufficient historical data in DataFrame).
        *   **Action:** Provide a DataFrame that triggers a crossover but is too short for the pivot lookback.
        *   **Assert:** `check_signal` should return `None` (and log a warning).
    *   **Test Case:** Correct TP calculation based on SL and R:R ratio (LONG).
        *   **Action:** Use the LONG signal scenario. Manually calculate `expected_tp = entry + (entry - sl) * rr_ratio`.
        *   **Assert:** `signal.take_profit_price` should be close to `expected_tp` (allow for float precision).
    *   **Test Case:** Correct TP calculation based on SL and R:R ratio (SHORT).
        *   **Action:** Use the SHORT signal scenario. Manually calculate `expected_tp = entry - (sl - entry) * rr_ratio`.
        *   **Assert:** `signal.take_profit_price` should be close to `expected_tp`.
    *   **Test Case:** No signal if calculated SL results in zero or negative risk (e.g., SL >= entry for LONG, SL <= entry for SHORT).
        *   **Action:** Craft DataFrame data where the calculated pivot leads to invalid risk.
        *   **Assert:** `check_signal` should return `None`.
    *   **Test Case:** Verify `signal.signal_kline` content matches the last row of the input DataFrame.
        *   **Action:** Check the `signal.signal_kline` attribute when a valid signal is generated.
        *   **Assert:** The `Kline` object's fields (`timestamp`, `open`, `high`, `low`, `close`, etc.) match the data from the last row of the DataFrame used for signal generation.

4.  **Test Filters:**
    *   **Test Case:** Minimum signal interval filter prevents rapid signals.
        *   **Action:** Configure mock config with a non-zero `min_signal_interval_minutes` (e.g., 15). Call `check_signal` for a symbol to generate a first signal. Immediately call `check_signal` again for the *same symbol* with data that would otherwise generate a signal.
        *   **Assert:** The first call returns a `TradeSignal`. The second call returns `None`.
    *   **Test Case:** Minimum signal interval filter allows signal after interval passes.
        *   **Action:** Generate the first signal. Manually manipulate `signal_engine_v1.last_signal_time[symbol]` using `time.time()` to simulate the interval having passed. Call `check_signal` again.
        *   **Assert:** The second call should now return a `TradeSignal`.
    *   **Test Case:** Minimum signal interval is pair-specific.
        *   **Action:** Use a config where Pair A has interval > 0, Pair B has interval = 0. Generate signal for Pair A. Immediately generate signal for Pair B.
        *   **Assert:** Signal for Pair A prevents immediate repeat. Signal for Pair B is generated successfully right after.

5.  **Test Helper Methods (Optional but Recommended):**
    *   **Test Case:** Direct test for `_get_pair_specific_config`.
        *   **Action:** Call `_get_pair_specific_config` with different `config_symbol` values.
        *   **Assert:** Verify it correctly merges global and pair-specific settings from the mock config.
    *   **Test Case:** Direct test for `_find_recent_pivot`.
        *   **Action:** Create various DataFrames and call `_find_recent_pivot` directly for LONG and SHORT directions with different lookback values.
        *   **Assert:** Verify it correctly identifies the min low / max high within the specified lookback window (excluding the last row). Test edge cases like flat lines or insufficient data.

**Acceptance Criteria:**
*   All test cases described above pass.
*   Test coverage for `src/signal_engine.py` is significantly increased, covering crossover logic, SL/TP calculation, and filters.
*   Tests use mocked dependencies (`ConfigManager`, `DataProcessor`).
*   Tests accurately simulate different market data scenarios using controlled DataFrames.
*   Generated `TradeSignal` objects contain correct data based on inputs.
*   Edge cases for SL/TP calculation and filters are handled correctly.


================================================
FILE: dev_tasks_docs/dev_plan_step_007.md
================================================
# Development Plan: Step 007 - Add Unit Tests for `order_manager.py`

**Task:** Step 007 - Add comprehensive unit tests for the `OrderManager` module (`src/order_manager.py`).

**Objective:** Ensure the `OrderManager` class correctly receives `TradeSignal` objects, calculates position size based on configuration (fixed margin MVP), fetches and applies exchange filters (precision, min notional), places the correct entry, Stop Loss (SL), and Take Profit (TP) orders via the `BinanceRESTClient`, and handles specifics for USDT-M and COIN-M contracts.

**Target File(s):**
*   `tests/unit/test_order_manager.py` (Primary file to create/modify)

**Context:**
*   `src/order_manager.py` exists with the `OrderManager` class implementation.
*   It depends on `ConfigManager` for parameters (leverage, fixed margin amounts) and `BinanceRESTClient` for executing orders and fetching exchange info.
*   MVP focuses on fixed margin sizing (USDT amount for USDT-M, potentially number of contracts for COIN-M as per current simple implementation).
*   Places MARKET entry, STOP_MARKET SL, and TAKE_PROFIT_MARKET TP orders.
*   Includes logic for adjusting quantity and price to meet exchange precision rules.
*   Includes a basic min_notional value check.
*   A basic `tests/unit/test_order_manager.py` file exists but needs comprehensive test cases.

**Detailed Plan:**

1.  **Setup Test Fixtures:**
    *   Create a `pytest` fixture (`mock_config_manager_for_om`) providing mock configurations, including USDT-M and COIN-M pairs with different leverage and fixed margin settings.
    *   Create a `pytest` fixture (`mock_rest_client_for_om`) using `unittest.mock.AsyncMock`.
        *   Mock `rest_client.fetch_exchange_info` to return realistic market data including `precision` (amount, price) and `limits` (cost/min_notional) for test symbols (e.g., BTCUSDT, ETHUSD_PERP).
        *   Mock `rest_client.create_order` to simulate successful order placement, returning a mock order dictionary with an ID and status. It should also capture the arguments it was called with for verification.
        *   Mock other methods if needed (e.g., `set_leverage`, `set_margin_mode`), although the current `handle_trade_signal` assumes these are pre-set.
    *   Create a `pytest` fixture (`order_manager`) that initializes `OrderManager` with the mock config manager and rest client. Prime the exchange info cache within the fixture using `await order_manager._get_exchange_info_for_symbol(symbol)`.
    *   Use `pytest.mark.asyncio` for all test functions as `handle_trade_signal` and underlying REST calls are async.

2.  **Test Precision and Filter Logic:**
    *   **Test Case:** `_adjust_quantity_to_precision`.
        *   **Action:** Call `order_manager._adjust_quantity_to_precision` directly with various quantities and step sizes (e.g., 0.001, 0.1, 1).
        *   **Assert:** Verify the returned quantity is correctly floored to the specified step size precision.
    *   **Test Case:** `_adjust_price_to_precision`.
        *   **Action:** Call `order_manager._adjust_price_to_precision` directly with various prices and tick sizes (e.g., 0.01, 0.5, 10).
        *   **Assert:** Verify the returned price is correctly rounded to the specified tick size precision.
    *   **Test Case:** `_get_symbol_filters` retrieves correct filters.
        *   **Action:** Call `await order_manager._get_symbol_filters(symbol)`.
        *   **Assert:** Verify it returns the correct tuple `(lot_step_size, price_tick_size, min_notional)` based on the mocked `fetch_exchange_info` data. Test that the cache prevents repeated `fetch_exchange_info` calls.
    *   **Test Case:** `_get_symbol_filters` handles missing filter data gracefully.
        *   **Action:** Mock `fetch_exchange_info` to return data missing certain precision/limits fields. Call `_get_symbol_filters`.
        *   **Assert:** Verify it returns `None` for the missing values and logs appropriate warnings.

3.  **Test Position Sizing (Fixed Margin MVP):**
    *   **Test Case:** Correct quantity calculation for USDT-M pair.
        *   **Action:** Create a `TradeSignal` for a configured USDT-M pair. Call `await order_manager.handle_trade_signal(signal)`.
        *   **Assert:** Manually calculate the expected quantity: `(margin_usdt * leverage) / entry_price`, adjusted to the mocked `lot_step_size`. Verify the `amount` passed to `mock_rest_client.create_order` for the entry order matches this expected quantity.
    *   **Test Case:** Correct quantity calculation for COIN-M pair (MVP assumption: `margin_coin` is number of contracts).
        *   **Action:** Create a `TradeSignal` for a configured COIN-M pair where `margin_coin` is set. Call `await order_manager.handle_trade_signal(signal)`.
        *   **Assert:** Verify the `amount` passed to `create_order` matches the `margin_coin` value from the config, adjusted to the mocked `lot_step_size`. Add a note acknowledging this is a simplification.
    *   **Test Case:** Handling missing margin configuration.
        *   **Action:** Create a signal for a pair where `margin_usdt` (for USDT-M) or `margin_coin` (for COIN-M) is missing in both pair-specific and global config. Call `handle_trade_signal`.
        *   **Assert:** Verify that `create_order` is *not* called and an error is logged.
    *   **Test Case:** Handling zero or invalid entry price.
        *   **Action:** Create a signal with `entry_price=0`. Call `handle_trade_signal`.
        *   **Assert:** Verify `create_order` is not called.

4.  **Test Order Placement Logic:**
    *   **Test Case:** Correct parameters for MARKET entry order (LONG).
        *   **Action:** Handle a LONG `TradeSignal`. Inspect the first call to `mock_rest_client.create_order`.
        *   **Assert:** Verify `symbol`, `order_type=OrderType.MARKET`, `side=OrderSide.BUY`, and calculated `amount` are correct.
    *   **Test Case:** Correct parameters for MARKET entry order (SHORT).
        *   **Action:** Handle a SHORT `TradeSignal`. Inspect the first call.
        *   **Assert:** Verify `symbol`, `order_type=OrderType.MARKET`, `side=OrderSide.SELL`, and calculated `amount` are correct.
    *   **Test Case:** Correct parameters for STOP_MARKET SL order (for LONG entry).
        *   **Action:** Handle a LONG `TradeSignal`. Inspect the second call.
        *   **Assert:** Verify `symbol`, `order_type=OrderType.STOP_MARKET`, `side=OrderSide.SELL`, `amount` (same as entry), `params['stopPrice']` (adjusted SL price), and `params['reduceOnly'] == 'true'`.
    *   **Test Case:** Correct parameters for STOP_MARKET SL order (for SHORT entry).
        *   **Action:** Handle a SHORT `TradeSignal`. Inspect the second call.
        *   **Assert:** Verify `symbol`, `order_type=OrderType.STOP_MARKET`, `side=OrderSide.BUY`, `amount`, `params['stopPrice']` (adjusted SL price), and `params['reduceOnly'] == 'true'`.
    *   **Test Case:** Correct parameters for TAKE_PROFIT_MARKET TP order (for LONG entry).
        *   **Action:** Handle a LONG `TradeSignal`. Inspect the third call.
        *   **Assert:** Verify `symbol`, `order_type=OrderType.TAKE_PROFIT_MARKET`, `side=OrderSide.SELL`, `amount`, `params['stopPrice']` (adjusted TP price), and `params['reduceOnly'] == 'true'`.
    *   **Test Case:** Correct parameters for TAKE_PROFIT_MARKET TP order (for SHORT entry).
        *   **Action:** Handle a SHORT `TradeSignal`. Inspect the third call.
        *   **Assert:** Verify `symbol`, `order_type=OrderType.TAKE_PROFIT_MARKET`, `side=OrderSide.BUY`, `amount`, `params['stopPrice']` (adjusted TP price), and `params['reduceOnly'] == 'true'`.
    *   **Test Case:** Min Notional check prevents order placement.
        *   **Action:** Configure mock exchange info with a `min_notional` value higher than the calculated notional value (`quantity * entry_price` for USDT-M). Handle a relevant `TradeSignal`.
        *   **Assert:** Verify `mock_rest_client.create_order` is *not* called and a warning is logged.
    *   **Test Case:** Calculated quantity is zero or negative.
        *   **Action:** Contrive a scenario (e.g., via precision adjustment or bad input signal) where the final calculated quantity is <= 0. Call `handle_trade_signal`.
        *   **Assert:** Verify `create_order` is not called.

5.  **Test Error Handling:**
    *   **Test Case:** Failure to fetch exchange info.
        *   **Action:** Mock `rest_client.fetch_exchange_info` to return `None` or raise an exception. Clear the cache (`order_manager.exchange_info_cache = {}`) Call `handle_trade_signal`.
        *   **Assert:** Verify `create_order` is not called and an error is logged.
    *   **Test Case:** Entry order placement fails.
        *   **Action:** Mock `rest_client.create_order` for the first call to return `None` or an error response (e.g., `{"status": "REJECTED"}`). Handle a `TradeSignal`.
        *   **Assert:** Verify only the first call to `create_order` is made. Verify subsequent SL/TP orders are *not* placed. Verify an error is logged.
    *   **Test Case:** SL or TP order placement fails.
        *   **Action:** Mock `rest_client.create_order` to succeed for entry but fail for SL (return `None`). Handle a `TradeSignal`.
        *   **Assert:** Verify entry and SL calls are made. Verify TP call is still attempted (or not, depending on desired logic - current code attempts TP even if SL fails). Verify an error is logged regarding the failed SL order.

**Acceptance Criteria:**
*   All test cases described above pass.
*   Test coverage for `src/order_manager.py` is significantly increased, covering sizing, precision adjustment, order parameters, and basic error handling.
*   Tests use mocked dependencies (`ConfigManager`, `BinanceRESTClient`).
*   Order parameters (`symbol`, `type`, `side`, `amount`, `price`, `stopPrice`, `reduceOnly`) are validated for entry, SL, and TP orders in different scenarios.
*   Fixed margin position sizing logic for USDT-M and the simplified COIN-M approach are tested.
*   Precision adjustments and min_notional checks are verified.


================================================
FILE: dev_tasks_docs/dev_plan_step_008.md
================================================
# Development Plan: Step 008 - Add Unit Tests for `position_manager.py`

**Task:** Step 008 - Add comprehensive unit tests for the `PositionManager` module (`src/position_manager.py`).

**Objective:** Ensure the `PositionManager` class correctly tracks open positions (adds, updates, removes), provides accurate status information (`get_position`, `get_all_positions`, `has_open_position`), and updates position state correctly based on simulated order update events. Also, test the basic reconciliation logic.

**Target File(s):**
*   `tests/unit/test_position_manager.py` (Primary file to create/modify)

**Context:**
*   `src/position_manager.py` exists with the `PositionManager` class implementation.
*   It stores `Position` objects (defined in `src/models.py`) in a dictionary keyed by symbol.
*   It uses a `threading.RLock` for basic thread safety.
*   The core logic involves CRUD operations on the internal `_positions` dictionary and updating state based on `Order` objects passed to `update_position_on_order_update`.
*   Includes a `reconcile_positions_with_exchange` method requiring a `BinanceRESTClient` instance.
*   A basic `tests/unit/test_position_manager.py` file exists but needs comprehensive test cases.

**Detailed Plan:**

1.  **Setup Test Fixtures:**
    *   Create a `pytest` fixture (`mock_config_manager_for_pm`) - can be a simple mock as `PositionManager` doesn't heavily rely on config in its current form.
    *   Create a `pytest` fixture (`position_manager`) that initializes `PositionManager` with the mock config manager. Ensure each test gets a fresh instance.
    *   Use `pytest.mark.asyncio` for all test functions as methods like `add_or_update_position` and `update_position_on_order_update` are async.

2.  **Test Basic Position Management:**
    *   **Test Case:** Add a new position.
        *   **Action:** Create a sample `Position` object. Call `await position_manager.add_or_update_position(pos_data)`.
        *   **Assert:** `position_manager.get_position(symbol)` returns the added position object. `position_manager.has_open_position(symbol)` returns `True`. `position_manager.get_all_positions()` returns a list containing the position.
    *   **Test Case:** Update an existing position.
        *   **Action:** Add a position. Create a second `Position` object for the same symbol with modified data (e.g., updated `sl_order_id`, `unrealized_pnl`). Call `add_or_update_position` with the updated data.
        *   **Assert:** `position_manager.get_position(symbol)` returns the *updated* position object. `len(position_manager.get_all_positions())` should remain 1.
    *   **Test Case:** Remove an existing position.
        *   **Action:** Add a position. Call `await position_manager.remove_position(symbol)`.
        *   **Assert:** `position_manager.has_open_position(symbol)` returns `False`. `position_manager.get_position(symbol)` returns `None`. `position_manager.get_all_positions()` is empty.
    *   **Test Case:** Remove a non-existent position.
        *   **Action:** Call `remove_position` for a symbol not in the manager.
        *   **Assert:** No error occurs. State remains unchanged.
    *   **Test Case:** Getters return correct values when empty.
        *   **Action:** Initialize a fresh `PositionManager`.
        *   **Assert:** `get_position(symbol)` returns `None`. `get_all_positions()` returns `[]`. `has_open_position(symbol)` returns `False`.

3.  **Test `update_position_on_order_update` Logic:**
    *   **Test Case:** Entry order FILLED.
        *   **Action:** Add a `Position` with `entry_order_id="E1"`. Create an `Order` object for order "E1" with `status=OrderStatus.FILLED` and a specific `avg_fill_price`. Call `await position_manager.update_position_on_order_update(order)`.
        *   **Assert:** The position should still exist. Verify `position.entry_price` is updated to the `avg_fill_price` from the order. Verify `position.quantity` is updated if `filled_quantity` is present in the order.
    *   **Test Case:** Stop Loss order FILLED.
        *   **Action:** Add a `Position` with `sl_order_id="S1"`. Create an `Order` object for order "S1" with `status=OrderStatus.FILLED`. Call `update_position_on_order_update`.
        *   **Assert:** The position for that symbol should be removed (`get_position` returns `None`).
    *   **Test Case:** Take Profit order FILLED.
        *   **Action:** Add a `Position` with `tp_order_id="T1"`. Create an `Order` object for order "T1" with `status=OrderStatus.FILLED`. Call `update_position_on_order_update`.
        *   **Assert:** The position for that symbol should be removed.
    *   **Test Case:** Entry order CANCELED.
        *   **Action:** Add a `Position` with `entry_order_id="E1"`. Create an `Order` object for order "E1" with `status=OrderStatus.CANCELED`. Call `update_position_on_order_update`.
        *   **Assert:** The position for that symbol should be removed.
    *   **Test Case:** SL order CANCELED.
        *   **Action:** Add a `Position` with `sl_order_id="S1"`. Create an `Order` object for order "S1" with `status=OrderStatus.CANCELED`. Call `update_position_on_order_update`.
        *   **Assert:** The position should still exist, but `position.sl_order_id` should be set to `None`.
    *   **Test Case:** TP order CANCELED.
        *   **Action:** Add a `Position` with `tp_order_id="T1"`. Create an `Order` object for order "T1" with `status=OrderStatus.CANCELED`. Call `update_position_on_order_update`.
        *   **Assert:** The position should still exist, but `position.tp_order_id` should be set to `None`.
    *   **Test Case:** Order REJECTED (e.g., SL order).
        *   **Action:** Add a `Position` with `sl_order_id="S1"`. Create an `Order` object for "S1" with `status=OrderStatus.REJECTED`. Call `update_position_on_order_update`.
        *   **Assert:** Position exists, `position.sl_order_id` is `None`.
    *   **Test Case:** Order update for an unrelated order ID.
        *   **Action:** Add a `Position` with specific order IDs. Create an `Order` object with a different `order_id`. Call `update_position_on_order_update`.
        *   **Assert:** The position state should remain unchanged.
    *   **Test Case:** Order update for a symbol with no tracked position.
        *   **Action:** Ensure no position exists for "XYZUSDT". Create an `Order` for "XYZUSDT". Call `update_position_on_order_update`.
        *   **Assert:** No error occurs, internal state remains unchanged.

4.  **Test `reconcile_positions_with_exchange` Logic:**
    *   **Setup:** Create a mock `rest_client` using `unittest.mock.AsyncMock`. Mock its `fetch_positions` method.
    *   **Test Case:** Sync positions from exchange to empty manager.
        *   **Action:** Mock `fetch_positions` to return a list of position dictionaries (simulating ccxt response). Call `await position_manager.reconcile_positions_with_exchange(mock_rest_client)`.
        *   **Assert:** Verify internal `_positions` dict contains `Position` objects corresponding to the data returned by `fetch_positions`. Check key fields like `symbol`, `side`, `quantity`, `entry_price`.
    *   **Test Case:** Remove stale positions from manager not present on exchange.
        *   **Action:** Add a position manually to the manager (e.g., "STALEUSDT"). Mock `fetch_positions` to return an empty list or a list *without* "STALEUSDT". Call `reconcile_positions_with_exchange`.
        *   **Assert:** Verify the "STALEUSDT" position is removed from the manager.
    *   **Test Case:** Update existing positions in manager based on exchange data.
        *   **Action:** Add a position for "BTCUSDT" to the manager with quantity 0.01. Mock `fetch_positions` to return "BTCUSDT" data with quantity 0.05. Call `reconcile_positions_with_exchange`.
        *   **Assert:** Verify the "BTCUSDT" position in the manager now reflects the data from `fetch_positions` (quantity 0.05).
    *   **Test Case:** Handle exchange position with zero quantity.
        *   **Action:** Add a position for "ETHUSDT". Mock `fetch_positions` to return data for "ETHUSDT" but with quantity/contracts = 0. Call `reconcile_positions_with_exchange`.
        *   **Assert:** Verify the "ETHUSDT" position is removed from the manager.
    *   **Test Case:** Handle errors during `fetch_positions`.
        *   **Action:** Mock `fetch_positions` to return `None` or raise an exception. Call `reconcile_positions_with_exchange`.
        *   **Assert:** Verify internal state is unchanged and an error is logged.

5.  **Test Thread Safety (Conceptual):**
    *   **Test Case:** Verify lock object existence and type.
        *   **Assert:** Check `position_manager._lock` exists and is an instance of `threading.RLock`. (Direct testing of locking behavior is hard in unit tests but verifies setup).

**Acceptance Criteria:**
*   All test cases described above pass.
*   Test coverage for `src/position_manager.py` is significantly increased.
*   Tests verify adding, updating, retrieving, and removing positions.
*   Tests confirm correct state changes based on simulated `Order` updates for various statuses (FILLED, CANCELED, REJECTED).
*   Reconciliation logic correctly syncs internal state with mocked exchange data.
*   Basic thread safety setup is confirmed.


================================================
FILE: dev_tasks_docs/dev_plan_step_009.md
================================================
# Development Plan: Step 009 - Refine Main Application Logic (`main.py`)

**Task:** Step 009 - Review and refine the main application logic and orchestration in `src/main.py`. While the basic structure exists, ensure robustness, proper asynchronous handling, and clear data flow management.

**Objective:** Solidify the main application entry point (`TradingBot` class), ensuring all components are initialized correctly, data flows smoothly between them (especially WebSocket -> DataProcessor -> SignalEngine -> OrderManager), configuration updates are handled appropriately by the main application if needed, and graceful startup/shutdown procedures are robust.

**Target File(s):**
*   `src/main.py` (Primary file to review/modify)

**Context:**
*   `src/main.py` defines the `TradingBot` class orchestrating other modules.
*   It initializes `ConfigManager`, `BinanceRESTClient`, `PositionManager`, `OrderManager`, `DataProcessor`, `BinanceWebSocketConnector`, and `SignalEngineV1`.
*   It defines `_handle_kline_data` as the callback for the WebSocket connector, which processes klines and triggers signal checks.
*   It includes basic startup (`start`) and shutdown (`stop`) logic using `asyncio`.
*   It registers a callback (`_handle_app_config_update`) for config changes.
*   A placeholder `_periodic_tasks` method exists but isn't used in the primary event-driven flow.

**Detailed Plan:**

1.  **Review Initialization (`__init__`):**
    *   **Action:** Verify the order of initialization makes sense (e.g., `ConfigManager` first).
    *   **Action:** Confirm all necessary dependencies are passed correctly between components (e.g., `rest_client` to `OrderManager`).
    *   **Action:** Check if `PositionManager` needs to be passed to `OrderManager` or if position updates should be handled via events/callbacks routed through `main.py`. *Decision: For MVP, keep it simple. Assume `OrderManager` might eventually update `PositionManager`, or rely on `update_position_on_order_update` driven by user data stream later. No immediate changes needed unless a direct link is required now.*
    *   **Action:** Ensure logging is configured early based on the loaded config.

2.  **Review Kline Handling (`_handle_kline_data`):**
    *   **Action:** Verify robust error handling within the callback. What happens if `data_processor.process_kline` or `signal_engine.check_signal` raises an exception? Ensure exceptions are caught and logged without crashing the main loop or the WebSocket connection handler.
        *   *Refinement:* Wrap calls to `process_kline` and `check_signal` / `handle_trade_signal` in `try...except` blocks, logging errors appropriately.
    *   **Action:** Confirm the logic for triggering `signal_engine.check_signal` is correct (e.g., only on closed 1-minute candles for V1).
    *   **Action:** Double-check the mapping from API symbol (e.g., "BTCUSDT") back to the `config_symbol` (e.g., "BTC_USDT") needed for `signal_engine.check_signal`.
    *   **Action:** Re-evaluate the check `if not self.position_manager.has_open_position(kline.symbol):` before calling `check_signal`. Is this sufficient? Should it check the *intended direction* vs. existing position? *Decision: For V1 (no hedge mode), checking if *any* position exists for the symbol is a reasonable simplification to prevent conflicting signals on the same pair.* Keep as is for MVP.
    *   **Action:** Review the flow after a signal is generated and `order_manager.handle_trade_signal` is called. How is the `PositionManager` updated? *Decision: Currently, there's no explicit update call in `main`. This relies on a future User Data Stream integration or manual reconciliation. Add a log message indicating a signal was passed to OrderManager, but position tracking update relies on other mechanisms.*

3.  **Review Startup Logic (`start`):**
    *   **Action:** Ensure `_handle_app_config_update` is called initially to set up active pairs.
    *   **Action:** Review the position reconciliation call. Is it necessary for MVP startup? *Decision: It's good practice. Keep the placeholder call `await self.position_manager.reconcile_positions_with_exchange(self.rest_client)` but ensure `rest_client` is correctly passed. Add logging around it.*
    *   **Action:** Verify WebSocket connector is started (`await self.ws_connector.start()`).
    *   **Action:** Review the main `while self.running: await asyncio.sleep(1)` loop. Is it necessary if all logic is event-driven via `_handle_kline_data`? *Decision: Yes, it keeps the main application alive to receive signals (like SIGTERM) and allows background tasks (like WebSocket handlers) to run. Keep it.*
    *   **Action:** Ensure comprehensive logging during startup phases.

4.  **Review Shutdown Logic (`stop`):**
    *   **Action:** Verify the order of stopping components (e.g., WebSocket connector before REST client, config watcher last).
    *   **Action:** Ensure all awaited stop methods (`ws_connector.stop`, `rest_client.close_exchange`, `config_manager.stop_watcher`) are actually called.
    *   **Action:** Add error handling around the `stop` calls in case a component fails to stop gracefully.
    *   **Action:** Ensure `self.running` flag is set to `False` early in the `stop` sequence.

5.  **Review Asynchronous Loop (`_periodic_tasks`):**
    *   **Action:** This task seems commented out or not actively used in the event-driven flow.
    *   *Decision:* Remove the unused `self.main_loop_task = asyncio.create_task(self._periodic_tasks())` line from `start` and the `_periodic_tasks` method itself if it's not required for the V1 event-driven strategy. This simplifies the main loop. If periodic checks (like reconciliation) are needed *during* runtime, this structure could be revived.

6.  **Review Configuration Handling (`_handle_app_config_update`):**
    *   **Action:** Confirm that changes relevant to `main.py` itself (like logging level, active pairs list) are handled correctly.
    *   **Action:** Ensure changes handled by other modules via their own callbacks (e.g., WebSocket subscriptions, DataProcessor buffers) don't need redundant handling here.

7.  **Review Signal Handling (`handle_sigterm`):**
    *   **Action:** Verify the logic correctly finds the running event loop and schedules the `bot_instance.stop()` coroutine.
    *   **Action:** Test the `loop.run_until_complete(bot_instance.stop())` approach. Does it block the signal handler? Is it safe? *Alternative:* A common pattern is to set `bot_instance.running = False` in the signal handler and let the main `while self.running:` loop break naturally, triggering the `finally` block where `stop()` is called. This is often cleaner.
        *   *Refinement:* Modify `handle_sigterm` to just set `bot_instance.running = False`. Ensure the main `try...finally` block in `main()` calls `await bot_instance.stop()` if `bot_instance` exists. Remove `run_until_complete` from the handler.

**Acceptance Criteria:**
*   `src/main.py` code is reviewed and potentially refactored for clarity and robustness.
*   Error handling in `_handle_kline_data` is implemented.
*   Startup and shutdown sequences are verified and logged clearly.
*   Signal handling (`handle_sigterm`) uses a non-blocking approach by setting the `running` flag.
*   Unnecessary code (like the unused `_periodic_tasks` loop) is removed.
*   Data flow between components within `main.py` is clear and logical.
*   Interaction with `PositionManager` post-signal handling is clarified (acknowledged as dependent on future steps for full automation).


================================================
FILE: dev_tasks_docs/dev_plan_step_010.md
================================================
# Development Plan: Step 010 - Add Unit Tests for `monitoring.py`

**Task:** Step 010 - Add unit tests for the basic Prometheus metrics exposure in `src/monitoring.py`.

**Objective:** Ensure the `PrometheusMonitor` class correctly initializes Prometheus metrics (Counters, Gauges, Enums, Info), updates their values via helper methods, and handles the start/stop logic conceptually (actual server start/stop is hard to unit test cleanly).

**Target File(s):**
*   `tests/unit/test_monitoring.py` (Primary file to create/modify)

**Context:**
*   `src/monitoring.py` defines the `PrometheusMonitor` class using the `prometheus_client` library.
*   It defines various metrics types (Counter, Gauge, Enum, Info).
*   It provides helper methods (e.g., `inc_bot_error`, `set_websocket_status`) to update metric values with labels.
*   The `start` method uses `prometheus_client.start_http_server`.
*   An async task `_update_uptime_periodically` is used for the uptime gauge.
*   Stopping the server relies on process exit as `prometheus_client` doesn't offer a clean stop function.

**Detailed Plan:**

1.  **Setup Test Fixtures:**
    *   Create a `pytest` fixture (`monitor`) that initializes `PrometheusMonitor` with a test port.
    *   Use `pytest.mark.asyncio` as `_update_uptime_periodically` is async.
    *   **Mocking `start_http_server`:** Since we don't want to start a real HTTP server during unit tests, patch `prometheus_client.start_http_server`.
        *   `@patch('src.monitoring.start_http_server')`

2.  **Test Initialization:**
    *   **Test Case:** Verify metric objects are created correctly.
        *   **Action:** Initialize `PrometheusMonitor`.
        *   **Assert:** Check that attributes like `monitor.bot_uptime_seconds`, `monitor.bot_errors_total`, `monitor.websocket_connection_status`, etc., exist and are instances of the correct `prometheus_client` metric types (Gauge, Counter, Enum).

3.  **Test Metric Update Methods:**
    *   **Test Case:** Update Counter metrics (`inc_` methods).
        *   **Action:** Call methods like `monitor.inc_bot_error("moduleA", "type1")`, `monitor.inc_kline_processed("BTCUSDT", "1m")`, etc. Call them multiple times with the same and different labels.
        *   **Assert:** Use `prometheus_client.REGISTRY.get_sample_value` to retrieve the current value of the counter for specific label combinations and verify they increment as expected.
            *   Example: `assert REGISTRY.get_sample_value('trading_bot_errors_total', {'module': 'moduleA', 'error_type': 'type1'}) == 1`
    *   **Test Case:** Update Gauge metrics (`set_` methods).
        *   **Action:** Call methods like `monitor.set_indicator_calculation_duration("ETHUSDT", "5m", 0.123)`, `monitor.set_active_positions_count("USDT_M", 5)`. Call again with different values.
        *   **Assert:** Use `REGISTRY.get_sample_value` to verify the gauge reflects the *last* set value for the given labels.
    *   **Test Case:** Update Enum metrics (`set_websocket_status`).
        *   **Action:** Call `monitor.set_websocket_status("USDT_M", "connected")`, then `monitor.set_websocket_status("USDT_M", "disconnected")`. Call with an invalid state.
        *   **Assert:** Use `REGISTRY.get_sample_value` for the Enum metric. Enums expose multiple gauges (`<metric_name>{<label>=<value>} == 1`). Verify the gauge corresponding to the *last valid state* is 1 and others are 0. Verify that setting an invalid state logs a warning and potentially sets an 'error' state if implemented.
            *   Example: `assert REGISTRY.get_sample_value('trading_bot_websocket_connection_status', {'market_type': 'USDT_M', 'trading_bot_websocket_connection_status': 'disconnected'}) == 1`
            *   `assert REGISTRY.get_sample_value('trading_bot_websocket_connection_status', {'market_type': 'USDT_M', 'trading_bot_websocket_connection_status': 'connected'}) == 0`
    *   **Test Case:** Update Info metric (`bot_info`).
        *   **Action:** Call `monitor.start()` (with `start_http_server` mocked). The `info` metric is set within `start`.
        *   **Assert:** Use `REGISTRY.get_sample_value('trading_bot_info_info')` to check the labels set (version, name).

4.  **Test Start/Stop Logic (Conceptual):**
    *   **Test Case:** `start` calls `start_http_server` and sets info.
        *   **Action:** Call `monitor.start()` with `start_http_server` patched.
        *   **Assert:** Verify the mocked `start_http_server` was called once with the correct port. Verify the `bot_info` metric was populated. Verify `monitor._server_started` is `True`.
    *   **Test Case:** `start` handles `OSError` if server start fails.
        *   **Action:** Configure the patched `start_http_server` to raise `OSError`. Call `monitor.start()`.
        *   **Assert:** Verify an error is logged and `monitor._server_started` remains `False`.
    *   **Test Case:** `_update_uptime_periodically` updates the uptime gauge.
        *   **Action:** Call `monitor.start()`. Wait briefly using `asyncio.sleep`.
        *   **Assert:** Get the value of `trading_bot_uptime_seconds` using `REGISTRY.get_sample_value`. Verify it's a small positive number. Wait again, verify the value increases. (This requires careful handling of the async task lifecycle in tests, potentially mocking `asyncio.create_task` or running the loop briefly). *Alternative:* Test the update logic directly by calling the method once manually.
    *   **Test Case:** `stop` method (conceptual check).
        *   **Action:** Call `monitor.start()`, then `monitor.stop()`.
        *   **Assert:** Verify `monitor._server_started` is set to `False`. Verify a log message indicates shutdown. (Actual server stop cannot be tested here).

5.  **Cleanup:**
    *   **Action:** Ensure Prometheus registry is cleared between tests if necessary, although `get_sample_value` usually works on the current state. Using separate processes or carefully managing the global registry might be needed if tests interfere. For basic unit tests, checking values immediately after setting them should be sufficient. *Consider using `prometheus_client.REGISTRY.clear()` in test setup/teardown if interference occurs.*

**Acceptance Criteria:**
*   All test cases described above pass.
*   Test coverage for `src/monitoring.py` is significantly increased.
*   Tests verify the correct initialization and update of different Prometheus metric types (Counter, Gauge, Enum, Info) via the helper methods.
*   Labels are correctly applied and verified in assertions.
*   Conceptual testing of `start` and `stop` logic confirms expected behavior (mocked server start, flag setting).
*   Tests use mocked dependencies (`start_http_server`).


================================================
FILE: dev_tasks_docs/dev_plan_step_013.md
================================================
# Development Plan: Step 013 - Validate End-to-End Functionality on Testnet

**Task:** Step 013 - Configure and run the bot on the Binance Futures Testnet to validate end-to-end functionality of the V1 Strategy MVP.

**Objective:** Verify that the integrated system works correctly in a simulated live environment, including WebSocket data reception, indicator calculation, signal generation, order placement (Entry, SL, TP), position tracking (manual observation), logging, and basic monitoring. Identify and document any bugs or discrepancies.

**Target File(s):**
*   `config/config.yaml` (To be configured for Testnet)
*   Bot logs (output during Testnet run)
*   (Potentially) `docs/TROUBLESHOOTING.md` (To update with findings)

**Context:**
*   All core modules have initial implementations and unit/integration tests.
*   The bot is designed to run via `python -m src.main`.
*   Configuration is handled via `config/config.yaml`.
*   The bot supports connecting to Testnet via the `api.testnet: true` flag.
*   Requires Binance Futures Testnet API Keys.

**Prerequisites:**
*   User must obtain API Key and Secret from the [Binance Futures Testnet website](https://testnet.binancefuture.com/).
*   Testnet account needs sufficient test funds (usually provided automatically or via a faucet on the Testnet site).

**Detailed Plan:**

1.  **Configure for Testnet:**
    *   **Action:** Copy `config/config.yaml.example` to `config/config.yaml`.
    *   **Action:** Edit `config/config.yaml`:
        *   Enter the obtained **Testnet** API Key and Secret under the `api` section.
        *   Add or set `testnet: true` under the `api` section.
        *   Enable at least one or two **USDT-M perpetual** pairs commonly available on Testnet (e.g., `BTC_USDT`, `ETH_USDT`) under the `pairs` section. Set `enabled: true`.
        *   Configure `leverage` and `margin_usdt` for the chosen pairs to reasonable test values (e.g., 5x leverage, 50 USDT margin). Ensure the margin is small relative to available Testnet funds.
        *   Set `global_settings.v1_strategy.min_signal_interval_minutes` to a low value (e.g., 1 or 5) for faster testing, but be aware this might increase noise.
        *   Set `logging.level` to `INFO` or `DEBUG` for detailed observation.
        *   Ensure `monitoring.prometheus_port` is set if monitoring is desired.
    *   **Action:** Verify Python environment has all dependencies installed from `requirements.txt`.

2.  **Run the Bot:**
    *   **Action:** Open a terminal in the project's root directory.
    *   **Action:** Execute the bot: `python -m src.main`
    *   **Action:** Monitor the console output / log file (`logs/bot.log` if configured) for startup messages, connection status, and errors.

3.  **Monitor Bot Behavior & Verify Functionality:**
    *   **Verification:** **WebSocket Connection & Data:**
        *   Check logs for successful connection messages to the *Testnet* WebSocket endpoints (e.g., `stream.binancefuture.com`).
        *   Check logs for confirmation of subscriptions to the kline streams for the enabled pairs/timeframes (e.g., `btcusdt@kline_1m`).
        *   Observe if kline data appears to be processing (debug logs might show this, or inferred if signals occur).
    *   **Verification:** **Indicator Calculation:**
        *   (Difficult to verify directly without DEBUG logs showing calculated SMAs). Infer correctness if sensible signals are generated based on visible chart patterns on the Testnet trading interface.
    *   **Verification:** **Signal Generation (V1 SMA Crossover):**
        *   Observe the Testnet chart for the enabled pair(s) on the 1-minute timeframe.
        *   Watch for potential SMA 21 / SMA 200 crossovers.
        *   Check bot logs for messages indicating a "Signal generated" (LONG or SHORT) when a crossover appears to occur on the chart. Note the signal details logged (entry, SL, TP).
    *   **Verification:** **Order Placement:**
        *   When a signal is logged, check the logs for messages indicating "Placing entry order", "Placing SL order", "Placing TP order".
        *   Log in to the Binance Futures Testnet web interface.
        *   Check the "Open Orders" tab for the corresponding pair. Verify that a MARKET order executed (check Trade History), and that corresponding STOP_MARKET (SL) and TAKE_PROFIT_MARKET (TP) orders were created with `reduceOnly` flag set and prices matching (or very close due to precision) the logged SL/TP values.
        *   Verify the quantities match the expected calculated size based on config (margin * leverage / entry).
    *   **Verification:** **Position Tracking (Manual):**
        *   After the entry order fills, check the "Positions" tab on the Testnet interface.
        *   Verify a position exists for the pair with the correct side (Long/Short), entry price, and quantity.
        *   Observe if the position closes when price hits the SL or TP level (check trade history and open orders again). *Note: Automated position tracking within the bot via `PositionManager` relies heavily on User Data Stream (not in MVP) or reconciliation, so internal state might lag the exchange.*
    *   **Verification:** **Logging:**
        *   Review the log output for clarity, appropriate levels (INFO/DEBUG), and useful information regarding bot status, signals, orders, and potential errors.
    *   **Verification:** **Monitoring (Optional):**
        *   If monitoring is enabled, access the Prometheus endpoint (`http://localhost:PORT/metrics`).
        *   Check if metrics like uptime, WebSocket status, klines processed, signals generated, orders placed are updating.

4.  **Identify and Document Issues:**
    *   **Action:** Keep detailed notes of any unexpected behavior, errors in logs, discrepancies between bot actions and Testnet interface state, or crashes.
    *   **Action:** Note specific conditions or sequences of events that trigger issues.
    *   **Action:** If issues are found, attempt to reproduce them.
    *   **Action:** Update `docs/TROUBLESHOOTING.md` with common problems encountered and their solutions/workarounds found during Testnet.

5.  **Refine and Debug (Iterative):**
    *   **Action:** Based on findings, stop the bot (`Ctrl+C`).
    *   **Action:** Modify the code (`src/...`) to fix identified bugs.
    *   **Action:** Restart the bot and re-verify the specific functionality that failed previously.
    *   **Action:** Repeat the monitoring and verification process until the core V1 strategy flow operates reliably on Testnet.

**Acceptance Criteria:**
*   The bot successfully connects to the Binance Futures Testnet WebSocket and REST APIs using provided testnet credentials.
*   Kline data is received and processed for configured pairs.
*   The bot generates V1 SMA crossover signals (both LONG and SHORT) based on observed chart patterns on Testnet.
*   Upon signal generation, the bot successfully places MARKET entry orders and corresponding STOP_MARKET (SL) / TAKE_PROFIT_MARKET (TP) orders with `reduceOnly=true` on the Testnet exchange.
*   Order details (prices, quantities) on Testnet match the bot's calculations and logs (considering precision adjustments).
*   The bot runs stably for a reasonable test period (e.g., several hours) without crashing.
*   Logs provide clear information about the bot's state and actions.
*   Any critical bugs identified during Testnet validation are fixed.


================================================
FILE: docs/ARCHITECTURE.md
================================================
# Architecture Overview

This document provides an overview of the system architecture for the Binance Futures Trading Bot. The bot is designed with a modular approach to ensure separation of concerns, testability, and extensibility.

## Core Principles

- **Modularity**: Each major function (data ingestion, signal generation, order execution, etc.) is handled by a distinct module.
- **Asynchronous Operations**: Leverages `asyncio` for efficient handling of I/O-bound tasks like network requests and WebSocket communication.
- **Configurability**: Most operational parameters are externalized to a YAML configuration file, supporting hot-reloading.
- **Event-Driven**: The bot primarily reacts to real-time market events (k-line updates) and internal signals.
- **Testability**: Modules are designed to be unit-testable, with dependencies injectable or mockable.

## System Components

The following diagram illustrates the high-level interaction between the core components:

```mermaid
graph TD
    subgraph User_Interaction
        ConfigFile[config.yaml]
    end

    subgraph Bot_Core_Application
        MainApp[Main Application (main.py)]
        ConfigMgr[ConfigManager (config_loader.py)]
        Scheduler[Async Event Loop]
    end

    subgraph Data_Pipeline
        BinanceWS[Binance WebSocket API]
        WSConnector[WebSocketConnector (connectors.py)]
        DataProcessor[DataProcessor (data_processor.py)]
    end

    subgraph Trading_Logic
        SignalEngine[SignalEngineV1 (signal_engine.py)]
        OrderManager[OrderManager (order_manager.py)]
        PositionManager[PositionManager (position_manager.py)]
    end

    subgraph External_Services
        BinanceREST[Binance REST API]
        RESTClient[RESTClient (connectors.py)]
    end

    subgraph Monitoring_System
        Prometheus[Prometheus Server]
        Metrics[PrometheusMonitor (monitoring.py)]
    end

    ConfigFile --> ConfigMgr
    ConfigMgr --> MainApp
    ConfigMgr --> WSConnector
    ConfigMgr --> DataProcessor
    ConfigMgr --> SignalEngine
    ConfigMgr --> OrderManager
    ConfigMgr --> PositionManager
    ConfigMgr --> RESTClient
    ConfigMgr --> Metrics

    MainApp -- Manages/Orchestrates --> WSConnector
    MainApp -- Manages/Orchestrates --> DataProcessor
    MainApp -- Manages/Orchestrates --> SignalEngine
    MainApp -- Manages/Orchestrates --> OrderManager
    MainApp -- Manages/Orchestrates --> PositionManager
    MainApp -- Manages/Orchestrates --> RESTClient
    MainApp -- Manages/Orchestrates --> Metrics
    MainApp -- Uses --> Scheduler

    BinanceWS -- Streams Data --> WSConnector
    WSConnector -- Raw Kline Data --> MainApp
    MainApp -- Kline Data --> DataProcessor
    DataProcessor -- Indicator Data --> SignalEngine
    SignalEngine -- Trade Signals --> MainApp
    MainApp -- Trade Signals --> OrderManager
    
    OrderManager -- Executes Orders via --> RESTClient
    RESTClient -- Interacts with --> BinanceREST
    PositionManager -- Tracks Positions --> MainApp # Position updates can come from OrderManager or UserDataStream
    OrderManager -- Updates --> PositionManager # After successful order execution

    Metrics -- Exposes Data to --> Prometheus
```

### 1. Main Application (`src/main.py`)
- **Responsibilities**: 
    - Initializes and orchestrates all other modules.
    - Manages the main asynchronous event loop.
    - Handles startup, graceful shutdown, and signal handling (SIGINT, SIGTERM).
    - Routes data between components (e.g., k-line data from WebSocket connector to Data Processor, signals from Signal Engine to Order Manager).
    - Responds to configuration changes detected by the `ConfigManager`.

### 2. Configuration Manager (`src/config_loader.py`)
- **Responsibilities**:
    - Loads trading parameters, API keys, and other settings from `config/config.yaml`.
    - Provides access to configuration values for all other modules.
    - Implements hot-reloading: monitors the configuration file for changes and notifies registered callbacks in other modules to apply updates dynamically.
    - Handles creation of default `config.yaml` from `config.yaml.example` if it doesn_t exist.

### 3. Connectors (`src/connectors.py`)
   Contains modules for interacting with Binance APIs.
   - **`BinanceWebSocketConnector`**:
     - Establishes and maintains WebSocket connections to Binance Futures for real-time market data (k-lines, potentially order book depth, user data streams in future).
     - Subscribes to streams for configured trading pairs and timeframes.
     - Parses incoming JSON messages into structured `Kline` objects (defined in `src/models.py`).
     - Passes `Kline` data to the Main Application via a callback for further processing.
     - Handles connection management, automatic reconnections, and subscription updates on configuration changes.
   - **`BinanceRESTClient`**:
     - Interacts with the Binance Futures REST API for actions like placing orders, fetching account balance, getting open positions, setting leverage/margin mode, and retrieving exchange information (symbol precision, limits).
     - Uses the `ccxt` library for standardized API interaction.
     - Manages API authentication (API key and secret).
     - Implements retry logic for transient API errors (using `tenacity`).
     - Provides a simulation mode if API keys are not configured or are placeholders, allowing basic testing without live trading.

### 4. Data Models (`src/models.py`)
- **Responsibilities**:
    - Defines Pydantic data models for structured representation of various entities used throughout the application. This ensures data consistency and provides validation.
    - Key models include:
        - `Kline`: Represents a single k-line/candlestick data point.
        - `PairConfig`: Represents configuration for a specific trading pair.
        - `TradeSignal`: Represents a trading signal generated by the strategy engine.
        - `Order`: Represents a trading order (entry, SL, TP).
        - `Position`: Represents an open trading position.
        - Enums for `TradeDirection`, `OrderStatus`, `OrderType`, `OrderSide`, etc.

### 5. Data Processor (`src/data_processor.py`)
- **Responsibilities**:
    - Receives raw `Kline` objects from the Main Application (originating from the `WebSocketConnector`).
    - Maintains rolling buffers (e.g., `collections.deque` of `Kline` objects) for each active trading pair and timeframe.
    - Calculates technical indicators (e.g., SMAs for V1 strategy) based on the k-line data in the buffers.
    - Stores calculated indicators, typically in a Pandas DataFrame associated with each pair/timeframe buffer for easy access and analysis.
    - Provides methods for other modules (like `SignalEngine`) to retrieve the latest k-line data and calculated indicators.
    - Updates its internal state and buffers based on configuration changes (e.g., new pairs enabled, indicator timeframes changed).

### 6. Signal Engine (`src/signal_engine.py`)
- **Responsibilities**:
    - Implements the trading strategy logic (e.g., V1 SMA Crossover).
    - Uses data provided by the `DataProcessor` (k-lines and indicators) to identify potential trading opportunities.
    - When a trading condition is met (e.g., SMA crossover), it generates a `TradeSignal` object.
    - Includes logic for signal filtering, such as minimum interval between signals for the same pair, and buffer time for crossover confirmation.
    - Calculates initial stop-loss (SL) and take-profit (TP) levels for the generated signal based on strategy rules (e.g., recent pivot lows/highs for SL, fixed R:R ratio for TP).
    - Passes the `TradeSignal` to the Main Application for execution.

### 7. Order Manager (`src/order_manager.py`)
- **Responsibilities**:
    - Receives `TradeSignal` objects from the Main Application.
    - Determines position size based on configured margin (fixed USDT amount for USDT-M, fixed coin amount for COIN-M in MVP) and leverage.
    - Fetches symbol-specific trading rules (precision for price/quantity, minimum notional value) from `BinanceRESTClient` to ensure orders are valid.
    - Constructs and places market entry orders, and associated stop-market SL and take-profit-market TP orders (with `reduceOnly=true`) via the `BinanceRESTClient`.
    - Sets margin type (ISOLATED/CROSSED) and leverage for the pair before placing trades if necessary.
    - Handles specifics for USDT-M and COIN-M contracts.
    - Logs order placement details and outcomes.
    - (Future Enhancement) Could interact with `PositionManager` to update position state after orders are confirmed.

### 8. Position Manager (`src/position_manager.py`)
- **Responsibilities**:
    - Tracks currently open trading positions managed by the bot.
    - Stores details for each position: symbol, side (LONG/SHORT), entry price, quantity, entry/SL/TP order IDs, unrealized PnL, etc.
    - Updates position status based on order fill events (e.g., entry filled, SL/TP hit, manual close). This is crucial and would typically be driven by a user data WebSocket stream or polling order statuses.
    - Provides methods to query current open positions.
    - (Future Enhancement) Handles reconciliation of positions with the exchange on startup or periodically.
    - (Future Enhancement) Manages trailing stops or other dynamic exit strategies.

### 9. Monitoring (`src/monitoring.py`)
- **Responsibilities**:
    - Implements a Prometheus metrics exporter.
    - Exposes key operational metrics such as:
        - Bot uptime, error counts.
        - WebSocket connection status, messages received.
        - K-lines processed, indicator calculation times.
        - Signals generated, orders placed/filled/failed.
        - Active position counts, PnL (if available).
    - Starts an HTTP server on a configurable port to serve the `/metrics` endpoint for Prometheus to scrape.

## Data Flow Example (V1 SMA Crossover Strategy)

1. **Configuration**: `ConfigManager` loads `config.yaml`.
2. **Initialization**: `MainApp` initializes all components using the loaded configuration.
3. **WebSocket Connection**: `WebSocketConnector` connects to Binance and subscribes to k-line streams for enabled pairs (e.g., BTCUSDT 1m, 5m, etc.).
4. **Kline Reception**: `WebSocketConnector` receives a k-line update, parses it into a `Kline` object, and passes it to `MainApp`.
5. **Data Processing**: `MainApp` forwards the `Kline` to `DataProcessor`.
   - `DataProcessor` appends the k-line to the relevant buffer (e.g., BTCUSDT, 1m).
   - It then recalculates indicators (e.g., 21 SMA, 200 SMA) for that buffer and updates its internal DataFrame.
6. **Signal Check**: If the k-line is closed (for 1m timeframe as per V1 strategy):
   - `MainApp` (or a callback mechanism) triggers `SignalEngineV1` to check for signals on BTCUSDT.
   - `SignalEngineV1` requests the latest indicator DataFrame for BTCUSDT 1m from `DataProcessor`.
   - It checks for SMA crossover conditions (e.g., 21 SMA crosses above 200 SMA).
   - If a crossover is confirmed (and passes filters like `min_signal_interval_minutes` and `buffer_time_candles`):
     - It calculates SL (e.g., recent low) and TP (e.g., entry + (entry-SL) * R:R).
     - It creates a `TradeSignal` object (e.g., LONG BTCUSDT).
     - It returns the `TradeSignal` to `MainApp`.
7. **Order Execution**: `MainApp` receives the `TradeSignal` and passes it to `OrderManager`.
   - `OrderManager` determines position size (e.g., 100 USDT margin, 10x leverage for BTCUSDT).
   - It fetches BTCUSDT trading rules (precision, min notional) from `RESTClient` (cached if possible).
   - It adjusts quantity and prices to meet precision requirements.
   - It calls `RESTClient` to:
     - Set leverage and margin mode for BTCUSDT (if not already set or changed).
     - Place a MARKET BUY order (entry).
     - Place a STOP_MARKET SELL order (SL) with `reduceOnly=true`.
     - Place a TAKE_PROFIT_MARKET SELL order (TP) with `reduceOnly=true`.
8. **Position Tracking**: 
   - `OrderManager` (or `MainApp` upon order confirmation) informs `PositionManager` about the new potential position, including the order IDs for entry, SL, and TP.
   - `PositionManager` creates a new `Position` entry.
   - (Ideally, a User Data Stream via `WebSocketConnector` would provide real-time order fill updates, which would then be routed to `PositionManager` to confirm the position is active or closed).
9. **Monitoring**: Throughout this process, modules update metrics via `PrometheusMonitor` (e.g., k-lines processed, signals generated, orders placed).

## Future Enhancements Considerations

- **User Data Stream**: Integrate a user data WebSocket stream for real-time updates on order fills, account balance changes, and position updates. This would make position management more robust and reactive.
- **Database Integration**: For persistent storage of trades, historical performance, and potentially k-line data for backtesting.
- **Advanced Strategies**: The modular design allows for new strategy engines to be developed and plugged in.
- **Web UI/Dashboard**: A user interface for monitoring the bot, managing settings, and viewing performance.
- **Backtesting Engine**: To test strategies on historical data before live deployment.

This architecture provides a solid foundation for a reliable and extensible trading bot.



================================================
FILE: docs/CONFIGURATION_GUIDE.md
================================================
# Configuration Guide

This document provides a detailed explanation of all options available in the `config/config.yaml` file for the Binance Futures Trading Bot.

## Root Level Configuration

```yaml
api:
  # ... see API section
global_settings:
  # ... see Global Settings section
pairs:
  # ... see Pairs section
logging:
  # ... see Logging section
monitoring:
  # ... see Monitoring section
```

## 1. API Configuration (`api`)

This section contains your Binance API credentials.

```yaml
api:
  binance_api_key: "YOUR_BINANCE_API_KEY"    # Your Binance API Key
  binance_api_secret: "YOUR_BINANCE_API_SECRET" # Your Binance API Secret
  # testnet: false # Optional: Set to true to use Binance Testnet. Default is false (mainnet).
```

- **`binance_api_key`**: (Required) Your public API key from Binance. Ensure API restrictions are set appropriately (e.g., enable Futures trading, disable withdrawals if not needed by other tools).
- **`binance_api_secret`**: (Required) Your secret API key from Binance. Keep this confidential.
- **`testnet`**: (Optional) Boolean. If set to `true`, the bot will connect to the Binance Futures Testnet. If `false` or omitted, it connects to the mainnet. It is highly recommended to test thoroughly on testnet before trading with real funds.

## 2. Global Settings (`global_settings`)

These settings apply to all trading pairs unless overridden in the specific pair's configuration.

```yaml
global_settings:
  v1_strategy: # Settings specific to the V1 SMA Crossover strategy
    sma_short_period: 21
    sma_long_period: 200
    min_signal_interval_minutes: 60
    tp_sl_ratio: 2.0
    default_margin_usdt: 50.0
    default_leverage: 10
    margin_mode: "ISOLATED" # or "CROSSED"
    indicator_timeframes: ["1m", "5m", "15m", "1h", "4h"]
    # buffer_time_candles: 3 # Optional: Number of candles for buffer time after crossover
    # pivot_lookback_candles: 30 # Optional: Lookback period for SL pivot calculation

  risk_management:
    # dynamic_sizing_enabled: false # Optional: Enable dynamic position sizing (e.g., % of balance)
    # max_account_risk_per_trade_pct: 1.0 # Optional: If dynamic sizing, max % of account to risk
    # max_concurrent_trades: 5 # Optional: Limit on total concurrent open positions
```

### 2.1. V1 Strategy (`v1_strategy`)

Parameters for the default SMA (Simple Moving Average) crossover strategy.

- **`sma_short_period`**: Integer. The period for the shorter SMA (e.g., 21).
- **`sma_long_period`**: Integer. The period for the longer SMA (e.g., 200).
- **`min_signal_interval_minutes`**: Integer. Minimum time in minutes to wait between generating new signals for the *same trading pair* to avoid over-trading. Set to `0` to disable this wait.
- **`tp_sl_ratio`**: Float. The Take Profit to Stop Loss ratio (Risk/Reward Ratio). For example, `2.0` means the Take Profit distance will be twice the Stop Loss distance from the entry price.
- **`default_margin_usdt`**: Float. For USDT-M pairs, the default amount of USDT to allocate as margin for a new trade if not specified per pair. This is used for fixed margin position sizing.
- **`default_leverage`**: Integer. The default leverage to use for new trades if not specified per pair (e.g., 10 for 10x leverage).
- **`margin_mode`**: String. The margin mode to use: `"ISOLATED"` or `"CROSSED"`. It is generally recommended to use `"ISOLATED"` for better risk control per position.
- **`indicator_timeframes`**: List of strings. The k-line timeframes the bot should subscribe to and use for calculating indicators for each pair. Examples: `["1m", "5m", "15m", "1h", "4h"]`. The V1 strategy primarily uses the `1m` timeframe for signal generation based on the provided documents, but other timeframes are fetched for potential future strategy enhancements or multi-timeframe analysis.
- **`buffer_time_candles`**: (Optional) Integer. Number of candles the crossover condition must persist before a signal is considered valid. This helps filter out false signals during choppy markets. (As per "Binance Futures Trading Bot Strategy Improvements (2).txt")
- **`pivot_lookback_candles`**: (Optional) Integer. The lookback period (number of candles) used to determine recent pivot highs/lows for stop-loss placement. (As per "Binance Futures Trading Bot Strategy Improvements (2).txt")

### 2.2. Risk Management (`risk_management`)

Global risk parameters (some are placeholders for future enhancements).

- **`dynamic_sizing_enabled`**: (Optional) Boolean. If `true`, enables dynamic position sizing (e.g., risking a fixed percentage of account balance per trade). If `false` (default), uses fixed margin allocation (`default_margin_usdt` or pair-specific `margin_usdt`). *MVP focuses on fixed margin.*
- **`max_account_risk_per_trade_pct`**: (Optional) Float. If `dynamic_sizing_enabled` is `true`, this is the maximum percentage of the total account balance to risk on a single trade (e.g., `1.0` for 1%).
- **`max_concurrent_trades`**: (Optional) Integer. The maximum number of trades the bot can have open simultaneously across all pairs.

## 3. Pairs Configuration (`pairs`)

This section defines the specific trading pairs the bot will monitor and trade. You can list multiple pairs.

```yaml
pairs:
  BTC_USDT: # User-defined name for the pair, used internally
    enabled: true
    contract_type: "USDT_M" # "USDT_M" or "COIN_M"
    leverage: 20 # Optional: Overrides global_settings.v1_strategy.default_leverage
    margin_usdt: 100.0 # Optional: For USDT_M, overrides global_settings.v1_strategy.default_margin_usdt
    # margin_coin: 0.01 # Optional: For COIN_M, amount of base coin for margin (e.g., 0.01 BTC for BTCUSD_PERP)
    # indicator_timeframes: ["1m", "15m"] # Optional: Overrides global_settings.v1_strategy.indicator_timeframes for this pair
    # min_signal_interval_minutes: 30 # Optional: Overrides global setting for this pair
    # tp_sl_ratio: 1.5 # Optional: Overrides global setting for this pair

  ETH_USDT:
    enabled: true
    contract_type: "USDT_M"
    # Uses global settings for leverage, margin_usdt, etc.

  BTCUSD_PERP: # Example for a COIN-M contract
    enabled: false # This pair is currently disabled
    contract_type: "COIN_M"
    leverage: 5
    margin_coin: 0.002 # e.g., 0.002 BTC for this contract
```

For each pair (e.g., `BTC_USDT`, `ETHUSD_PERP`): 
- The key (e.g., `BTC_USDT`) is a user-defined identifier. The bot will convert this to the format Binance API expects (e.g., `BTCUSDT` or `BTCUSD_PERP`).
  - For USDT-margined perpetuals, use the format `BASE_QUOTE` (e.g., `BTC_USDT`).
  - For COIN-margined perpetuals, use the format `BASEUSD_PERP` (e.g., `BTCUSD_PERP`).
- **`enabled`**: Boolean. If `true`, the bot will actively trade this pair. If `false`, it will be ignored.
- **`contract_type`**: String. Specifies the type of futures contract:
    - `"USDT_M"`: For USDT-margined contracts (e.g., BTC/USDT, ETH/USDT).
    - `"COIN_M"`: For COIN-margined contracts (e.g., BTC/USD, ETH/USD perpetuals).
- **`leverage`**: (Optional) Integer. Pair-specific leverage. Overrides `global_settings.v1_strategy.default_leverage`.
- **`margin_usdt`**: (Optional) Float. For `USDT_M` contracts, the amount of USDT to use as margin for trades on this specific pair. Overrides `global_settings.v1_strategy.default_margin_usdt`.
- **`margin_coin`**: (Optional) Float. For `COIN_M` contracts, the amount of the base coin (e.g., BTC for BTCUSD_PERP) to use as margin for trades on this specific pair. *Note: For COIN-M, position sizing is typically in terms of number of contracts. This `margin_coin` value might be interpreted as the number of contracts to trade for MVP if fixed sizing is used, or as the coin margin if the API supports that directly for sizing.*
- **`indicator_timeframes`**: (Optional) List of strings. Pair-specific k-line timeframes. Overrides `global_settings.v1_strategy.indicator_timeframes`.
- **`min_signal_interval_minutes`**: (Optional) Integer. Pair-specific minimum signal interval. Overrides `global_settings.v1_strategy.min_signal_interval_minutes`.
- **`tp_sl_ratio`**: (Optional) Float. Pair-specific Take Profit / Stop Loss ratio. Overrides `global_settings.v1_strategy.tp_sl_ratio`.

## 4. Logging Configuration (`logging`)

Controls how the bot logs information.

```yaml
logging:
  level: "INFO" # Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
  # file: "logs/bot.log" # Optional: Path to a log file. If omitted, logs to console only.
  # rotation_size_mb: 10 # Optional: Max size in MB before log file rotates.
  # rotation_backup_count: 5 # Optional: Number of backup log files to keep.
```

- **`level`**: String. The minimum logging level to output. Options (from least to most verbose): `CRITICAL`, `ERROR`, `WARNING`, `INFO`, `DEBUG`.
- **`file`**: (Optional) String. Path to the file where logs should be saved. If commented out or omitted, logs will only be printed to the console.
- **`rotation_size_mb`**: (Optional) Integer. If `file` is specified, this is the maximum size in megabytes a log file can reach before it is rotated (e.g., `bot.log` becomes `bot.log.1`).
- **`rotation_backup_count`**: (Optional) Integer. If `file` and `rotation_size_mb` are specified, this is the number of old log files to keep.

## 5. Monitoring Configuration (`monitoring`)

Settings for the Prometheus metrics exporter.

```yaml
monitoring:
  prometheus_port: 8000 # Port for the Prometheus metrics HTTP server
  # enabled: true # Optional: Set to false to disable Prometheus exporter. Defaults to true.
```

- **`prometheus_port`**: Integer. The TCP port on which the bot will expose Prometheus metrics. Default is `8000`.
- **`enabled`**: (Optional) Boolean. Set to `false` to disable the Prometheus metrics server. Defaults to `true` if the section exists.

## Hot Reloading

The bot monitors the `config/config.yaml` file for changes. Most settings (API keys excluded for security during runtime) can be updated live without restarting the bot. This includes:
- Logging levels
- Enabling/disabling pairs
- Leverage, margin settings for pairs
- Strategy parameters like `min_signal_interval_minutes`, `tp_sl_ratio`
- Indicator timeframes

When the file is saved, the bot will detect the changes and apply them. Check the bot's logs for confirmation of reloaded configurations.

---

*Always ensure your configuration is validated and tested on a testnet environment before deploying with real funds. Incorrect configurations can lead to unintended trading behavior and financial loss.*



================================================
FILE: docs/TROUBLESHOOTING.md
================================================
# Troubleshooting Guide

This document provides solutions for common issues you might encounter when running the Binance Futures Trading Bot.

## Connection Issues

### WebSocket Connection Failures

**Symptoms:**
- Repeated log messages about WebSocket connection failures
- Bot not receiving market data

**Possible Solutions:**
1. **Check Internet Connection**: Ensure your server has a stable internet connection.
2. **Verify API Endpoints**: Confirm Binance API endpoints are accessible from your location.
3. **Check Firewall Settings**: Make sure outbound WebSocket connections are allowed.
4. **Proxy Configuration**: If using a proxy, verify it's correctly configured.

```bash
# Test connectivity to Binance WebSocket endpoint
ping fstream.binance.com
```

### REST API Connection Issues

**Symptoms:**
- Error messages when placing orders
- Failed account balance retrieval

**Possible Solutions:**
1. **Verify API Keys**: Ensure your API keys are valid and have the correct permissions.
2. **Check IP Restrictions**: If you've set IP restrictions on your API keys, verify your server's IP is allowed.
3. **Rate Limits**: You might be hitting Binance's rate limits. Check logs for 429 errors and consider reducing request frequency.

## Configuration Issues

### Bot Not Trading Expected Pairs

**Symptoms:**
- Some configured pairs are not being traded
- No signals generated for certain pairs

**Possible Solutions:**
1. **Check Pair Configuration**: Ensure the pair is correctly formatted and `enabled: true` is set.
2. **Verify Symbol Existence**: Confirm the trading pair exists on Binance Futures.
3. **Check Logs**: Look for any error messages related to the specific pair.

### Strategy Parameters Not Taking Effect

**Symptoms:**
- Bot behavior doesn't match configured strategy parameters

**Possible Solutions:**
1. **Config Hot-Reload**: Verify the configuration was properly reloaded (check logs).
2. **Parameter Scope**: Some parameters might be pair-specific. Check if you've set them at the correct level.
3. **Restart Bot**: Some core parameters might require a bot restart to take effect.

## Trading Issues

### No Signals Generated

**Symptoms:**
- Bot is running but not generating any trade signals

**Possible Solutions:**
1. **Market Conditions**: The strategy conditions might not be met in current market conditions.
2. **Check Indicator Calculation**: Verify indicators are being calculated correctly.
3. **Signal Interval**: Check if `min_signal_interval_minutes` is set too high.
4. **Buffer Time**: If using buffer time, the crossover might need to persist for several candles.

### Orders Failing

**Symptoms:**
- Signals generated but orders not placed
- Error messages when placing orders

**Possible Solutions:**
1. **Insufficient Funds**: Ensure your account has sufficient balance.
2. **Leverage/Margin Settings**: Check if the configured leverage is allowed for the pair.
3. **Minimum Notional**: The calculated position size might be below the minimum notional value required by Binance.
4. **Symbol Precision**: Order quantities might not meet the symbol's precision requirements.

### Unexpected Position Sizes

**Symptoms:**
- Position sizes differ from what you expected based on configuration

**Possible Solutions:**
1. **Check Margin Settings**: Verify `margin_usdt` or `margin_coin` settings.
2. **Leverage Configuration**: Confirm the leverage setting is applied correctly.
3. **Price Impact**: For market orders, the execution price might differ from the signal price.

## Monitoring Issues

### Prometheus Metrics Not Available

**Symptoms:**
- Cannot access metrics at http://your-server:8000/metrics

**Possible Solutions:**
1. **Port Configuration**: Verify the `prometheus_port` setting.
2. **Firewall Settings**: Ensure the configured port is accessible.
3. **Metrics Enabled**: Check that monitoring is enabled in the configuration.

## Logging Issues

### Missing or Insufficient Logs

**Symptoms:**
- Not enough information in logs to diagnose issues

**Possible Solutions:**
1. **Log Level**: Set `logging.level` to "DEBUG" for more detailed logs.
2. **Log File Configuration**: Ensure the log file path is writable if using file logging.

## Performance Issues

### High CPU Usage

**Symptoms:**
- Bot process consuming excessive CPU resources

**Possible Solutions:**
1. **Too Many Pairs**: Reduce the number of active trading pairs.
2. **Timeframe Overload**: Limit the number of indicator timeframes being processed.
3. **Indicator Calculation**: Some indicators might be computationally expensive.

### Memory Leaks

**Symptoms:**
- Increasing memory usage over time

**Possible Solutions:**
1. **Buffer Size**: Check if k-line buffers are growing unbounded.
2. **Restart Periodically**: Consider implementing a scheduled restart.

## Testnet vs. Mainnet

### Testing on Testnet

Before trading with real funds, test thoroughly on Binance Futures Testnet:

1. Create a Testnet account at https://testnet.binancefuture.com/
2. Generate API keys for the Testnet
3. Configure the bot with `testnet: true` in the API section
4. Verify all functionality works as expected

### Moving to Mainnet

When ready to trade with real funds:

1. Generate new API keys on the main Binance platform
2. Update your configuration with the new keys
3. Set `testnet: false` or remove the testnet parameter
4. Start with small position sizes to verify everything works correctly

## Getting Help

If you encounter issues not covered in this guide:

1. Check the detailed logs for error messages
2. Review the [Binance API documentation](https://binance-docs.github.io/apidocs/futures/en/)
3. Open an issue on the project's GitHub repository with:
   - Detailed description of the issue
   - Relevant log excerpts
   - Configuration (with sensitive information redacted)
   - Steps to reproduce the problem



================================================
FILE: src/__init__.py
================================================



================================================
FILE: src/config_loader.py
================================================
import yaml
import os
import logging
import time
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
from threading import Lock

logger = logging.getLogger(__name__)

DEFAULT_CONFIG_PATH = os.path.join(os.path.dirname(os.path.dirname(__file__)), "config", "config.yaml")
EXAMPLE_CONFIG_PATH = os.path.join(os.path.dirname(os.path.dirname(__file__)), "config", "config.yaml.example")

class ConfigChangeHandler(FileSystemEventHandler):
    def __init__(self, config_manager):
        self.config_manager = config_manager

    def on_modified(self, event):
        if not event.is_directory and event.src_path == self.config_manager.config_file_path:
            logger.info(f"Configuration file {event.src_path} changed. Reloading...")
            self.config_manager.load_config()

class ConfigManager:
    _instance = None
    _lock = Lock()

    def __new__(cls, *args, **kwargs):
        if not cls._instance:
            with cls._lock:
                if not cls._instance:
                    cls._instance = super(ConfigManager, cls).__new__(cls)
        return cls._instance

    def __init__(self, config_file_path=None, auto_reload=True):
        # Ensure __init__ is only run once for the singleton instance
        if not hasattr(self, '_initialized'):
            with self._lock:
                if not hasattr(self, '_initialized'): 
                    self.config_file_path = config_file_path or DEFAULT_CONFIG_PATH
                    self.config_data = {}
                    self._callbacks = []
                    self.observer = None
                    self.auto_reload = auto_reload
                    self._ensure_config_file_exists()
                    self.load_config()
                    if self.auto_reload:
                        self._start_watcher()
                    self._initialized = True

    def _ensure_config_file_exists(self):
        if not os.path.exists(self.config_file_path):
            logger.warning(
                f"Config file not found at {self.config_file_path}. "
                f"Attempting to copy from {EXAMPLE_CONFIG_PATH}."
            )
            try:
                config_dir = os.path.dirname(self.config_file_path)
                if not os.path.exists(config_dir):
                    os.makedirs(config_dir)
                
                with open(EXAMPLE_CONFIG_PATH, 'r') as src, open(self.config_file_path, 'w') as dst:
                    dst.write(src.read())
                logger.info(f"Successfully copied example config to {self.config_file_path}. Please review and update it.")
            except Exception as e:
                logger.error(f"Could not copy example config: {e}. Please create {self.config_file_path} manually.")
                # Potentially raise an error or exit if config is critical for startup

    def load_config(self):
        try:
            with open(self.config_file_path, 'r') as f:
                new_config_data = yaml.safe_load(f)
            if new_config_data:
                self.config_data = new_config_data
                logger.info(f"Configuration loaded successfully from {self.config_file_path}")
                self._notify_callbacks()
            else:
                logger.warning(f"Configuration file {self.config_file_path} is empty or invalid.")
        except FileNotFoundError:
            logger.error(f"Configuration file not found: {self.config_file_path}")
            # Fallback to empty or default config if appropriate, or raise error
            self.config_data = {}
        except yaml.YAMLError as e:
            logger.error(f"Error parsing YAML configuration file {self.config_file_path}: {e}")
            # Keep old config or fallback
        except Exception as e:
            logger.error(f"An unexpected error occurred while loading configuration: {e}")

    def get_config(self):
        with self._lock: # Ensure thread-safe access to config_data
            return self.config_data.copy() # Return a copy to prevent modification

    def get_specific_config(self, key_path, default=None):
        """ Fetches a specific config value using a dot-separated key path. E.g., 'api.binance_api_key' """
        try:
            value = self.config_data
            for key in key_path.split('.'):
                if isinstance(value, dict):
                    value = value[key]
                else:
                    # If at any point value is not a dict and we still have keys, path is invalid
                    logger.warning(f"Invalid key path '{key_path}' at segment '{key}'.")
                    return default
            return value
        except KeyError:
            logger.debug(f"Config key '{key_path}' not found. Returning default: {default}")
            return default
        except Exception as e:
            logger.error(f"Error getting specific config '{key_path}': {e}")
            return default

    def register_callback(self, callback):
        if callable(callback):
            self._callbacks.append(callback)
        else:
            logger.warning("Attempted to register a non-callable callback.")

    def _notify_callbacks(self):
        for callback in self._callbacks:
            try:
                callback(self.get_config())
            except Exception as e:
                logger.error(f"Error executing config update callback {callback.__name__}: {e}")

    def _start_watcher(self):
        if self.observer:
            self.observer.stop()
            self.observer.join() # Wait for the thread to finish

        event_handler = ConfigChangeHandler(self)
        self.observer = Observer()
        # Observe the directory containing the config file, as some editors modify files by creating a new one and renaming.
        config_dir = os.path.dirname(self.config_file_path) or '.'
        self.observer.schedule(event_handler, config_dir, recursive=False)
        
        try:
            self.observer.start()
            logger.info(f"Started watching configuration file {self.config_file_path} for changes.")
        except Exception as e:
            logger.error(f"Error starting configuration file watcher: {e}")
            self.observer = None # Ensure observer is None if it failed to start

    def stop_watcher(self):
        if self.observer and self.observer.is_alive():
            self.observer.stop()
            self.observer.join()
            logger.info("Stopped configuration file watcher.")

# Example usage (typically in main.py or similar entry point):
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    
    # Create a dummy config.yaml for testing
    dummy_config_content = """
    api:
      binance_api_key: "TEST_KEY"
      binance_api_secret: "TEST_SECRET"
    logging:
      level: "DEBUG"
    """
    if not os.path.exists(os.path.dirname(DEFAULT_CONFIG_PATH)):
        os.makedirs(os.path.dirname(DEFAULT_CONFIG_PATH))
    with open(DEFAULT_CONFIG_PATH, "w") as f:
        f.write(dummy_config_content)

    config_manager = ConfigManager()
    print("Initial config:", config_manager.get_config())
    print("API Key:", config_manager.get_specific_config("api.binance_api_key"))
    print("Logging Level:", config_manager.get_specific_config("logging.level"))

    def my_config_update_handler(new_config):
        print("Callback: Config updated! New logging level:", new_config.get("logging", {}).get("level"))

    config_manager.register_callback(my_config_update_handler)

    print(f"\nSimulating config file change. Please modify {DEFAULT_CONFIG_PATH} and save.")
    print("(e.g., change logging.level to INFO)")
    print("Watching for 30 seconds... Press Ctrl+C to stop early.")
    
    try:
        time.sleep(30) # Keep alive to observe changes
    except KeyboardInterrupt:
        print("\nExiting example.")
    finally:
        config_manager.stop_watcher()
        # Clean up dummy config
        # os.remove(DEFAULT_CONFIG_PATH)




================================================
FILE: src/connectors.py
================================================
import ccxt.async_support as ccxt
import asyncio
import websockets
import json
import logging
import time
import random
from typing import Callable, List, Dict, Any, Optional, Literal

from src.config_loader import ConfigManager
from src.models import Kline # Assuming Kline model is in src.models

logger = logging.getLogger(__name__)

# Symbol conversion utility (can be moved to utils.py later)
def convert_symbol_to_ws_format(config_symbol: str) -> str:
    """Converts BTC_USDT to btcusdt, BTCUSD_PERP to btcusd_perp"""
    if "_" in config_symbol:
        if config_symbol.endswith("_PERP"):
            return config_symbol.replace("_PERP", "_perp").lower()
        return config_symbol.replace("_", "").lower()
    return config_symbol.lower() # Fallback for already formatted or simple symbols

def convert_symbol_to_api_format(config_symbol: str) -> str:
    """Converts BTC_USDT to BTCUSDT, BTCUSD_PERP to BTCUSD_PERP"""
    if "_" in config_symbol:
        if config_symbol.endswith("_PERP"):
            return config_symbol.upper()
        return config_symbol.replace("_", "").upper()
    return config_symbol.upper()

class BinanceRESTClient:
    def __init__(self, config_manager: ConfigManager):
        self.config_manager = config_manager
        self.exchange = None
        self._initialize_exchange()

    def _initialize_exchange(self):
        config = self.config_manager.get_config()
        api_key = config.get("api", {}).get("binance_api_key")
        api_secret = config.get("api", {}).get("binance_api_secret")
        is_testnet = config.get("api", {}).get("testnet", False)

        if not api_key or not api_secret or "YOUR_" in api_key: # Basic check for placeholder
            logger.warning("API key/secret not found or placeholders used. REST client will operate in simulated mode (no real calls).")
            self.exchange = None 
            return

        self.exchange = ccxt.binance({
            "apiKey": api_key,
            "secret": api_secret,
            "options": {
                "defaultType": "future",
            },
        })
        if is_testnet:
            self.exchange.set_sandbox_mode(True)
            logger.info("Binance REST Client initialized in Testnet mode.")
        else:
            logger.info("Binance REST Client initialized in Mainnet mode.")

    async def close_exchange(self):
        if self.exchange:
            await self.exchange.close()
            logger.info("CCXT exchange instance closed.")

    async def fetch_exchange_info(self, params={}):
        if not self.exchange: return None
        try:
            markets = await self.exchange.load_markets()
            return markets 
        except Exception as e:
            logger.error(f"Error fetching exchange info: {e}")
            return None

    async def fetch_balance(self, params={}):
        if not self.exchange: return None # Or simulate a balance for testing
        try:
            balance = await self.exchange.fetch_balance(params)
            return balance
        except Exception as e:
            logger.error(f"Error fetching balance: {e}")
            return None

    async def create_order(self, symbol: str, order_type: str, side: str, amount: float, price: Optional[float] = None, params={}):
        if not self.exchange: 
            logger.info(f"Simulated order: {side} {amount} {symbol} at {price or 'market'}")
            return {"id": f"simulated_order_{int(time.time())}", "symbol": symbol, "status": "NEW", "type": order_type, "side": side, "amount": amount, "price": price}
        try:
            api_symbol = convert_symbol_to_api_format(symbol)
            order = await self.exchange.create_order(api_symbol, order_type, side, amount, price, params)
            logger.info(f"Order created: {order}")
            return order
        except Exception as e:
            logger.error(f"Error creating order for {symbol}: {e}")
            return None

    async def cancel_order(self, order_id: str, symbol: str, params={}):
        if not self.exchange: 
            logger.info(f"Simulated cancel order: {order_id} for {symbol}")
            return {"id": order_id, "status": "CANCELED"}
        try:
            api_symbol = convert_symbol_to_api_format(symbol)
            response = await self.exchange.cancel_order(order_id, api_symbol, params)
            return response
        except Exception as e:
            logger.error(f"Error cancelling order {order_id} for {symbol}: {e}")
            return None

    async def fetch_open_orders(self, symbol: Optional[str] = None, params={}):
        if not self.exchange: return []
        try:
            api_symbol = convert_symbol_to_api_format(symbol) if symbol else None
            open_orders = await self.exchange.fetch_open_orders(api_symbol, params=params)
            return open_orders
        except Exception as e:
            logger.error(f"Error fetching open orders for {symbol}: {e}")
            return []

    async def fetch_position(self, symbol: str, params={}):
        if not self.exchange: return None
        try:
            api_symbol = convert_symbol_to_api_format(symbol)
            positions = await self.exchange.fetch_positions([api_symbol], params=params)
            for position in positions:
                # CCXT position symbol format might vary, ensure robust matching
                if position.get("symbol") == api_symbol or position.get("info", {}).get("symbol") == api_symbol:
                    return position
            return None 
        except Exception as e:
            logger.error(f"Error fetching position for {symbol}: {e}")
            return None

    async def fetch_positions(self, symbols: Optional[List[str]] = None, params={}):
        if not self.exchange: return []
        try:
            api_symbols = [convert_symbol_to_api_format(s) for s in symbols] if symbols else None
            positions = await self.exchange.fetch_positions(api_symbols, params=params)
            return positions
        except Exception as e:
            logger.error(f"Error fetching positions: {e}")
            return []

    async def set_leverage(self, symbol: str, leverage: int, params={}):
        if not self.exchange: 
            logger.info(f"Simulated set leverage: {leverage}x for {symbol}")
            return True 
        try:
            api_symbol = convert_symbol_to_api_format(symbol)
            response = await self.exchange.set_leverage(leverage, api_symbol, params)
            logger.info(f"Leverage set for {symbol} to {leverage}x: {response}")
            return response
        except Exception as e:
            logger.error(f"Error setting leverage for {symbol} to {leverage}x: {e}")
            return False

    async def set_margin_mode(self, symbol: str, margin_mode: str, params={}):
        if not self.exchange: 
            logger.info(f"Simulated set margin mode: {margin_mode} for {symbol}")
            return True
        try:
            api_symbol = convert_symbol_to_api_format(symbol)
            response = await self.exchange.set_margin_mode(margin_mode.upper(), api_symbol, params)
            logger.info(f"Margin mode set for {symbol} to {margin_mode.upper()}: {response}")
            return response
        except Exception as e:
            logger.error(f"Error setting margin mode for {symbol} to {margin_mode.upper()}: {e}")
            return False

    async def fetch_historical_klines(self, symbol: str, timeframe: str = "1m", since: Optional[int] = None, limit: Optional[int] = None, params={}):
        if not self.exchange: return []
        try:
            api_symbol = convert_symbol_to_api_format(symbol)
            klines_data = await self.exchange.fetch_ohlcv(api_symbol, timeframe, since, limit, params)
            # Convert to Kline model before returning
            klines = [
                Kline(
                    timestamp=k[0],
                    open=float(k[1]),
                    high=float(k[2]),
                    low=float(k[3]),
                    close=float(k[4]),
                    volume=float(k[5]),
                    is_closed=True, # fetch_ohlcv usually returns closed candles
                    symbol=api_symbol, # Use the API symbol
                    interval=timeframe
                ) for k in klines_data
            ]
            return klines
        except Exception as e:
            logger.error(f"Error fetching historical klines for {symbol} {timeframe}: {e}")
            return []

class BinanceWebSocketConnector:
    def __init__(self, config_manager: ConfigManager, kline_callback: Callable[[Kline, str], asyncio.Task]):
        self.config_manager = config_manager
        self.kline_callback = kline_callback
        self.ws_url_usdm_mainnet = "wss://fstream.binance.com/stream"
        self.ws_url_usdm_testnet = "wss://stream.binancefuture.com/stream" # Testnet URL for USDM
        self.ws_url_coinm_mainnet = "wss://dstream.binance.com/stream"
        self.ws_url_coinm_testnet = "wss://dstream.binancefuture.com/stream" # Testnet URL for COINM
        self._ws_connections: Dict[str, websockets.WebSocketClientProtocol] = {}
        self._active_subscriptions: Dict[str, List[str]] = {"USDT_M": [], "COIN_M": []}
        self._is_running = False
        self._reconnect_delay = 5
        self._tasks: List[asyncio.Task] = []
        self._is_testnet = self.config_manager.get_config().get("api", {}).get("testnet", False)

    def _get_ws_url(self, market_type: str) -> str:
        if market_type == "USDT_M":
            return self.ws_url_usdm_testnet if self._is_testnet else self.ws_url_usdm_mainnet
        elif market_type == "COIN_M":
            return self.ws_url_coinm_testnet if self._is_testnet else self.ws_url_coinm_mainnet
        raise ValueError(f"Invalid market type: {market_type}")

    def _get_active_pairs_and_intervals(self) -> Dict[str, List[str]]:
        config = self.config_manager.get_config()
        pairs_config = config.get("pairs", {})
        global_intervals = config.get("global_settings", {}).get("v1_strategy", {}).get("indicator_timeframes", ["1m"])
        
        active_streams_usdm: List[str] = []
        active_streams_coinm: List[str] = []

        for pair_symbol_config, pair_details in pairs_config.items():
            if pair_details.get("enabled", False):
                ws_symbol = convert_symbol_to_ws_format(pair_symbol_config)
                intervals_to_subscribe = pair_details.get("indicator_timeframes", global_intervals)
                contract_type = pair_details.get("contract_type", "USDT_M")
                
                for interval in intervals_to_subscribe:
                    stream_name = f"{ws_symbol}@kline_{interval}"
                    if contract_type == "COIN_M":
                        active_streams_coinm.append(stream_name)
                    else:
                        active_streams_usdm.append(stream_name)
        return {"USDT_M": active_streams_usdm, "COIN_M": active_streams_coinm}

    async def _subscribe(self, ws: websockets.WebSocketClientProtocol, streams: List[str]):
        if not streams: return
        sub_payload = {
            "method": "SUBSCRIBE",
            "params": streams,
            "id": int(time.time() * 1000)
        }
        await ws.send(json.dumps(sub_payload))
        logger.info(f"Subscribed to streams: {streams} on {ws.remote_address}")

    async def _unsubscribe(self, ws: websockets.WebSocketClientProtocol, streams: List[str]):
        if not streams or not ws or not ws.open: return
        unsub_payload = {
            "method": "UNSUBSCRIBE",
            "params": streams,
            "id": int(time.time() * 1000)
        }
        try:
            await ws.send(json.dumps(unsub_payload))
            logger.info(f"Unsubscribed from streams: {streams} on {ws.remote_address}")
        except Exception as e:
            logger.error(f"Error unsubscribing from {streams}: {e}")

    async def _handle_connection(self, market_type: Literal["USDT_M", "COIN_M"]):
        ws_url = self._get_ws_url(market_type)
        while self._is_running:
            try:
                current_streams_for_market = self._active_subscriptions[market_type]
                if not current_streams_for_market:
                    logger.debug(f"No active streams for {market_type}, connection loop sleeping.")
                    await asyncio.sleep(self._reconnect_delay) 
                    continue

                async with websockets.connect(ws_url, ping_interval=20, ping_timeout=10) as ws:
                    self._ws_connections[market_type] = ws
                    logger.info(f"Connected to Binance Futures {market_type} WebSocket ({'Testnet' if self._is_testnet else 'Mainnet'}): {ws_url}")
                    await self._subscribe(ws, current_streams_for_market)
                    self._reconnect_delay = 5 
                    async for message in ws:
                        await self._process_message(message, market_type)
            except (websockets.exceptions.ConnectionClosedError, websockets.exceptions.ConnectionClosedOK) as e:
                logger.warning(f"WebSocket connection closed for {market_type}: {e}. Reconnecting...")
            except ConnectionRefusedError:
                logger.error(f"Connection refused for {market_type} WebSocket. Check network or Binance status.")
            except Exception as e:
                logger.error(f"Error in {market_type} WebSocket handler: {e}. Reconnecting...")
            finally:
                if market_type in self._ws_connections:
                    del self._ws_connections[market_type]
                if self._is_running:
                    await asyncio.sleep(self._reconnect_delay)
                    self._reconnect_delay = min(self._reconnect_delay * 1.5, 60) 
                    self._reconnect_delay += random.uniform(0,1)

    async def _process_message(self, message_str: str, market_type: str):
        try:
            data = json.loads(message_str)
            if "stream" in data and "@kline_" in data["stream"]:
                kline_data = data["data"]["k"]
                kline_obj = Kline(
                    timestamp=kline_data["t"],
                    open=float(kline_data["o"]),
                    high=float(kline_data["h"]),
                    low=float(kline_data["l"]),
                    close=float(kline_data["c"]),
                    volume=float(kline_data["v"]),
                    quote_asset_volume=float(kline_data["q"]) if "q" in kline_data else 0.0,
                    number_of_trades=int(kline_data["n"]) if "n" in kline_data else 0,
                    is_closed=kline_data["x"],
                    symbol=kline_data["s"], 
                    interval=kline_data["i"]
                )
                # Ensure kline_callback is awaited if it's a coroutine
                if asyncio.iscoroutinefunction(self.kline_callback):
                    await self.kline_callback(kline_obj, market_type)
                else:
                    self.kline_callback(kline_obj, market_type) # If it's a regular function
            elif "result" in data and data["result"] is None: 
                logger.debug(f"Subscription/Unsubscription confirmed: {data}")
            elif "error" in data:
                logger.error(f"WebSocket error message: {data}")
        except json.JSONDecodeError:
            logger.error(f"Failed to decode JSON message: {message_str}")
        except Exception as e:
            logger.error(f"Error processing WebSocket message: {e} - Message: {message_str}")

    async def start(self):
        if self._is_running:
            logger.warning("WebSocket connector already running.")
            return
        self._is_running = True
        self._is_testnet = self.config_manager.get_config().get("api", {}).get("testnet", False)
        self.config_manager.register_callback(self._handle_config_update) 
        await self._handle_config_update(self.config_manager.get_config()) # Initial subscription setup
        logger.info("Binance WebSocket Connector started.")

    async def _handle_config_update(self, new_config: Dict):
        logger.info("Configuration updated, re-evaluating WebSocket subscriptions...")
        self._is_testnet = new_config.get("api", {}).get("testnet", False) # Update testnet status
        new_target_streams = self._get_active_pairs_and_intervals()

        for market_type in ["USDT_M", "COIN_M"]:
            current_ws = self._ws_connections.get(market_type)
            old_streams = self._active_subscriptions.get(market_type, [])
            new_streams_for_market = new_target_streams.get(market_type, [])

            streams_to_add = list(set(new_streams_for_market) - set(old_streams))
            streams_to_remove = list(set(old_streams) - set(new_streams_for_market))

            if current_ws and current_ws.open:
                if streams_to_remove:
                    await self._unsubscribe(current_ws, streams_to_remove)
                if streams_to_add:
                    await self._subscribe(current_ws, streams_to_add)
            elif streams_to_add: 
                # If no connection, but new streams, start a new connection task if not already planned
                # Check if a task for this market_type is already running or scheduled
                is_task_active = False
                for task in self._tasks:
                    # This check is a bit simplistic; ideally, tasks would be identifiable
                    if market_type in str(task): # Heuristic to check if task is for this market type
                        is_task_active = True
                        break
                if not is_task_active:
                    logger.info(f"No active connection for {market_type}, but new streams detected. Scheduling connection.")
                    task = asyncio.create_task(self._handle_connection(market_type))
                    self._tasks.append(task)
            
            self._active_subscriptions[market_type] = new_streams_for_market
            
            # If all streams for a market type are removed and a connection exists, close it.
            if not new_streams_for_market and current_ws and current_ws.open:
                logger.info(f"All streams for {market_type} removed. Closing WebSocket connection.")
                await current_ws.close()
                if market_type in self._ws_connections:
                    del self._ws_connections[market_type]
            # If no streams and no task, ensure no new tasks are created for this market type
            elif not new_streams_for_market:
                 logger.debug(f"No streams for {market_type}, ensuring no connection task is active or created.")

        # Initial connection tasks if not already started
        for market_type in ["USDT_M", "COIN_M"]:
            if self._active_subscriptions.get(market_type) and market_type not in self._ws_connections:
                is_task_active = False
                for task in self._tasks:
                    if market_type in str(task):
                        is_task_active = True
                        break
                if not is_task_active:
                    logger.info(f"Initial streams for {market_type} detected. Scheduling connection.")
                    task = asyncio.create_task(self._handle_connection(market_type))
                    self._tasks.append(task)

    async def stop(self):
        logger.info("Stopping Binance WebSocket Connector...")
        self._is_running = False
        self.config_manager.unregister_callback(self._handle_config_update)
        for market_type, ws in list(self._ws_connections.items()): # Iterate over a copy
            if ws and ws.open:
                logger.info(f"Closing WebSocket connection for {market_type}...")
                await ws.close()
        self._ws_connections.clear()
        
        # Cancel and await pending tasks
        for task in self._tasks:
            if not task.done():
                task.cancel()
        
        if self._tasks:
            results = await asyncio.gather(*self._tasks, return_exceptions=True)
            for i, result in enumerate(results):
                if isinstance(result, asyncio.CancelledError):
                    logger.debug(f"Task {self._tasks[i]} was cancelled.")
                elif isinstance(result, Exception):
                    logger.error(f"Task {self._tasks[i]} raised an exception during stop: {result}")
        self._tasks.clear()
        logger.info("Binance WebSocket Connector stopped.")




================================================
FILE: src/data_processor.py
================================================
import pandas as pd
from collections import deque, defaultdict
import logging
from typing import Dict, Deque, Optional, List, Tuple, Callable

from src.models import Kline
from src.config_loader import ConfigManager
from src.connectors import convert_symbol_to_api_format # For consistent symbol usage

logger = logging.getLogger(__name__)

# Define a maximum length for k-line deques to prevent memory issues
# Needs to be at least max(sma_long_period) + some buffer for calculations
# For SMA 200, we need at least 200 candles. Let's use a bit more.
MAX_KLINE_BUFFER_LENGTH = 300 

class DataProcessor:
    def __init__(self, config_manager: ConfigManager):
        self.config_manager = config_manager
        # Structure: self.kline_buffers[api_symbol][interval] = deque([Kline, ...])
        self.kline_buffers: Dict[str, Dict[str, Deque[Kline]]] = defaultdict(lambda: defaultdict(lambda: deque(maxlen=MAX_KLINE_BUFFER_LENGTH)))
        # Structure: self.indicator_data[api_symbol][interval] = pd.DataFrame with columns [timestamp, open, high, low, close, volume, sma_short, sma_long]
        self.indicator_data: Dict[str, Dict[str, pd.DataFrame]] = defaultdict(lambda: defaultdict(pd.DataFrame))
        
        self.config_manager.register_callback(self._handle_config_update) # Listen for config changes
        self._active_pairs_timeframes: Dict[str, List[str]] = {}
        self._initialize_buffers_from_config()

    def _handle_config_update(self, new_config: Dict):
        logger.info("DataProcessor: Configuration updated. Re-initializing buffers and settings.")
        self._initialize_buffers_from_config(new_config)

    def _initialize_buffers_from_config(self, config: Optional[Dict] = None):
        if config is None:
            config = self.config_manager.get_config()
        
        new_active_pairs_timeframes: Dict[str, List[str]] = {}
        pairs_config = config.get("pairs", {})
        global_settings = config.get("global_settings", {})
        default_timeframes = global_settings.get("v1_strategy", {}).get("indicator_timeframes", ["1m"])

        for pair_symbol_config, pair_details in pairs_config.items():
            if pair_details.get("enabled", False):
                api_symbol = convert_symbol_to_api_format(pair_symbol_config)
                timeframes_for_pair = pair_details.get("indicator_timeframes", default_timeframes)
                new_active_pairs_timeframes[api_symbol] = timeframes_for_pair
                # Ensure buffers exist for newly active pairs/timeframes
                for tf in timeframes_for_pair:
                    if tf not in self.kline_buffers[api_symbol]:
                        self.kline_buffers[api_symbol][tf] = deque(maxlen=MAX_KLINE_BUFFER_LENGTH)
                    if tf not in self.indicator_data[api_symbol]:
                        self.indicator_data[api_symbol][tf] = pd.DataFrame()
        
        # Cleanup buffers for pairs/timeframes that are no longer active (optional, to save memory)
        # For simplicity, we are not removing old buffers now, but this could be added.
        self._active_pairs_timeframes = new_active_pairs_timeframes
        logger.debug(f"DataProcessor initialized/updated for pairs and timeframes: {self._active_pairs_timeframes}")

    async def process_kline(self, kline: Kline, market_type: Optional[str] = None):
        """ Process an incoming Kline object. market_type is for context if needed. """
        api_symbol = kline.symbol # Assuming kline.symbol is already in API format (e.g., BTCUSDT)
        interval = kline.interval

        if api_symbol not in self._active_pairs_timeframes or interval not in self._active_pairs_timeframes.get(api_symbol, []):
            # logger.debug(f"Skipping kline for inactive pair/timeframe: {api_symbol} {interval}")
            return

        # Add to deque. If it's an update to the last candle, replace it.
        # Kline data from Binance WS usually gives the current (non-closed) candle and then the closed one.
        # We are interested in closed candles for SMA calculation primarily.
        
        buffer = self.kline_buffers[api_symbol][interval]
        if kline.is_closed:
            if buffer and buffer[-1].timestamp == kline.timestamp:
                if not buffer[-1].is_closed:
                    buffer[-1] = kline # Replace the non-closed one with the closed one
            else:
                buffer.append(kline)
            self._update_indicators(api_symbol, interval)
        else: # Kline is not closed (current, ongoing candle)
            if buffer and buffer[-1].timestamp == kline.timestamp:
                buffer[-1] = kline # Update the last (current) candle
            else:
                buffer.append(kline) # Add as new current candle

    def _update_indicators(self, api_symbol: str, interval: str):
        kline_deque = self.kline_buffers[api_symbol][interval]
        if not kline_deque:
            return
        
        df_data = {
            "timestamp": [k.timestamp for k in kline_deque],
            "open": [k.open for k in kline_deque],
            "high": [k.high for k in kline_deque],
            "low": [k.low for k in kline_deque],
            "close": [k.close for k in kline_deque],
            "volume": [k.volume for k in kline_deque],
            "is_closed": [k.is_closed for k in kline_deque]
        }
        df = pd.DataFrame(df_data)
        df.set_index("timestamp", inplace=True, drop=False) # Keep timestamp column too
        df.sort_index(inplace=True) # Ensure time order
        df = df[~df.index.duplicated(keep="last")] # Remove duplicate timestamps, keep last update

        if df.empty:
            return

        config = self.config_manager.get_config()
        sma_short_period = config.get("global_settings", {}).get("v1_strategy", {}).get("sma_short_period", 21)
        sma_long_period = config.get("global_settings", {}).get("v1_strategy", {}).get("sma_long_period", 200)

        if len(df) >= sma_short_period:
            df["sma_short"] = df["close"].rolling(window=sma_short_period).mean()
        else:
            df["sma_short"] = pd.NA

        if len(df) >= sma_long_period:
            df["sma_long"] = df["close"].rolling(window=sma_long_period).mean()
        else:
            df["sma_long"] = pd.NA
        
        self.indicator_data[api_symbol][interval] = df

    def get_latest_kline(self, api_symbol: str, interval: str) -> Optional[Kline]:
        if api_symbol in self.kline_buffers and interval in self.kline_buffers[api_symbol]:
            if self.kline_buffers[api_symbol][interval]:
                return self.kline_buffers[api_symbol][interval][-1]
        return None

    def get_indicator_dataframe(self, api_symbol: str, interval: str) -> Optional[pd.DataFrame]:
        if api_symbol in self.indicator_data and interval in self.indicator_data[api_symbol]:
            return self.indicator_data[api_symbol][interval].copy() # Return a copy
        return None

    def get_latest_indicators(self, api_symbol: str, interval: str) -> Optional[pd.Series]:
        df = self.get_indicator_dataframe(api_symbol, interval)
        if df is not None and not df.empty:
            return df.iloc[-1]
        return None




================================================
FILE: src/main.py
================================================
import asyncio
import logging
import signal
import os
from typing import Optional

# Let's use absolute imports to be consistent and avoid potential issues
from src.config_loader import ConfigManager
from src.connectors import BinanceRESTClient, BinanceWebSocketConnector, convert_symbol_to_api_format
from src.data_processor import DataProcessor
from src.signal_engine import SignalEngineV1
from src.order_manager import OrderManager
from src.position_manager import PositionManager
from src.models import Kline, Order, TradeSignal  # For type hinting
# from src.monitoring import PrometheusMonitor # If implementing Prometheus

# Setup basic logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.StreamHandler(),
        # logging.FileHandler("app.log") # Add file handler if needed from config
    ]
)
logger = logging.getLogger("main_app")

class TradingBot:
    def __init__(self) -> None:
        self.config_manager = ConfigManager()
        self._configure_logging()
        
        self.rest_client = BinanceRESTClient(config_manager=self.config_manager)
        self.position_manager = PositionManager(config_manager=self.config_manager)
        self.order_manager = OrderManager(config_manager=self.config_manager, rest_client=self.rest_client)
        # Note: PositionManager updates rely on user data stream (to be implemented) or periodic reconciliation
        # Direct linking could be done if needed: self.order_manager.position_manager = self.position_manager

        self.data_processor = DataProcessor(config_manager=self.config_manager)
        self.ws_connector = BinanceWebSocketConnector(
            config_manager=self.config_manager, 
            kline_callback=self._handle_kline_data
        )
        self.signal_engine_v1 = SignalEngineV1(config_manager=self.config_manager, data_processor=self.data_processor)
        
        self.running = False
        self.active_trading_pairs = []  # List of config_symbols (e.g. BTC_USDT)

        self.config_manager.register_callback(self._handle_app_config_update)

    def _configure_logging(self) -> None:
        """Configure logging based on settings from config."""
        log_level_str = self.config_manager.get_specific_config("logging.level", "INFO").upper()
        log_level = getattr(logging, log_level_str, logging.INFO)
        logging.getLogger().setLevel(log_level)  # Set root logger level
        for handler in logging.getLogger().handlers:
            handler.setLevel(log_level)
        logger.info(f"Logging level set to {log_level_str}")
        # TODO: Add file logging based on config if specified

    async def _handle_kline_data(self, kline: Kline, market_type: str) -> None:
        """
        Process incoming kline data from WebSocket and trigger signal checks when appropriate.
        Includes error handling to prevent WebSocket callback crashes.
        """
        try:
            # Process the kline data through DataProcessor
            await self.data_processor.process_kline(kline, market_type)
        except Exception as e:
            logger.error(f"Error processing kline for {kline.symbol}: {e}", exc_info=True)
            return  # Skip signal check if data processing fails

        # For V1, only check signals on closed 1m candles
        if kline.interval == "1m" and kline.is_closed:
            try:
                # Find the config_symbol corresponding to kline.symbol (API format)
                config = self.config_manager.get_config()
                target_config_symbol = None
                for cfg_sym, details in config.get("pairs", {}).items():
                    if convert_symbol_to_api_format(cfg_sym) == kline.symbol and details.get("enabled"):
                        target_config_symbol = cfg_sym
                        break
                
                if not target_config_symbol:
                    return  # No enabled config symbol found for this API symbol
                
                # Check if a position is already open for this symbol
                if not self.position_manager.has_open_position(kline.symbol):
                    signal = await self.signal_engine_v1.check_signal(kline.symbol, target_config_symbol)
                    if signal:
                        logger.info(f"Signal generated for {signal.symbol}: {signal.direction.value}")
                        # Double check no position exists
                        if not self.position_manager.has_open_position(signal.symbol):
                            try:
                                await self.order_manager.handle_trade_signal(signal)
                                logger.info(f"Signal processed by OrderManager. Position tracking update will be handled via reconciliation or user data stream.")
                                # Note: In the current architecture, position updates rely on:
                                # 1. User data stream (to be implemented in future)
                                # 2. Periodic reconciliation
                            except Exception as e:
                                logger.error(f"Error handling trade signal for {signal.symbol}: {e}", exc_info=True)
                        else:
                            logger.info(f"Signal for {signal.symbol} ignored, position already open.")
                else:
                    logger.debug(f"Skipping signal check for {kline.symbol}, position already open.")
            except Exception as e:
                logger.error(f"Error during signal processing for {kline.symbol}: {e}", exc_info=True)

    async def _handle_order_update_data(self, order_data: Order) -> None:
        """Handle order updates from user data stream (to be implemented)."""
        logger.info(f"Main: Received order update: {order_data.symbol} ID {order_data.order_id} Status {order_data.status}")
        try:
            await self.position_manager.update_position_on_order_update(order_data)
        except Exception as e:
            logger.error(f"Error updating position based on order update: {e}", exc_info=True)

    def _handle_app_config_update(self, new_config: dict) -> None:
        """Handle configuration updates affecting the main application."""
        logger.info("MainApp: Detected configuration change. Applying updates...")
        self._configure_logging()  # Update log level if changed
        
        # Update active trading pairs
        self.active_trading_pairs = [
            cfg_sym for cfg_sym, details in new_config.get("pairs", {}).items() if details.get("enabled")
        ]
        logger.info(f"Updated active trading pairs: {self.active_trading_pairs}")

    async def start(self) -> None:
        """Start the trading bot and all its components."""
        if self.running:
            logger.warning("Bot is already running.")
            return
        
        logger.info("Starting Binance Futures Trading Bot...")
        self.running = True

        # Initial config load for active pairs
        self._handle_app_config_update(self.config_manager.get_config())

        # Reconcile positions with exchange on startup
        logger.info("Reconciling positions with exchange on startup...")
        try:
            await self.position_manager.reconcile_positions_with_exchange(self.rest_client)
            logger.info("Position reconciliation completed.")
        except Exception as e:
            logger.error(f"Error during position reconciliation: {e}", exc_info=True)

        # Start WebSocket connector
        try:
            await self.ws_connector.start()
            logger.info("WebSocket connector started successfully.")
        except Exception as e:
            logger.error(f"Failed to start WebSocket connector: {e}", exc_info=True)
            self.running = False
            return

        logger.info("Bot is now running. Press Ctrl+C to stop.")
        
        # Main event loop - keep the application alive
        try:
            while self.running:
                await asyncio.sleep(1)
        except asyncio.CancelledError:
            logger.info("Main bot loop cancelled.")

    async def stop(self) -> None:
        """Stop the trading bot and all its components gracefully."""
        if not self.running:
            logger.info("Bot is not running.")
            return
        
        logger.info("Stopping Binance Futures Trading Bot...")
        self.running = False

        # Stop WebSocket connector
        if self.ws_connector:
            try:
                await self.ws_connector.stop()
                logger.info("WebSocket connector stopped successfully.")
            except Exception as e:
                logger.error(f"Error stopping WebSocket connector: {e}", exc_info=True)
        
        # Close REST client connection
        if self.rest_client:
            try:
                await self.rest_client.close_exchange()
                logger.info("REST client closed successfully.")
            except Exception as e:
                logger.error(f"Error closing REST client: {e}", exc_info=True)

        # Stop config watcher
        if self.config_manager:
            try:
                self.config_manager.stop_watcher()
                logger.info("Config manager watcher stopped successfully.")
            except Exception as e:
                logger.error(f"Error stopping config watcher: {e}", exc_info=True)
        
        logger.info("Bot has stopped.")


def handle_sigterm(sig, frame) -> None:
    """
    Handle SIGTERM signal for graceful shutdown.
    Only sets the running flag to False, letting the main loop handle the actual shutdown.
    """
    logger.info("SIGTERM received, initiating graceful shutdown...")
    # Simply set the running flag to False
    if "bot_instance" in globals() and bot_instance:
        bot_instance.running = False
    else:
        logger.warning("Bot instance not found for SIGTERM handler.")

async def main() -> None:
    """Main entry point for the application."""
    global bot_instance  # Make bot instance accessible to signal handler
    bot_instance = None
    
    try:
        bot_instance = TradingBot()
        
        # Register signal handlers for graceful shutdown
        signal.signal(signal.SIGTERM, handle_sigterm)
        
        await bot_instance.start()
    except KeyboardInterrupt:
        logger.info("KeyboardInterrupt received, stopping bot...")
    except Exception as e:
        logger.error(f"Unhandled exception in main: {e}", exc_info=True)
    finally:
        if bot_instance and bot_instance.running:
            await bot_instance.stop()

if __name__ == "__main__":
    # Ensure a config file exists for the bot to run, copy from example if not
    # ConfigManager handles this internally now.
    asyncio.run(main())




================================================
FILE: src/models.py
================================================
from typing import Optional, List, Dict, Any, Literal
from pydantic import BaseModel, Field, validator
import time
from enum import Enum

# Enum for trade direction
class TradeDirection(str, Enum):
    LONG = "BUY"
    SHORT = "SELL"

class Kline(BaseModel):
    timestamp: int # Kline start time in milliseconds
    open: float
    high: float
    low: float
    close: float
    volume: float
    quote_asset_volume: Optional[float] = None # Volume in quote asset
    number_of_trades: Optional[int] = None
    is_closed: bool # True if this kline is closed
    symbol: Optional[str] = None # Trading pair symbol, e.g., BTCUSDT
    interval: Optional[str] = None # Kline interval, e.g., 1m, 5m, 1h

class PairConfig(BaseModel):
    enabled: bool = True
    symbol: str # e.g. BTC_USDT (config format), will be converted for API/WS
    contract_type: Literal["USDT_M", "COIN_M"] = "USDT_M"

    # V1 Strategy specific (can be overridden from global)
    sma_short_period: Optional[int] = None
    sma_long_period: Optional[int] = None
    min_signal_interval_minutes: Optional[int] = None
    tp_sl_ratio: Optional[float] = None
    margin_usdt: Optional[float] = None # For USDT-M
    margin_coin: Optional[float] = None # For COIN-M, in base currency units
    leverage: Optional[int] = None
    margin_mode: Optional[Literal["ISOLATED", "CROSSED"]] = None

    # V2 Strategy specific (can be overridden from global)
    strategy_v2_enabled: Optional[bool] = None
    # ... other V2 params like ema_short_period_1m, stochrsi_k_1m etc.

    # Filter overrides
    volume_filter_enabled: Optional[bool] = None
    # ... other filter params ...

    # Risk management overrides
    dynamic_sizing_enabled: Optional[bool] = None
    risk_percent_per_trade: Optional[float] = None

    @validator("symbol")
    def symbol_format(cls, value):
        # Basic validation, can be expanded
        if "_" not in value and not value.endswith("PERP") and value.isupper():
            pass 
        elif "_" not in value:
            raise ValueError("Symbol in config should generally be in format BASE_QUOTE, e.g., BTC_USDT or end with PERP for COIN-M e.g. BTCUSD_PERP")
        return value

class TradeSignal(BaseModel):
    timestamp: int = Field(default_factory=lambda: int(time.time() * 1000))
    symbol: str # e.g., BTCUSDT (API format)
    config_symbol: str # e.g., BTC_USDT (Config format, for logging/reference)
    contract_type: Literal["USDT_M", "COIN_M"]
    direction: TradeDirection
    entry_price: float # Estimated entry price at signal time (e.g., current close)
    stop_loss_price: float
    take_profit_price: float
    strategy_name: str = "V1_SMA_Crossover" # Or V2_MultiTF_EMA, etc.
    signal_kline: Optional[Kline] = None # The kline that triggered the signal
    details: Optional[Dict[str, Any]] = None # e.g., SMA values, pivot points used for SL

class OrderStatus(str, Enum):
    NEW = "NEW"
    PARTIALLY_FILLED = "PARTIALLY_FILLED"
    FILLED = "FILLED"
    CANCELED = "CANCELED"
    PENDING_CANCEL = "PENDING_CANCEL" 
    REJECTED = "REJECTED"
    EXPIRED = "EXPIRED"

class OrderType(str, Enum):
    LIMIT = "LIMIT"
    MARKET = "MARKET"
    STOP_LOSS = "STOP_LOSS" 
    STOP_LOSS_LIMIT = "STOP_LOSS_LIMIT" 
    TAKE_PROFIT = "TAKE_PROFIT" 
    TAKE_PROFIT_LIMIT = "TAKE_PROFIT_LIMIT" 
    LIMIT_MAKER = "LIMIT_MAKER"
    STOP = "STOP" 
    STOP_MARKET = "STOP_MARKET"
    TAKE_PROFIT_MARKET = "TAKE_PROFIT_MARKET"
    TRAILING_STOP_MARKET = "TRAILING_STOP_MARKET"

class OrderSide(str, Enum):
    BUY = "BUY"
    SELL = "SELL"

class Order(BaseModel):
    order_id: str # Exchange order ID
    client_order_id: Optional[str] = None # Custom order ID
    symbol: str # API format, e.g., BTCUSDT
    type: OrderType
    side: OrderSide
    quantity: float # Order quantity
    price: Optional[float] = None # For LIMIT orders
    stop_price: Optional[float] = None # For STOP_MARKET, TAKE_PROFIT_MARKET etc.
    status: OrderStatus
    timestamp: int # Order creation/update timestamp (milliseconds)
    avg_fill_price: Optional[float] = None
    filled_quantity: Optional[float] = None
    reduce_only: Optional[bool] = False
    commission: Optional[float] = None
    commission_asset: Optional[str] = None

class Position(BaseModel):
    symbol: str # API format, e.g., BTCUSDT
    contract_type: Literal["USDT_M", "COIN_M"]
    side: TradeDirection # LONG or SHORT
    entry_price: float
    quantity: float # Size of the position
    margin_type: Optional[Literal["ISOLATED", "CROSSED"]] = None
    leverage: Optional[int] = None
    unrealized_pnl: Optional[float] = None
    liquidation_price: Optional[float] = None
    mark_price: Optional[float] = None
    entry_timestamp: int = Field(default_factory=lambda: int(time.time() * 1000))
    entry_order_id: Optional[str] = None
    sl_order_id: Optional[str] = None
    tp_order_id: Optional[str] = None
    current_sl_price: Optional[float] = None
    current_tp_price: Optional[float] = None
    trailing_sl_active: Optional[bool] = False

# Example usage (not part of the module, just for illustration)
if __name__ == "__main__":
    kline_data = {
        "timestamp": int(time.time() * 1000),
        "open": 40000.0, "high": 40100.0, "low": 39900.0, "close": 40050.0,
        "volume": 100.0, "is_closed": True, "symbol": "BTCUSDT", "interval": "1m"
    }
    kline_obj = Kline(**kline_data)
    print(f"Kline: {kline_obj.json(indent=2)}")

    pair_cfg_data = {"symbol": "BTC_USDT", "leverage": 20, "margin_usdt": 100}
    pair_cfg_obj = PairConfig(**pair_cfg_data)
    print(f"PairConfig: {pair_cfg_obj.json(indent=2)}")

    signal_data = {
        "symbol": "BTCUSDT", "config_symbol": "BTC_USDT", "contract_type": "USDT_M",
        "direction": TradeDirection.LONG, "entry_price": 40050.0,
        "stop_loss_price": 39800.0, "take_profit_price": 40800.0,
        "details": {"sma_short": 40020, "sma_long": 40000}
    }
    signal_obj = TradeSignal(**signal_data)
    print(f"TradeSignal: {signal_obj.json(indent=2)}")

    order_data = {
        "order_id": "12345", "symbol": "BTCUSDT", "type": OrderType.MARKET, "side": OrderSide.BUY,
        "quantity": 0.001, "status": OrderStatus.FILLED, "timestamp": int(time.time() * 1000),
        "avg_fill_price": 40055.0, "filled_quantity": 0.001
    }
    order_obj = Order(**order_data)
    print(f"Order: {order_obj.json(indent=2)}")

    position_data = {
        "symbol": "BTCUSDT", "contract_type": "USDT_M", "side": TradeDirection.LONG, "entry_price": 40055.0,
        "quantity": 0.001, "leverage": 20, "margin_type": "ISOLATED"
    }
    position_obj = Position(**position_data)
    print(f"Position: {position_obj.json(indent=2)}")




================================================
FILE: src/monitoring.py
================================================
from prometheus_client import start_http_server, Counter, Gauge, Enum, Info
import time
import logging
import asyncio

logger = logging.getLogger(__name__)

class PrometheusMonitor:
    def __init__(self, port: int = 8000):
        self.port = port
        self.start_time = time.time()

        # --- General Metrics ---
        self.bot_info = Info(
            "trading_bot_info", 
            "Information about the trading bot"
        )
        self.bot_uptime_seconds = Gauge(
            "trading_bot_uptime_seconds", 
            "Time in seconds since the bot started"
        )
        self.bot_errors_total = Counter(
            "trading_bot_errors_total", 
            "Total number of critical errors encountered by the bot",
            ["module", "error_type"]
        )

        # --- WebSocket Metrics ---
        self.websocket_connection_status = Enum(
            "trading_bot_websocket_connection_status",
            "Status of the WebSocket connection",
            ["market_type"], # e.g., USDT_M, COIN_M
            states=["connected", "disconnected", "connecting", "error"]
        )
        self.websocket_messages_received_total = Counter(
            "trading_bot_websocket_messages_received_total",
            "Total number of messages received via WebSocket",
            ["market_type", "message_type"] # e.g., kline, depthUpdate, userData
        )

        # --- Data Processing Metrics ---
        self.kline_processed_total = Counter(
            "trading_bot_klines_processed_total",
            "Total number of klines processed",
            ["symbol", "interval"]
        )
        self.indicator_calculation_duration_seconds = Gauge(
            "trading_bot_indicator_calculation_duration_seconds",
            "Duration of the last indicator calculation cycle",
            ["symbol", "interval"]
        )

        # --- Signal Engine Metrics ---
        self.signals_generated_total = Counter(
            "trading_bot_signals_generated_total",
            "Total number of trade signals generated",
            ["symbol", "strategy", "direction"] # e.g., BTCUSDT, V1_SMA, LONG
        )

        # --- Order Management Metrics ---
        self.orders_placed_total = Counter(
            "trading_bot_orders_placed_total",
            "Total number of orders placed",
            ["symbol", "order_type", "side"]
        )
        self.orders_failed_total = Counter(
            "trading_bot_orders_failed_total",
            "Total number of orders that failed to place or were rejected",
            ["symbol", "reason"]
        )
        self.orders_filled_total = Counter(
            "trading_bot_orders_filled_total",
            "Total number of orders filled",
            ["symbol", "order_type", "side"]
        )

        # --- Position Management Metrics ---
        self.active_positions_count = Gauge(
            "trading_bot_active_positions_count",
            "Current number of active positions",
            ["contract_type"] # USDT_M, COIN_M
        )
        self.position_pnl_unrealized = Gauge(
            "trading_bot_position_pnl_unrealized",
            "Unrealized PnL for an active position",
            ["symbol"]
        )

        self._server_started = False

    def start(self):
        if self._server_started:
            logger.warning("Prometheus metrics server already started.")
            return
        try:
            start_http_server(self.port)
            self._server_started = True
            logger.info(f"Prometheus metrics server started on port {self.port}")
            # Set initial info
            self.bot_info.info({"version": "0.1.0-mvp", "name": "BinanceFuturesBot"})
            # Start periodic update of uptime
            asyncio.create_task(self._update_uptime_periodically())
        except OSError as e:
            logger.error(f"Could not start Prometheus server on port {self.port}: {e}. Metrics will not be available.")
        except Exception as e:
            logger.error(f"An unexpected error occurred while starting Prometheus server: {e}")

    async def _update_uptime_periodically(self):
        while self._server_started: # Or a separate running flag for the task
            self.bot_uptime_seconds.set(time.time() - self.start_time)
            await asyncio.sleep(5) # Update every 5 seconds

    def stop(self):
        # The prometheus_client library doesn\t provide a direct way to stop the HTTP server cleanly.
        # It runs in a separate daemon thread. For a real production app, this might need a custom server.
        # For this project, we assume the process termination will handle it.
        logger.info("Prometheus metrics server stopping (typically handled by process exit).")
        self._server_started = False # To stop uptime updates

    # --- Helper methods to update metrics ---
    def inc_bot_error(self, module: str, error_type: str = "general"):
        self.bot_errors_total.labels(module=module, error_type=error_type).inc()

    def set_websocket_status(self, market_type: str, status: str):
        # Ensure status is one of the Enum states
        valid_states = self.websocket_connection_status._states
        if status not in valid_states:
            logger.warning(f"Invalid WebSocket status 	{status}	 for market 	{market_type}	. Valid states: {valid_states}")
            self.websocket_connection_status.labels(market_type=market_type).state("error")
            return
        self.websocket_connection_status.labels(market_type=market_type).state(status)

    def inc_websocket_message(self, market_type: str, message_type: str):
        self.websocket_messages_received_total.labels(market_type=market_type, message_type=message_type).inc()

    def inc_kline_processed(self, symbol: str, interval: str):
        self.kline_processed_total.labels(symbol=symbol, interval=interval).inc()

    def set_indicator_calculation_duration(self, symbol: str, interval: str, duration_seconds: float):
        self.indicator_calculation_duration_seconds.labels(symbol=symbol, interval=interval).set(duration_seconds)

    def inc_signal_generated(self, symbol: str, strategy: str, direction: str):
        self.signals_generated_total.labels(symbol=symbol, strategy=strategy, direction=direction).inc()

    def inc_order_placed(self, symbol: str, order_type: str, side: str):
        self.orders_placed_total.labels(symbol=symbol, order_type=order_type, side=side).inc()

    def inc_order_failed(self, symbol: str, reason: str = "unknown"):
        self.orders_failed_total.labels(symbol=symbol, reason=reason).inc()

    def inc_order_filled(self, symbol: str, order_type: str, side: str):
        self.orders_filled_total.labels(symbol=symbol, order_type=order_type, side=side).inc()

    def set_active_positions_count(self, contract_type: str, count: int):
        self.active_positions_count.labels(contract_type=contract_type).set(count)
    
    def update_active_positions_gauge(self, positions_usdt_m: int, positions_coin_m: int):
        self.set_active_positions_count(contract_type="USDT_M", count=positions_usdt_m)
        self.set_active_positions_count(contract_type="COIN_M", count=positions_coin_m)

    def set_position_pnl(self, symbol: str, pnl: float):
        self.position_pnl_unrealized.labels(symbol=symbol).set(pnl)

# Example Usage (typically integrated into main_app.py)
async def main_monitor_test():
    logging.basicConfig(level=logging.INFO)
    monitor = PrometheusMonitor(port=8088) # Use a different port for testing
    monitor.start()

    # Simulate some bot activity
    monitor.set_websocket_status(market_type="USDT_M", status="connecting")
    await asyncio.sleep(1)
    monitor.set_websocket_status(market_type="USDT_M", status="connected")
    monitor.inc_websocket_message(market_type="USDT_M", message_type="kline")
    monitor.inc_kline_processed(symbol="BTCUSDT", interval="1m")
    monitor.set_indicator_calculation_duration(symbol="BTCUSDT", interval="1m", duration_seconds=0.05)
    monitor.inc_signal_generated(symbol="BTCUSDT", strategy="V1_SMA", direction="LONG")
    monitor.inc_order_placed(symbol="BTCUSDT", order_type="MARKET", side="BUY")
    monitor.inc_order_filled(symbol="BTCUSDT", order_type="MARKET", side="BUY")
    monitor.set_active_positions_count(contract_type="USDT_M", count=1)
    monitor.set_position_pnl(symbol="BTCUSDT", pnl=10.5)
    monitor.inc_bot_error(module="SignalEngine", error_type="DataMissing")

    try:
        while True:
            # Uptime is updated automatically by the monitor itself
            await asyncio.sleep(10)
            logger.info("Monitor test running... check http://localhost:8088/metrics")
    except KeyboardInterrupt:
        logger.info("Stopping monitor test...")
    finally:
        monitor.stop()

if __name__ == "__main__":
    asyncio.run(main_monitor_test())



================================================
FILE: src/order_manager.py
================================================
import logging
import asyncio
import time
from typing import Optional, Dict, Any, Tuple
import math

from src.config_loader import ConfigManager
from src.connectors import BinanceRESTClient, convert_symbol_to_api_format
from src.models import TradeSignal, Order, OrderStatus, OrderType, OrderSide, Position, TradeDirection
# from src.position_manager import PositionManager # Will be used later

logger = logging.getLogger(__name__)

class OrderManager:
    def __init__(self, config_manager: ConfigManager, rest_client: BinanceRESTClient):
        self.config_manager = config_manager
        self.rest_client = rest_client
        # self.position_manager = position_manager # To notify about new positions/orders
        self.exchange_info_cache: Dict[str, Any] = {}

    async def _get_exchange_info_for_symbol(self, api_symbol: str) -> Optional[Dict[str, Any]]:
        if api_symbol in self.exchange_info_cache:
            return self.exchange_info_cache[api_symbol]
        
        markets = await self.rest_client.fetch_exchange_info()
        if markets:
            for market_symbol, market_data in markets.items():
                # ccxt market symbols are usually already in API format (e.g., BTCUSDT)
                # We store all of them for potential future use
                self.exchange_info_cache[market_symbol] = market_data 
            
            if api_symbol in self.exchange_info_cache:
                return self.exchange_info_cache[api_symbol]
            else:
                # Try variations if direct match fails (e.g. if input was BTC/USDT vs BTCUSDT)
                # This part might need refinement based on how symbols are consistently handled.
                normalized_api_symbol = api_symbol.replace("/","")
                if normalized_api_symbol in self.exchange_info_cache:
                    return self.exchange_info_cache[normalized_api_symbol]
                logger.warning(f"Exchange info not found for symbol {api_symbol} after fetching markets.")
                return None
        logger.error(f"Failed to fetch exchange info.")
        return None

    def _adjust_quantity_to_precision(self, quantity: float, step_size: float) -> float:
        if step_size == 0: return quantity # Avoid division by zero if step_size is not set
        # Precision is determined by the number of decimal places in step_size
        # e.g., step_size 0.001 means 3 decimal places
        precision = 0
        if "." in str(step_size):
            precision = len(str(step_size).split(".")[1].rstrip("0"))
        else: # step_size is an integer like 1, 10
            precision = 0
            
        # Floor to the nearest multiple of step_size
        adjusted_quantity = math.floor(quantity / step_size) * step_size
        return round(adjusted_quantity, precision) if precision > 0 else int(adjusted_quantity)

    def _adjust_price_to_precision(self, price: float, tick_size: float) -> float:
        if tick_size == 0: return price
        precision = 0
        if "." in str(tick_size):
            precision = len(str(tick_size).split(".")[1].rstrip("0"))
        else:
            precision = 0
        # For price, usually round to nearest tick_size. Behavior might differ (round, ceil, floor)
        # Let's round for now.
        adjusted_price = round(round(price / tick_size) * tick_size, precision) if precision > 0 else int(round(price / tick_size) * tick_size)
        return adjusted_price

    async def _get_symbol_filters(self, api_symbol: str) -> Tuple[Optional[float], Optional[float], Optional[float]]:
        """ Returns (lot_step_size, price_tick_size, min_notional) """
        market_info = await self._get_exchange_info_for_symbol(api_symbol)
        if not market_info:
            logger.warning(f"Cannot get filters for {api_symbol}, market info not found.")
            return None, None, None

        lot_step_size = None
        price_tick_size = None
        min_notional = None

        try:
            # CCXT structure for precision and limits:
            # market_info["precision"]["amount"] -> quantity precision (step size)
            # market_info["precision"]["price"] -> price precision (tick size)
            # market_info["limits"]["cost"]["min"] -> min notional value
            # market_info["limits"]["amount"]["min"] -> min quantity

            if market_info.get("precision") and market_info["precision"].get("amount") is not None:
                lot_step_size = float(market_info["precision"]["amount"])
            
            if market_info.get("precision") and market_info["precision"].get("price") is not None:
                price_tick_size = float(market_info["precision"]["price"])

            if market_info.get("limits", {}).get("cost", {}).get("min") is not None:
                min_notional = float(market_info["limits"]["cost"]["min"])
            elif market_info.get("info", {}).get("filters"):
                # Fallback for direct Binance API structure if ccxt doesn't normalize it fully
                for f in market_info["info"]["filters"]:
                    if f["filterType"] == "LOT_SIZE":
                        lot_step_size = float(f["stepSize"])
                    elif f["filterType"] == "PRICE_FILTER":
                        price_tick_size = float(f["tickSize"])
                    elif f["filterType"] == "MIN_NOTIONAL":
                        min_notional = float(f.get("notional", f.get("minNotional"))) # Binance uses "notional" or "minNotional"
            
            if lot_step_size is None: logger.warning(f"Lot step size not found for {api_symbol}")
            if price_tick_size is None: logger.warning(f"Price tick size not found for {api_symbol}")
            if min_notional is None: logger.warning(f"Min notional not found for {api_symbol}")

        except KeyError as e:
            logger.error(f"KeyError accessing filter info for {api_symbol}: {e}. Market info: {market_info}")
        except Exception as e:
            logger.error(f"Error parsing filters for {api_symbol}: {e}. Market info: {market_info}")
            
        return lot_step_size, price_tick_size, min_notional

    async def handle_trade_signal(self, signal: TradeSignal):
        logger.info(f"OrderManager received signal: {signal.symbol} {signal.direction.value} at {signal.entry_price}")
        config = self.config_manager.get_config()
        pair_configs = config.get("pairs", {})
        global_v1_config = config.get("global_settings", {}).get("v1_strategy", {})
        api_symbol = signal.symbol # Already in API format from signal

        pair_details = {}
        for cfg_sym, details in pair_configs.items():
            if convert_symbol_to_api_format(cfg_sym) == api_symbol:
                pair_details = details
                break
        
        if not pair_details:
            logger.error(f"No configuration found for symbol {api_symbol} in OrderManager.")
            return

        # 1. Set Margin Type and Leverage
        margin_mode = pair_details.get("margin_mode", global_v1_config.get("margin_mode", "ISOLATED"))
        leverage = pair_details.get("leverage", global_v1_config.get("default_leverage", 10))

        # These calls might not be needed if already set and not changing per trade.
        # However, good practice to ensure they are as expected.
        # await self.rest_client.set_margin_mode(api_symbol, margin_mode)
        # await self.rest_client.set_leverage(api_symbol, leverage)
        # For now, assume they are pre-set or handle this in a setup phase.
        # logger.info(f"Ensured margin mode {margin_mode} and leverage {leverage}x for {api_symbol}")

        # 2. Calculate Position Size (MVP: Fixed Margin Allocation)
        # TODO: Implement dynamic position sizing later
        fixed_margin_usdt = pair_details.get("margin_usdt", global_v1_config.get("default_margin_usdt"))
        fixed_margin_coin = pair_details.get("margin_coin") # For COIN-M
        entry_price = signal.entry_price
        quantity: Optional[float] = None

        lot_step, price_tick, min_notional_val = await self._get_symbol_filters(api_symbol)
        if lot_step is None or price_tick is None:
            logger.error(f"Could not get precision filters for {api_symbol}. Aborting trade.")
            return

        if signal.contract_type == "USDT_M":
            if fixed_margin_usdt and entry_price > 0:
                quantity_raw = (fixed_margin_usdt * leverage) / entry_price
                quantity = self._adjust_quantity_to_precision(quantity_raw, lot_step)
            else:
                logger.error(f"Invalid fixed_margin_usdt or entry_price for {api_symbol} (USDT-M).")
                return
        elif signal.contract_type == "COIN_M":
            # For COIN-M, quantity is in number of contracts. Value of 1 contract is e.g. 10 USD or 100 USD.
            # Margin is in base currency (e.g. BTC for BTCUSD_PERP).
            # Size = (MarginInBase * Leverage * EntryPrice) / ContractValueInQuote (if contract value is fixed in quote)
            # Or more simply: SizeInContracts = (MarginInBase * Leverage) / (MarginRequiredPerContractInBase)
            # Binance API for COIN-M: quantity is number of contracts.
            # Let's assume `fixed_margin_coin` is the amount of base currency to risk.
            # The actual USD value of this margin fluctuates.
            # Position size in contracts: (Margin_in_Coin * Leverage) / (InitialMarginPerContract_in_Coin)
            # InitialMarginPerContract_in_Coin = (ContractValue_in_USD / EntryPrice_USD) / Leverage (this is circular)
            # Simpler: Quantity_in_Contracts = (Margin_In_Coin * Leverage * EntryPrice_QuotePerBase) / Contract_FaceValue_In_Quote
            # This needs contract size info (e.g. 1 contract = 100 USD for BTCUSD_PERP)
            # For now, let's assume a simpler model if `fixed_margin_coin` is defined as number of contracts to trade directly.
            # This part needs careful review of COIN-M contract specs.
            # A common approach: if contract value is $100, margin is 0.01 BTC, leverage 10x, entry $50k
            # Total exposure in BTC = 0.01 * 10 = 0.1 BTC. Total exposure in USD = 0.1 * 50000 = $5000
            # Number of contracts = $5000 / $100_per_contract = 50 contracts.
            # So, quantity = (fixed_margin_coin * leverage * entry_price) / contract_value_quote
            # This requires `contract_value_quote` from exchange info or config.
            # For MVP, let's assume `fixed_margin_coin` IS the number of contracts if provided, else error.
            # This is a simplification and likely incorrect for general COIN-M. 
            # A better MVP for COIN-M might be to require quantity directly in config for COIN-M pairs.
            if fixed_margin_coin is not None: # Assuming fixed_margin_coin is intended as # of contracts for MVP
                quantity_raw = fixed_margin_coin # This is a placeholder assumption
                logger.warning(f"COIN-M quantity calculation using 'margin_coin' as number of contracts. Review for correctness.")
                quantity = self._adjust_quantity_to_precision(quantity_raw, lot_step)
            else:
                logger.error(f"COIN-M trading requires 'margin_coin' (interpreted as num_contracts for MVP) or a more robust sizing logic. {api_symbol}")
                return
        else:
            logger.error(f"Unknown contract type: {signal.contract_type} for {api_symbol}")
            return

        if quantity is None or quantity <= 0:
            logger.error(f"Calculated quantity is zero or invalid for {api_symbol}: {quantity}")
            return
        
        # Check min notional if applicable
        if min_notional_val and entry_price > 0:
            notional_value = quantity * entry_price
            # For COIN-M, notional value is trickier as it depends on contract multiplier
            # if signal.contract_type == "COIN_M": # Need contract multiplier
            #    pass 
            if signal.contract_type == "USDT_M" and notional_value < min_notional_val:
                logger.warning(f"Order for {api_symbol} notional {notional_value} is less than min_notional {min_notional_val}. Skipping.")
                return

        # 3. Place Entry Order (MARKET)
        order_side = OrderSide.BUY if signal.direction == TradeDirection.LONG else OrderSide.SELL
        entry_order_params = {"newOrderRespType": "RESULT"} # To get full order details
        logger.info(f"Placing entry order for {api_symbol}: {order_side.value} {quantity} units at MARKET price.")
        entry_order_response = await self.rest_client.create_order(
            symbol=api_symbol, 
            order_type=OrderType.MARKET, 
            side=order_side, 
            amount=quantity, 
            params=entry_order_params
        )

        if not entry_order_response or "id" not in entry_order_response or entry_order_response.get("status") == OrderStatus.REJECTED:
            logger.error(f"Failed to place entry order for {api_symbol}. Response: {entry_order_response}")
            return
        
        entry_order_id = entry_order_response["id"]
        logger.info(f"Entry order placed for {api_symbol}. ID: {entry_order_id}, Status: {entry_order_response.get("status")}")

        # Wait for entry order to fill (or partial fill if handling that)
        # For MARKET orders, they usually fill quickly. Polling might be needed for LIMIT.
        # For simplicity, assume MARKET order fills almost instantly for MVP.
        # A robust system would poll order status or use user data stream.
        # Let's assume we get avgFillPrice from the response if available, or use signal.entry_price
        actual_entry_price = float(entry_order_response.get("avgPrice", signal.entry_price)) 
        if actual_entry_price == 0 and entry_order_response.get("status") == OrderStatus.FILLED:
             actual_entry_price = float(entry_order_response.get("fills",[{}])[0].get("price", signal.entry_price))
        if actual_entry_price == 0 : actual_entry_price = signal.entry_price # Fallback

        # 4. Place SL and TP Orders (STOP_MARKET and TAKE_PROFIT_MARKET with reduceOnly)
        sl_tp_side = OrderSide.SELL if signal.direction == TradeDirection.LONG else OrderSide.BUY
        
        # Adjust SL/TP prices to precision
        adjusted_sl_price = self._adjust_price_to_precision(signal.stop_loss_price, price_tick)
        adjusted_tp_price = self._adjust_price_to_precision(signal.take_profit_price, price_tick)

        sl_order_params = {"reduceOnly": "true"}
        logger.info(f"Placing SL order for {api_symbol}: {sl_tp_side.value} {quantity} units, stopPrice {adjusted_sl_price:.{self._get_price_precision(price_tick)}f}")
        sl_order_response = await self.rest_client.create_order(
            symbol=api_symbol, 
            order_type=OrderType.STOP_MARKET, 
            side=sl_tp_side, 
            amount=quantity, 
            params={**sl_order_params, "stopPrice": adjusted_sl_price}
        )

        if not sl_order_response or "id" not in sl_order_response:
            logger.error(f"Failed to place SL order for {api_symbol}. Response: {sl_order_response}. Entry order {entry_order_id} might need manual SL.")
            # Potentially try to close the position if SL cannot be placed
        else:
            logger.info(f"SL order placed for {api_symbol}. ID: {sl_order_response["id"]}")

        tp_order_params = {"reduceOnly": "true"}
        logger.info(f"Placing TP order for {api_symbol}: {sl_tp_side.value} {quantity} units, stopPrice {adjusted_tp_price:.{self._get_price_precision(price_tick)}f}")
        tp_order_response = await self.rest_client.create_order(
            symbol=api_symbol, 
            order_type=OrderType.TAKE_PROFIT_MARKET, 
            side=sl_tp_side, 
            amount=quantity, 
            params={**tp_order_params, "stopPrice": adjusted_tp_price}
        )

        if not tp_order_response or "id" not in tp_order_response:
            logger.error(f"Failed to place TP order for {api_symbol}. Response: {tp_order_response}. Entry order {entry_order_id} might need manual TP.")
        else:
            logger.info(f"TP order placed for {api_symbol}. ID: {tp_order_response["id"]}")

        # TODO: Notify PositionManager about the new position and associated orders
        # position_data = Position(
        #     symbol=api_symbol,
        #     contract_type=signal.contract_type,
        #     side=signal.direction,
        #     entry_price=actual_entry_price,
        #     quantity=quantity,
        #     leverage=leverage,
        #     margin_type=margin_mode,
        #     entry_order_id=entry_order_id,
        #     sl_order_id=sl_order_response.get("id") if sl_order_response else None,
        #     tp_order_id=tp_order_response.get("id") if tp_order_response else None,
        #     current_sl_price=adjusted_sl_price,
        #     current_tp_price=adjusted_tp_price
        # )
        # await self.position_manager.add_or_update_position(position_data)
        logger.info(f"Trade execution process completed for signal on {api_symbol}.")

    def _get_price_precision(self, tick_size: float) -> int:
        if tick_size == 0: return 8 # Default high precision if tick_size is 0
        if "." in str(tick_size):
            return len(str(tick_size).split(".")[1].rstrip("0"))
        return 0

# Example Usage (for integration testing, not standalone run)
async def main_order_manager_test():
    logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s")
    
    class MockConfigManager:
        def get_config(self):
            return {
                "api": {"binance_api_key": "SIM_KEY", "binance_api_secret": "SIM_SECRET"}, # Simulate real keys for REST client init
                "global_settings": {
                    "v1_strategy": {
                        "default_margin_usdt": 50,
                        "default_leverage": 10,
                        "margin_mode": "ISOLATED"
                    }
                },
                "pairs": {
                    "BTC_USDT": {"enabled": True, "contract_type": "USDT_M", "margin_usdt": 100, "leverage": 20},
                    "ETHUSD_PERP": {"enabled": True, "contract_type": "COIN_M", "margin_coin": 0.1, "leverage": 10} # margin_coin as num_contracts
                }
            }
        def register_callback(self, cb): pass
        def stop_watcher(self): pass

    class MockBinanceRESTClient:
        def __init__(self, cfg):
            logger.info("MockBinanceRESTClient initialized")
            self.exchange_info_data = {
                "BTCUSDT": {"precision": {"amount": "0.00001", "price": "0.01"}, "limits": {"cost": {"min": "10"}}},
                "ETHUSD_PERP": {"precision": {"amount": "1", "price": "0.01"}, "limits": {"cost": {"min": "5"}}} # COIN-M contracts are usually integers
            }
        async def fetch_exchange_info(self): return self.exchange_info_data
        async def create_order(self, symbol, order_type, side, amount, price=None, params={}):
            order_id = f"mock_{order_type.lower()}_{int(time.time()*1000)}"
            logger.info(f"MOCK Create Order: {symbol}, {order_type}, {side}, {amount}, Price: {price}, Params: {params}, ID: {order_id}")
            avg_price = price or (params.get("stopPrice") if order_type != OrderType.MARKET else 50000.0) # Simulate some fill price
            return {"id": order_id, "symbol": symbol, "status": "NEW", "avgPrice": str(avg_price), "type": order_type}
        async def set_leverage(self, symbol, leverage, params={}): logger.info(f"MOCK Set Leverage: {symbol} to {leverage}x"); return True
        async def set_margin_mode(self, symbol, mode, params={}): logger.info(f"MOCK Set Margin Mode: {symbol} to {mode}"); return True
        async def close_exchange(self): pass

    cfg = MockConfigManager()
    rest_client = MockBinanceRESTClient(cfg) # Use mock for testing
    order_manager = OrderManager(cfg, rest_client)

    # Test USDT-M signal
    usdt_signal = TradeSignal(
        symbol="BTCUSDT", config_symbol="BTC_USDT", contract_type="USDT_M",
        direction=TradeDirection.LONG, entry_price=50000.0,
        stop_loss_price=49000.0, take_profit_price=53000.0
    )
    logger.info("--- Testing USDT-M Signal ---")
    await order_manager.handle_trade_signal(usdt_signal)

    await asyncio.sleep(1) # Ensure logs are flushed

    # Test COIN-M signal
    coinm_signal = TradeSignal(
        symbol="ETHUSD_PERP", config_symbol="ETHUSD_PERP", contract_type="COIN_M",
        direction=TradeDirection.SHORT, entry_price=3000.0,
        stop_loss_price=3100.0, take_profit_price=2700.0
    )
    logger.info("--- Testing COIN-M Signal ---")
    await order_manager.handle_trade_signal(coinm_signal)
    
    await rest_client.close_exchange()

if __name__ == "__main__":
    asyncio.run(main_order_manager_test())



================================================
FILE: src/position_manager.py
================================================
import logging
from typing import Dict, Optional, List
from threading import RLock # For thread-safe access to positions dictionary

from src.models import Position, Order, OrderStatus, TradeDirection
from src.config_loader import ConfigManager # For potential config needs

logger = logging.getLogger(__name__)

class PositionManager:
    def __init__(self, config_manager: ConfigManager):
        self.config_manager = config_manager
        # self.positions: Dict[str, Position] = {}  # Key: api_symbol (e.g., BTCUSDT)
        # A symbol can have only one position in Binance Futures (either LONG or SHORT, not both simultaneously unless in Hedge Mode)
        # For non-Hedge mode, a new trade in opposite direction first closes/reduces existing one.
        # Our bot logic (at least for V1) will likely manage one position per symbol at a time.
        self._positions: Dict[str, Position] = {}
        self._lock = RLock()

    async def add_or_update_position(self, position_data: Position):
        """Adds a new position or updates an existing one based on symbol."""
        with self._lock:
            api_symbol = position_data.symbol
            if api_symbol in self._positions:
                # This would typically mean an update, e.g., SL/TP moved, or PnL update
                # For MVP, a new signal might replace an old position after it is closed.
                # For now, let simple replacement happen if a new position is explicitly added.
                logger.info(f"Updating existing position for {api_symbol}.")
            else:
                logger.info(f"Adding new position for {api_symbol}.")
            self._positions[api_symbol] = position_data
            logger.debug(f"Position for {api_symbol} added/updated: {position_data}")

    async def remove_position(self, api_symbol: str):
        """Removes a position, typically after it has been closed."""
        with self._lock:
            if api_symbol in self._positions:
                logger.info(f"Removing position for {api_symbol}.")
                del self._positions[api_symbol]
            else:
                logger.warning(f"Attempted to remove non-existent position for {api_symbol}.")

    def get_position(self, api_symbol: str) -> Optional[Position]:
        """Retrieves the current position for a given symbol."""
        with self._lock:
            return self._positions.get(api_symbol)

    def get_all_positions(self) -> List[Position]:
        """Retrieves all currently tracked positions."""
        with self._lock:
            return list(self._positions.values())
    
    def has_open_position(self, api_symbol: str) -> bool:
        """Checks if there is an active position for the symbol."""
        with self._lock:
            return api_symbol in self._positions

    async def update_position_on_order_update(self, order: Order):
        """
        Updates position based on an order update (e.g., fill, cancellation).
        This is a crucial part that would typically be driven by user data stream.
        For MVP, this might be called by OrderManager after an order is confirmed filled/cancelled.
        """
        with self._lock:
            api_symbol = order.symbol
            position = self.get_position(api_symbol)

            if not position:
                # If an order update comes for a symbol with no tracked position, it might be an old order
                # or an order not initiated by this bot session. For now, we ignore.
                # logger.debug(f"Received order update for {api_symbol} but no active position tracked. Order ID: {order.order_id}")
                return

            # Was this order part of our tracked position?
            is_entry_order = order.order_id == position.entry_order_id
            is_sl_order = order.order_id == position.sl_order_id
            is_tp_order = order.order_id == position.tp_order_id

            if not (is_entry_order or is_sl_order or is_tp_order):
                # logger.debug(f"Order {order.order_id} for {api_symbol} not related to current tracked position.")
                return

            logger.info(f"Processing order update for position {api_symbol}. Order ID: {order.order_id}, Status: {order.status}")

            if order.status == OrderStatus.FILLED:
                if is_entry_order:
                    # Entry order filled. Position is now fully active.
                    # Update entry price if it was a market order and avgFillPrice is available.
                    if order.avg_fill_price and order.avg_fill_price > 0:
                        logger.info(f"Updating entry price for {api_symbol} from {position.entry_price} to {order.avg_fill_price} based on fill.")
                        position.entry_price = order.avg_fill_price
                    # Potentially update quantity if partial fill handling is added
                    position.quantity = order.filled_quantity or position.quantity
                    logger.info(f"Entry order {order.order_id} for {api_symbol} filled. Position active.")
                
                elif is_sl_order:
                    logger.info(f"Stop-loss order {order.order_id} for {api_symbol} FILLED. Position closed.")
                    # Position closed by SL. Remove it.
                    # Before removing, one might want to log PnL, etc.
                    await self.remove_position(api_symbol)
                    # TODO: Cancel the corresponding TP order if it is still open
                    if position.tp_order_id:
                        logger.info(f"Attempting to cancel TP order {position.tp_order_id} for closed position {api_symbol}")
                        # await self.rest_client.cancel_order(position.tp_order_id, api_symbol) # Requires rest_client here

                elif is_tp_order:
                    logger.info(f"Take-profit order {order.order_id} for {api_symbol} FILLED. Position closed.")
                    # Position closed by TP. Remove it.
                    await self.remove_position(api_symbol)
                    # TODO: Cancel the corresponding SL order if it is still open
                    if position.sl_order_id:
                        logger.info(f"Attempting to cancel SL order {position.sl_order_id} for closed position {api_symbol}")
                        # await self.rest_client.cancel_order(position.sl_order_id, api_symbol)
            
            elif order.status == OrderStatus.CANCELED:
                # If an SL or TP order is canceled, we need to handle it.
                # Maybe the bot decided to close the position manually, or an error occurred.
                if is_sl_order:
                    logger.warning(f"SL order {order.order_id} for {api_symbol} was CANCELED. Position might be unprotected.")
                    position.sl_order_id = None # Mark SL as no longer active
                elif is_tp_order:
                    logger.warning(f"TP order {order.order_id} for {api_symbol} was CANCELED.")
                    position.tp_order_id = None
                # If entry order is canceled, the position was never truly opened.
                elif is_entry_order:
                    logger.warning(f"Entry order {order.order_id} for {api_symbol} was CANCELED. Removing tentative position.")
                    await self.remove_position(api_symbol)
            
            elif order.status == OrderStatus.REJECTED:
                logger.error(f"Order {order.order_id} for {api_symbol} was REJECTED.")
                if is_entry_order:
                    await self.remove_position(api_symbol)
                elif is_sl_order:
                    position.sl_order_id = None
                elif is_tp_order:
                    position.tp_order_id = None
                # This state requires careful handling - why was it rejected?

            # Persist the updated position state (if not removed)
            if self.get_position(api_symbol):
                 self._positions[api_symbol] = position # Ensure the modified position object is stored back

    # Placeholder for fetching positions from exchange on startup (reconciliation)
    async def reconcile_positions_with_exchange(self, rest_client: any):
        """
        Fetches open positions from the exchange and updates internal state.
        Useful on startup to sync with any positions already open on Binance.
        `rest_client` is passed here as PositionManager might not always have it directly.
        """
        with self._lock:
            logger.info("Reconciling positions with exchange...")
            try:
                exchange_positions = await rest_client.fetch_positions() # Fetches all open positions
                if exchange_positions is None: # Error occurred during fetch
                    logger.error("Failed to fetch positions from exchange for reconciliation.")
                    return

                current_bot_symbols = set(self._positions.keys())
                exchange_symbols_with_pos = set()

                for pos_data in exchange_positions:
                    api_symbol = pos_data.get("symbol")
                    if not api_symbol: continue
                    exchange_symbols_with_pos.add(api_symbol)

                    # Basic conversion from ccxt position structure to our Position model
                    # This needs to be robust and handle various fields from ccxt
                    qty = float(pos_data.get("contracts", pos_data.get("amount", 0)))
                    if qty == 0: # No actual position, skip
                        if api_symbol in self._positions: # If bot thought it had a position, remove it
                            logger.info(f"Reconciliation: Exchange shows no position for {api_symbol}, removing from bot state.")
                            del self._positions[api_symbol]
                        continue
                    
                    side = TradeDirection.LONG if qty > 0 else TradeDirection.SHORT
                    entry_price = float(pos_data.get("entryPrice", 0))
                    
                    # Create or update bot's internal position state
                    # This is a simplified reconciliation. A full one would also check SL/TP orders.
                    reconciled_pos = Position(
                        symbol=api_symbol,
                        contract_type="USDT_M" if "USDT" in api_symbol else "COIN_M", # Basic assumption
                        side=side,
                        entry_price=entry_price,
                        quantity=abs(qty),
                        margin_type=pos_data.get("marginType"),
                        leverage=int(pos_data.get("leverage",0)),
                        unrealized_pnl=float(pos_data.get("unrealizedPnl",0)),
                        liquidation_price=float(pos_data.get("liquidationPrice",0)),
                        mark_price=float(pos_data.get("markPrice",0)),
                        # SL/TP order IDs are not directly available from fetch_positions, would need separate logic
                    )
                    self._positions[api_symbol] = reconciled_pos
                    logger.info(f"Reconciliation: Synced position for {api_symbol} from exchange: {side.value} {abs(qty)} @ {entry_price}")

                # Remove positions tracked by bot but not on exchange
                for sym_in_bot in current_bot_symbols:
                    if sym_in_bot not in exchange_symbols_with_pos:
                        logger.info(f"Reconciliation: Bot had position for {sym_in_bot}, but not found on exchange. Removing.")
                        del self._positions[sym_in_bot]
                
                logger.info("Position reconciliation completed.")
            except Exception as e:
                logger.error(f"Error during position reconciliation: {e}", exc_info=True)


# Example Usage (for testing purposes)
async def main_position_manager_test():
    logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s")

    class MockConfigManager:
        def get_config(self): return {}
        def register_callback(self, cb): pass

    cfg_manager = MockConfigManager()
    position_manager = PositionManager(config_manager=cfg_manager)

    # Test adding a position
    pos1_data = Position(
        symbol="BTCUSDT", contract_type="USDT_M", side=TradeDirection.LONG, entry_price=50000,
        quantity=0.001, entry_order_id="entry1", sl_order_id="sl1", tp_order_id="tp1"
    )
    await position_manager.add_or_update_position(pos1_data)
    print(f"Position for BTCUSDT: {position_manager.get_position('BTCUSDT')}")
    print(f"All positions: {position_manager.get_all_positions()}")

    # Test updating a position (e.g. SL moved, not fully implemented here but shows add_or_update)
    pos1_updated_data = Position(
        symbol="BTCUSDT", contract_type="USDT_M", side=TradeDirection.LONG, entry_price=50000,
        quantity=0.001, entry_order_id="entry1", sl_order_id="sl1_moved", tp_order_id="tp1"
    )
    await position_manager.add_or_update_position(pos1_updated_data)
    print(f"Updated Position for BTCUSDT: {position_manager.get_position('BTCUSDT')}")

    # Test order update - SL filled
    sl_fill_order = Order(
        order_id="sl1_moved", client_order_id="", symbol="BTCUSDT", type="STOP_MARKET", side="SELL",
        quantity=0.001, status=OrderStatus.FILLED, timestamp=1234567890, avg_fill_price=49000, filled_quantity=0.001
    )
    await position_manager.update_position_on_order_update(sl_fill_order)
    print(f"Position for BTCUSDT after SL fill: {position_manager.get_position('BTCUSDT')}") # Should be None
    assert position_manager.get_position('BTCUSDT') is None

    # Test adding another position
    pos2_data = Position(
        symbol="ETHUSDT", contract_type="USDT_M", side=TradeDirection.SHORT, entry_price=3000,
        quantity=0.05, entry_order_id="entry2", sl_order_id="sl2", tp_order_id="tp2"
    )
    await position_manager.add_or_update_position(pos2_data)
    print(f"All positions: {position_manager.get_all_positions()}")

    # Test removing a position directly
    await position_manager.remove_position("ETHUSDT")
    print(f"All positions after ETHUSDT removal: {position_manager.get_all_positions()}")
    assert position_manager.get_position('ETHUSDT') is None

if __name__ == "__main__":
    import asyncio
    asyncio.run(main_position_manager_test())



================================================
FILE: src/signal_engine.py
================================================
import logging
import time
import pandas as pd
from typing import Optional, Dict, Any, Tuple

from src.config_loader import ConfigManager
from src.data_processor import DataProcessor
from src.models import TradeSignal, TradeDirection, Kline
from src.connectors import convert_symbol_to_api_format, convert_symbol_to_ws_format # For consistency

logger = logging.getLogger(__name__)

class SignalEngineV1:
    def __init__(self, config_manager: ConfigManager, data_processor: DataProcessor):
        self.config_manager = config_manager
        self.data_processor = data_processor
        self.last_signal_time: Dict[str, float] = {} # Stores timestamp of the last signal for each pair

    def _get_pair_specific_config(self, config_symbol: str) -> Dict[str, Any]:
        config = self.config_manager.get_config()
        pair_configs = config.get("pairs", {})
        global_v1_config = config.get("global_settings", {}).get("v1_strategy", {})
        
        pair_specific_overrides = {}
        for cfg_sym, details in pair_configs.items():
            if cfg_sym.upper() == config_symbol.upper(): # Match config_symbol (e.g. BTC_USDT)
                pair_specific_overrides = details
                break
        
        return {
            "sma_short_period": pair_specific_overrides.get("sma_short_period", global_v1_config.get("sma_short_period", 21)),
            "sma_long_period": pair_specific_overrides.get("sma_long_period", global_v1_config.get("sma_long_period", 200)),
            "min_signal_interval_minutes": pair_specific_overrides.get("min_signal_interval_minutes", global_v1_config.get("min_signal_interval_minutes", 15)),
            "tp_sl_ratio": pair_specific_overrides.get("tp_sl_ratio", global_v1_config.get("tp_sl_ratio", 3.0)),
            "contract_type": pair_specific_overrides.get("contract_type", "USDT_M") # Default to USDT_M
        }

    def _find_recent_pivot(self, klines_df: pd.DataFrame, lookback: int = 10, direction: TradeDirection = TradeDirection.LONG) -> Optional[float]:
        """Finds the most recent significant pivot low (for LONG) or high (for SHORT)."""
        if klines_df is None or klines_df.empty or len(klines_df) < 3:
            return None

        # Ensure we only look at a recent window of closed candles for pivots
        # The signal candle itself is usually the last one, so we look before it.
        relevant_klines = klines_df[klines_df["is_closed"]].iloc[-lookback-1:-1] # Look at N closed candles before the signal candle
        if len(relevant_klines) < 3:
             relevant_klines = klines_df[klines_df["is_closed"]].iloc[-len(klines_df):-1] # use all available if not enough
             if len(relevant_klines) < 3:
                return None

        if direction == TradeDirection.LONG:
            # Find pivot lows: low[i] < low[i-1] and low[i] < low[i+1]
            # For simplicity, let\"s find the minimum low in the lookback window as a proxy for recent support
            # A more robust pivot detection would use scipy.signal.find_peaks or similar
            min_low = relevant_klines["low"].min()
            return min_low
        else: # TradeDirection.SHORT
            # Find pivot highs: high[i] > high[i-1] and high[i] > high[i+1]
            # For simplicity, let\"s find the maximum high in the lookback window as a proxy for recent resistance
            max_high = relevant_klines["high"].max()
            return max_high

    async def check_signal(self, api_symbol: str, config_symbol: str) -> Optional[TradeSignal]:
        """Checks for a V1 SMA crossover signal for the given API symbol (e.g., BTCUSDT)."""
        pair_config = self._get_pair_specific_config(config_symbol)
        if not pair_config: 
            # logger.debug(f"No configuration found for {config_symbol} in SignalEngineV1")
            return None

        # V1 strategy uses 1-minute timeframe for signals
        signal_interval = "1m"
        df = self.data_processor.get_indicator_dataframe(api_symbol, signal_interval)

        if df is None or df.empty or len(df) < 2:
            # logger.debug(f"Not enough data for {api_symbol} {signal_interval} to generate signal.")
            return None

        # Get the latest two candles for crossover detection
        latest = df.iloc[-1]
        previous = df.iloc[-2]

        sma_short_col = "sma_short"
        sma_long_col = "sma_long"

        if not all(col in latest.index and col in previous.index for col in [sma_short_col, sma_long_col, "close", "is_closed"]):
            # logger.debug(f"SMA data not available for {api_symbol} {signal_interval}.")
            return None
        
        # Ensure latest candle data is present and SMAs are calculated
        if pd.isna(latest[sma_short_col]) or pd.isna(latest[sma_long_col]) or \
           pd.isna(previous[sma_short_col]) or pd.isna(previous[sma_long_col]):
            # logger.debug(f"SMA values are NA for {api_symbol} {signal_interval}. Latest: {latest[sma_short_col]}, {latest[sma_long_col]}. Previous: {previous[sma_short_col]}, {previous[sma_long_col]}")
            return None

        # --- Significance Filter (Time-based) ---
        min_interval_seconds = pair_config["min_signal_interval_minutes"] * 60
        current_time = time.time()
        if api_symbol in self.last_signal_time and (current_time - self.last_signal_time[api_symbol]) < min_interval_seconds:
            # logger.debug(f"Signal for {api_symbol} too soon. Last signal at {self.last_signal_time[api_symbol]}, current: {current_time}")
            return None

        # --- SMA Crossover Detection ---
        # Ensure we are checking on a closed candle or a very recent candle
        # The signal is based on the state at the close of the \"previous\" candle that caused the crossover, 
        # and the \"latest\" candle confirms it.
        # Let\"s assume the signal is valid if the crossover happened on the \"latest\" candle compared to \"previous\".
        
        crossed_up = (previous[sma_short_col] <= previous[sma_long_col] and
                      latest[sma_short_col] > latest[sma_long_col])
        crossed_down = (previous[sma_short_col] >= previous[sma_long_col] and
                        latest[sma_short_col] < latest[sma_long_col])

        signal_direction: Optional[TradeDirection] = None
        if crossed_up:
            signal_direction = TradeDirection.LONG
        elif crossed_down:
            signal_direction = TradeDirection.SHORT
        else:
            return None # No crossover

        # --- SL/TP Calculation ---
        entry_price = latest["close"] # Current close price as entry
        stop_loss_price: Optional[float] = None
        take_profit_price: Optional[float] = None
        tp_sl_ratio = pair_config["tp_sl_ratio"]

        # Use a lookback of N candles for pivot detection, e.g., 20-50 candles for 1m chart
        # The klines for pivot detection should be from the main DataFrame `df`
        pivot_lookback = 30 # Number of 1-minute candles to look back for pivot

        if signal_direction == TradeDirection.LONG:
            pivot_low = self._find_recent_pivot(df, lookback=pivot_lookback, direction=TradeDirection.LONG)
            if pivot_low is not None:
                # Add a small buffer to SL, e.g., a few ticks or a percentage
                # For simplicity, direct use for now. Buffer can be added from config.
                stop_loss_price = pivot_low 
                risk = entry_price - stop_loss_price
                if risk <= 0: # Invalid SL (e.g. pivot_low >= entry_price)
                    logger.warning(f"Invalid SL for LONG {api_symbol}: entry={entry_price}, pivot_low={pivot_low}. Skipping signal.")
                    return None
                take_profit_price = entry_price + (risk * tp_sl_ratio)
            else:
                logger.warning(f"Could not determine pivot low for LONG SL for {api_symbol}. Skipping signal.")
                return None
        else: # TradeDirection.SHORT
            pivot_high = self._find_recent_pivot(df, lookback=pivot_lookback, direction=TradeDirection.SHORT)
            if pivot_high is not None:
                stop_loss_price = pivot_high
                risk = stop_loss_price - entry_price
                if risk <= 0: # Invalid SL (e.g. pivot_high <= entry_price)
                    logger.warning(f"Invalid SL for SHORT {api_symbol}: entry={entry_price}, pivot_high={pivot_high}. Skipping signal.")
                    return None
                take_profit_price = entry_price - (risk * tp_sl_ratio)
            else:
                logger.warning(f"Could not determine pivot high for SHORT SL for {api_symbol}. Skipping signal.")
                return None

        if stop_loss_price is None or take_profit_price is None:
            logger.warning(f"Failed to calculate SL/TP for {api_symbol}. Skipping signal.")
            return None
        
        # Ensure SL and TP are not the same as entry or inverted
        if (signal_direction == TradeDirection.LONG and (stop_loss_price >= entry_price or take_profit_price <= entry_price)) or \
           (signal_direction == TradeDirection.SHORT and (stop_loss_price <= entry_price or take_profit_price >= entry_price)):
            logger.warning(f"Calculated SL/TP invalid for {api_symbol}: E={entry_price}, SL={stop_loss_price}, TP={take_profit_price}. Skipping signal.")
            return None

        self.last_signal_time[api_symbol] = current_time
        logger.info(f"Generated signal for {api_symbol}: {signal_direction.value} at {entry_price}, SL={stop_loss_price}, TP={take_profit_price}")

        # Construct signal kline from the latest data point in the DataFrame
        signal_kline_data = latest.to_dict()
        # Ensure all fields required by Kline model are present, add defaults if necessary
        signal_kline_obj = Kline(
            timestamp=int(latest.name), # timestamp is the index
            open=signal_kline_data.get("open"),
            high=signal_kline_data.get("high"),
            low=signal_kline_data.get("low"),
            close=signal_kline_data.get("close"),
            volume=signal_kline_data.get("volume"),
            is_closed=signal_kline_data.get("is_closed", True), # Assume closed if it triggered signal logic
            symbol=api_symbol,
            interval=signal_interval
        )

        return TradeSignal(
            symbol=api_symbol,
            config_symbol=config_symbol,
            contract_type=pair_config["contract_type"],
            direction=signal_direction,
            entry_price=entry_price,
            stop_loss_price=stop_loss_price,
            take_profit_price=take_profit_price,
            strategy_name="V1_SMA_Crossover",
            signal_kline=signal_kline_obj,
            details={
                "sma_short_at_signal": latest[sma_short_col],
                "sma_long_at_signal": latest[sma_long_col],
                "sma_short_previous": previous[sma_short_col],
                "sma_long_previous": previous[sma_long_col],
                "pivot_used_for_sl": pivot_low if signal_direction == TradeDirection.LONG else pivot_high
            }
        )




================================================
FILE: src/utils.py
================================================



================================================
FILE: tests/__init__.py
================================================



================================================
FILE: tests/e2e/__init__.py
================================================



================================================
FILE: tests/integration/__init__.py
================================================



================================================
FILE: tests/integration/test_main_flow.py
================================================
import pytest
import asyncio
import pandas as pd
from unittest.mock import AsyncMock, MagicMock, patch
import os
import yaml

# Ensure src is in path for tests if running pytest from root
import sys
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), 	../../	)))

from src.config_loader import ConfigManager
from src.connectors import BinanceRESTClient, BinanceWebSocketConnector, convert_symbol_to_api_format
from src.data_processor import DataProcessor
from src.signal_engine import SignalEngineV1
from src.order_manager import OrderManager
from src.position_manager import PositionManager
from src.models import Kline, TradeSignal, TradeDirection, Order, OrderStatus, Position
from src.main import TradingBot # To test overall orchestration if needed

# --- Test Fixtures --- 
@pytest.fixture(scope="module") # Module scope for heavier setup
def event_loop():
    # Pytest-asyncio provides an event loop by default, but can be explicit if needed
    loop = asyncio.new_event_loop()
    yield loop
    loop.close()

@pytest.fixture
def temp_config_file_for_integration(tmp_path):
    config_dir = tmp_path / "config"
    config_dir.mkdir()
    config_file = config_dir / "config.yaml"
    config_content = """
    api:
      binance_api_key: "INTEGRATION_TEST_KEY" # Use distinct keys for integration tests
      binance_api_secret: "INTEGRATION_TEST_SECRET"
    global_settings:
      v1_strategy:
        sma_short_period: 3
        sma_long_period: 5
        min_signal_interval_minutes: 0 # No wait for testing
        tp_sl_ratio: 1.5
        default_margin_usdt: 20.0
        default_leverage: 5
        indicator_timeframes: ["1m"]
      risk_management:
        dynamic_sizing_enabled: false
    pairs:
      TEST_USDT:
        enabled: true
        contract_type: "USDT_M"
        # margin_usdt: 20 # Uses global
        # leverage: 5   # Uses global
    logging:
      level: "DEBUG"
    monitoring:
      prometheus_port: 8001 # Different port for tests
    """
    with open(config_file, "w") as f:
        f.write(config_content)
    return str(config_file)

@pytest.fixture
def integration_config_manager(temp_config_file_for_integration):
    if hasattr(ConfigManager, 	_instance	):
        ConfigManager._instance = None # Reset singleton
    with patch("src.config_loader.DEFAULT_CONFIG_PATH", temp_config_file_for_integration):
        cm = ConfigManager(auto_reload=False)
        yield cm
    if hasattr(ConfigManager, 	_instance	):
        ConfigManager._instance = None

@pytest.fixture
def mock_binance_rest_client_integration(integration_config_manager):
    client = BinanceRESTClient(config_manager=integration_config_manager)
    # Mock actual API calls to avoid hitting Binance
    client.exchange = AsyncMock() # Mock the ccxt exchange object itself
    client.exchange.load_markets = AsyncMock(return_value={
        "TESTUSDT": {
            "symbol": "TESTUSDT", "base": "TEST", "quote": "USDT", "type": "future",
            "precision": {"amount": "0.001", "price": "0.01"},
            "limits": {"amount": {"min": "0.001"}, "cost": {"min": "5.0"}}
        }
    })
    client.exchange.create_order = AsyncMock(side_effect=lambda symbol, type, side, amount, price=None, params={}:
        {
            "id": f"mock_order_{int(time.time()*1000)}",
            "symbol": symbol, "type": type, "side": side, "amount": amount, "price": price,
            "status": "NEW", # Simulate NEW, then assume it fills for test flow
            "avgPrice": str(price or params.get("stopPrice") or 100.0), # Mock fill price
            "filled": amount # Assume full fill for market orders
        }
    )
    client.exchange.set_leverage = AsyncMock(return_value=True)
    client.exchange.set_margin_mode = AsyncMock(return_value=True)
    client.exchange.fetch_balance = AsyncMock(return_value={"USDT": {"free": 1000.0, "total": 1000.0}})
    client.exchange.close = AsyncMock()
    return client

# --- Integration Tests --- 

@pytest.mark.asyncio
async def test_kline_to_signal_to_order_flow(integration_config_manager, mock_binance_rest_client_integration):
    """ Test the flow: Kline -> DataProcessor -> SignalEngine -> OrderManager """
    
    # 1. Setup components
    data_processor = DataProcessor(config_manager=integration_config_manager)
    signal_engine = SignalEngineV1(config_manager=integration_config_manager, data_processor=data_processor)
    order_manager = OrderManager(config_manager=integration_config_manager, rest_client=mock_binance_rest_client_integration)
    # PositionManager could be added if we test its interaction too

    api_symbol = "TESTUSDT"
    config_symbol = "TEST_USDT"
    interval = "1m"

    # 2. Simulate incoming Kline data that should generate a signal
    # Data for a LONG signal (SMA3 crosses above SMA5)
    # SMA3 periods: 3, SMA5 periods: 5
    # Prices: 90, 92, 94 (SMA3=92), 96 (SMA3=94), 98 (SMA3=96)
    #         SMA5 = (90+92+94+96+98)/5 = 94
    # Next candle: close=100. SMA3=(96+98+100)/3 = 98. SMA5=(92+94+96+98+100)/5 = 96.
    # Crossover: Prev SMA3(96) > Prev SMA5(94). Curr SMA3(98) > Curr SMA5(96). This is not a crossover from below.
    # Let's make prev short < long, curr short > long
    # Prices: 90, 92, 90 (SMA3=90.67), 92 (SMA3=91.33), 90 (SMA3=90.67)
    #         SMA5 = (90+92+90+92+90)/5 = 90.8
    # Prev (idx 4, close 90): SMA3=90.67, SMA5=90.8 (short < long)
    # Curr (idx 5, close 98): SMA3=(90+92+98)/3=93.33. SMA5=(92+90+92+90+98)/5=92.4 (short > long) -> BUY
    klines_to_process = [
        Kline(timestamp=1000, open=90, high=91, low=89, close=90, volume=10, is_closed=True, symbol=api_symbol, interval=interval),
        Kline(timestamp=2000, open=90, high=93, low=91, close=92, volume=10, is_closed=True, symbol=api_symbol, interval=interval),
        Kline(timestamp=3000, open=92, high=92, low=89, close=90, volume=10, is_closed=True, symbol=api_symbol, interval=interval),
        Kline(timestamp=4000, open=90, high=93, low=91, close=92, volume=10, is_closed=True, symbol=api_symbol, interval=interval),
        Kline(timestamp=5000, open=92, high=92, low=89, close=90, volume=10, is_closed=True, symbol=api_symbol, interval=interval), # Prev state: SMA3=90.67, SMA5=90.8
        Kline(timestamp=6000, open=90, high=99, low=89, close=98, volume=10, is_closed=True, symbol=api_symbol, interval=interval)  # Curr state: SMA3=93.33, SMA5=92.4 -> BUY
    ]

    for kline in klines_to_process:
        await data_processor.process_kline(kline)
    
    # 3. Check for signal
    # The signal check would typically happen in the main loop or after kline processing
    # For this test, we call it directly.
    signal = await signal_engine.check_signal(api_symbol=api_symbol, config_symbol=config_symbol)
    
    assert signal is not None, "Signal should have been generated"
    assert signal.direction == TradeDirection.LONG
    assert signal.symbol == api_symbol
    assert signal.entry_price == 98.0 # Close of the signal candle
    # SL: min low of lookback. DataProcessor buffer has these klines.
    # Pivots are calculated on `df` inside signal_engine. `df` comes from data_processor.
    # Lows in buffer: 89,91,89,91,89,89. Min low for SL should be 89.
    assert signal.stop_loss_price == 89.0
    # TP: entry + (entry - SL) * tp_sl_ratio = 98 + (98 - 89) * 1.5 = 98 + 9 * 1.5 = 98 + 13.5 = 111.5
    assert signal.take_profit_price == 111.5

    # 4. Handle signal with OrderManager
    # Ensure exchange info is primed for the mock client
    await order_manager._get_exchange_info_for_symbol(api_symbol) 
    
    await order_manager.handle_trade_signal(signal)

    # 5. Verify orders were placed (mocked)
    # Expected quantity: (20 USDT margin * 5x leverage) / 98 entry = 1.0204...
    # Adjusted by step 0.001: floor(1.0204... / 0.001)*0.001 = 1.020
    expected_quantity = 1.020

    assert mock_binance_rest_client_integration.create_order.call_count == 3
    calls = mock_binance_rest_client_integration.create_order.call_args_list
    
    # Entry order
    assert calls[0][1]["symbol"] == api_symbol
    assert calls[0][1]["order_type"] == "MARKET"
    assert calls[0][1]["side"] == "BUY"
    assert calls[0][1]["amount"] == expected_quantity
    
    # SL order (price adjusted to 0.01 tick)
    assert calls[1][1]["params"]["stopPrice"] == 89.00
    assert calls[1][1]["amount"] == expected_quantity

    # TP order (price adjusted to 0.01 tick)
    assert calls[2][1]["params"]["stopPrice"] == 111.50
    assert calls[2][1]["amount"] == expected_quantity

@pytest.mark.asyncio
async def test_full_bot_cycle_with_mock_dependencies(temp_config_file_for_integration):
    """ Test a simplified main loop cycle using the TradingBot class with mocks """
    
    # Patch ConfigManager to use the temp file for the entire TradingBot instance
    if hasattr(ConfigManager, 	_instance	):
        ConfigManager._instance = None
    
    with patch("src.config_loader.DEFAULT_CONFIG_PATH", temp_config_file_for_integration):
        # We need to mock the parts of TradingBot that make external calls or run indefinitely
        
        # Mock BinanceRESTClient methods used by OrderManager and PositionManager
        mock_rest = AsyncMock(spec=BinanceRESTClient)
        mock_rest.fetch_exchange_info.return_value = {
            "TESTUSDT": {
                "symbol": "TESTUSDT", "precision": {"amount": "0.001", "price": "0.01"},
                "limits": {"cost": {"min": "5.0"}}
            }
        }
        mock_rest.create_order.side_effect = lambda symbol, type, side, amount, price=None, params={}:
            {
                "id": f"mock_order_{int(time.time()*1000)}", "symbol": symbol, "status": "NEW",
                "avgPrice": str(price or params.get("stopPrice") or 100.0), "filled": amount
            }
        mock_rest.fetch_positions = AsyncMock(return_value=[]) # No initial positions
        mock_rest.close_exchange = AsyncMock()

        # Mock BinanceWebSocketConnector methods
        mock_ws = AsyncMock(spec=BinanceWebSocketConnector)
        mock_ws.start = AsyncMock()
        mock_ws.stop = AsyncMock()

        with patch("src.main.BinanceRESTClient", return_value=mock_rest), \
             patch("src.main.BinanceWebSocketConnector", return_value=mock_ws): 
            
            bot = TradingBot() # This will now use the mocked clients
            
            # Manually trigger the kline processing that would come from WebSocket
            api_symbol = "TESTUSDT"
            config_symbol = "TEST_USDT"
            interval = "1m"
            klines_to_process = [
                Kline(timestamp=1000, open=90, high=91, low=89, close=90, volume=10, is_closed=True, symbol=api_symbol, interval=interval),
                Kline(timestamp=2000, open=90, high=93, low=91, close=92, volume=10, is_closed=True, symbol=api_symbol, interval=interval),
                Kline(timestamp=3000, open=92, high=92, low=89, close=90, volume=10, is_closed=True, symbol=api_symbol, interval=interval),
                Kline(timestamp=4000, open=90, high=93, low=91, close=92, volume=10, is_closed=True, symbol=api_symbol, interval=interval),
                Kline(timestamp=5000, open=92, high=92, low=89, close=90, volume=10, is_closed=True, symbol=api_symbol, interval=interval),
                Kline(timestamp=6000, open=90, high=99, low=89, close=98, volume=10, is_closed=True, symbol=api_symbol, interval=interval) 
            ]

            # Simulate the kline callback from WebSocket connector
            for kline in klines_to_process:
                await bot._handle_kline_data(kline, market_type="USDT_M")
            
            # Verify that create_order on the (mocked) REST client was called
            # This means DataProcessor, SignalEngine, and OrderManager worked together
            assert mock_rest.create_order.call_count >= 1 # Should be 3 for entry, SL, TP
            
            # Test position update (simplified)
            # If OrderManager called PositionManager.add_or_update_position, we could check that.
            # For this test, we focus on the order placement part of the flow.
            # A more complex test would mock PositionManager and verify its calls.

            # Test config hot reload effect on main app (e.g., active pairs)
            assert config_symbol in bot.active_trading_pairs
            new_config_content = yaml.safe_load(open(temp_config_file_for_integration, 	r	).read())
            new_config_content["pairs"]["TEST_USDT"]["enabled"] = False
            new_config_content["pairs"]["NEW_PAIR_USDT"] = {"enabled": True, "contract_type": "USDT_M"}
            with open(temp_config_file_for_integration, "w") as f:
                yaml.dump(new_config_content, f)
            
            bot.config_manager.load_config() # Manually trigger reload for test simplicity
            # The callback _handle_app_config_update should run
            assert config_symbol not in bot.active_trading_pairs
            assert "NEW_PAIR_USDT" in bot.active_trading_pairs

            await bot.stop() # Test graceful shutdown
            mock_ws.stop.assert_called_once()
            mock_rest.close_exchange.assert_called_once()

    if hasattr(ConfigManager, 	_instance	):
        ConfigManager._instance = None # Cleanup singleton




================================================
FILE: tests/unit/__init__.py
================================================



================================================
FILE: tests/unit/test_config_loader.py
================================================
import pytest
import os
import yaml
import time
from unittest.mock import patch, mock_open

from src.config_loader import ConfigManager, DEFAULT_CONFIG_PATH, EXAMPLE_CONFIG_PATH

@pytest.fixture
def temp_config_files(tmp_path):
    config_dir = tmp_path / "config"
    config_dir.mkdir()
    default_config_file = config_dir / "config.yaml"
    example_config_file = config_dir / "config.yaml.example"

    example_content = {
        "api": {"key": "example_key", "secret": "example_secret"},
        "logging": {"level": "INFO"}
    }
    with open(example_config_file, "w") as f:
        yaml.dump(example_content, f)
    
    # Initially, no default config.yaml, so it should be copied from example
    return str(default_config_file), str(example_config_file)

@pytest.fixture
def cleanup_singleton():
    # Reset the singleton instance before and after each test
    if hasattr(ConfigManager, 	_instance	):
        ConfigManager._instance = None
    if hasattr(ConfigManager, 	_initialized	):
        # This is a bit of a hack; ideally, the singleton is designed to be reset or re-initialized for tests.
        # For this specific implementation, clearing _instance is the main thing.
        # If __init__ has instance checks, we might need to delattr(ConfigManager, 	_initialized	) too.
        pass 
    yield
    if hasattr(ConfigManager, 	_instance	):
        ConfigManager._instance = None

@pytest.mark.asyncio
async def test_config_manager_singleton(cleanup_singleton):
    cm1 = ConfigManager(config_file_path="dummy_path1.yaml", auto_reload=False)
    cm2 = ConfigManager(config_file_path="dummy_path2.yaml", auto_reload=False)
    assert cm1 is cm2
    # Even if params are different after first init, it should return the same instance
    # and not re-initialize with new params. This is typical singleton behavior.
    # The current ConfigManager init logic ensures it only initializes fully once.
    assert cm1.config_file_path == "dummy_path1.yaml" # Should retain path from first call

@pytest.mark.asyncio
async def test_config_load_from_example_if_default_missing(temp_config_files, cleanup_singleton):
    default_cfg_path, example_cfg_path = temp_config_files
    
    # Ensure default_cfg_path does not exist initially for this part of the test
    if os.path.exists(default_cfg_path):
        os.remove(default_cfg_path)

    # Mock the global paths to use temp_config_files
    with patch("src.config_loader.DEFAULT_CONFIG_PATH", default_cfg_path), \
         patch("src.config_loader.EXAMPLE_CONFIG_PATH", example_cfg_path):
        
        cm = ConfigManager(auto_reload=False) # Should trigger copy from example
        assert os.path.exists(default_cfg_path) # Default should have been created
        config_data = cm.get_config()
        assert config_data["api"]["key"] == "example_key"
        assert config_data["logging"]["level"] == "INFO"

@pytest.mark.asyncio
async def test_config_load_existing_default(temp_config_files, cleanup_singleton):
    default_cfg_path, example_cfg_path = temp_config_files

    # Create a specific default config.yaml
    default_content = {
        "api": {"key": "default_key", "secret": "default_secret"},
        "logging": {"level": "DEBUG"}
    }
    with open(default_cfg_path, "w") as f:
        yaml.dump(default_content, f)

    with patch("src.config_loader.DEFAULT_CONFIG_PATH", default_cfg_path), \
         patch("src.config_loader.EXAMPLE_CONFIG_PATH", example_cfg_path):
        cm = ConfigManager(auto_reload=False)
        config_data = cm.get_config()
        assert config_data["api"]["key"] == "default_key"
        assert config_data["logging"]["level"] == "DEBUG"

@pytest.mark.asyncio
async def test_get_specific_config(temp_config_files, cleanup_singleton):
    default_cfg_path, example_cfg_path = temp_config_files
    # Let it load from example
    if os.path.exists(default_cfg_path):
        os.remove(default_cfg_path)

    with patch("src.config_loader.DEFAULT_CONFIG_PATH", default_cfg_path), \
         patch("src.config_loader.EXAMPLE_CONFIG_PATH", example_cfg_path):
        cm = ConfigManager(auto_reload=False)
        assert cm.get_specific_config("api.key") == "example_key"
        assert cm.get_specific_config("logging.level") == "INFO"
        assert cm.get_specific_config("non.existent.path", "default_val") == "default_val"
        assert cm.get_specific_config("api.non_existent_key") is None

@pytest.mark.asyncio
async def test_config_hot_reload(temp_config_files, cleanup_singleton):
    default_cfg_path, example_cfg_path = temp_config_files
    # Start with example content
    if os.path.exists(default_cfg_path):
        os.remove(default_cfg_path)

    callback_triggered = False
    new_conf_in_callback = None

    def my_callback(new_config):
        nonlocal callback_triggered, new_conf_in_callback
        callback_triggered = True
        new_conf_in_callback = new_config

    with patch("src.config_loader.DEFAULT_CONFIG_PATH", default_cfg_path), \
         patch("src.config_loader.EXAMPLE_CONFIG_PATH", example_cfg_path):
        
        cm = ConfigManager(auto_reload=True) # Enable auto_reload
        cm.register_callback(my_callback)
        
        initial_config = cm.get_config()
        assert initial_config["logging"]["level"] == "INFO"

        # Modify the config file
        modified_content = {
            "api": {"key": "modified_key", "secret": "modified_secret"},
            "logging": {"level": "DEBUG_MODIFIED"}
        }
        # Wait a moment to ensure the watcher is established before writing
        await asyncio.sleep(0.2) 
        with open(default_cfg_path, "w") as f:
            yaml.dump(modified_content, f)
        
        # Give watchdog time to detect and process the change
        await asyncio.sleep(1.0) # Increased sleep for reliability in CI/slower systems

        assert callback_triggered is True
        assert new_conf_in_callback is not None
        assert new_conf_in_callback["logging"]["level"] == "DEBUG_MODIFIED"
        
        current_config_from_cm = cm.get_config()
        assert current_config_from_cm["logging"]["level"] == "DEBUG_MODIFIED"
        assert cm.get_specific_config("api.key") == "modified_key"

        cm.stop_watcher() # Clean up watcher thread

@pytest.mark.asyncio
async def test_config_load_failure_empty_file(temp_config_files, cleanup_singleton):
    default_cfg_path, example_cfg_path = temp_config_files
    # Create an empty config.yaml
    with open(default_cfg_path, "w") as f:
        f.write("")

    with patch("src.config_loader.DEFAULT_CONFIG_PATH", default_cfg_path), \
         patch("src.config_loader.EXAMPLE_CONFIG_PATH", example_cfg_path):
        cm = ConfigManager(auto_reload=False)
        # Should log a warning, and config_data should be empty or fallback
        # The current implementation falls back to empty dict if load fails post-initialization
        assert cm.get_config() == {} 

@pytest.mark.asyncio
async def test_config_load_failure_invalid_yaml(temp_config_files, cleanup_singleton):
    default_cfg_path, example_cfg_path = temp_config_files
    # Create an invalid YAML config.yaml
    with open(default_cfg_path, "w") as f:
        f.write("api: key: -: invalid_yaml_structure")

    # Pre-populate with valid example data first so there is an "old" config
    example_data = {"api": {"key": "example_key"}}
    with open(example_cfg_path, "w") as f:
        yaml.dump(example_data, f)
    if os.path.exists(default_cfg_path):
        os.remove(default_cfg_path)

    with patch("src.config_loader.DEFAULT_CONFIG_PATH", default_cfg_path), \
         patch("src.config_loader.EXAMPLE_CONFIG_PATH", example_cfg_path):
        
        cm_initial = ConfigManager(auto_reload=False) # Loads from example
        initial_key = cm_initial.get_specific_config("api.key")
        assert initial_key == "example_key"

        # Now, simulate the invalid file being loaded (e.g., by a hot reload attempt or direct load)
        with open(default_cfg_path, "w") as f:
            f.write("api: key: -: invalid_yaml_structure")
        
        cm_initial.load_config() # Manually trigger a load of the bad file

        # Config should remain the old valid one due to parsing error
        assert cm_initial.get_specific_config("api.key") == initial_key




================================================
FILE: tests/unit/test_connectors.py
================================================
import pytest
import asyncio
from unittest.mock import AsyncMock, patch, MagicMock

from src.config_loader import ConfigManager
from src.connectors import BinanceRESTClient, BinanceWebSocketConnector, convert_symbol_to_ws_format, convert_symbol_to_api_format
from src.models import Kline

@pytest.fixture
def mock_config_manager_for_connectors(tmp_path):
    # Create a dummy config file for tests
    config_dir = tmp_path / "config"
    config_dir.mkdir()
    config_file = config_dir / "config.yaml"
    config_content = """
    api:
      binance_api_key: "TEST_KEY"
      binance_api_secret: "TEST_SECRET"
    global_settings:
      v1_strategy:
        indicator_timeframes: ["1m", "5m"]
    pairs:
      BTC_USDT:
        enabled: true
        contract_type: "USDT_M"
      ETH_USDT:
        enabled: true
        contract_type: "USDT_M"
        indicator_timeframes: ["1m"]
      BTCUSD_PERP:
        enabled: true
        contract_type: "COIN_M"
        indicator_timeframes: ["1m"]
    logging:
      level: "DEBUG"
    """
    with open(config_file, "w") as f:
        f.write(config_content)
    
    # Patch ConfigManager to use this temp config file
    # and ensure singleton is reset for these tests
    if hasattr(ConfigManager, 	_instance	):
        ConfigManager._instance = None

    with patch("src.config_loader.DEFAULT_CONFIG_PATH", str(config_file)):
        cm = ConfigManager(auto_reload=False)
        yield cm
    
    # Cleanup singleton after test
    if hasattr(ConfigManager, 	_instance	):
        ConfigManager._instance = None

# --- Test Symbol Conversion --- 
def test_convert_symbol_to_ws_format():
    assert convert_symbol_to_ws_format("BTC_USDT") == "btcusdt"
    assert convert_symbol_to_ws_format("ETH_BTC") == "ethbtc"
    assert convert_symbol_to_ws_format("BTCUSD_PERP") == "btcusd_perp"
    assert convert_symbol_to_ws_format("btcusdt") == "btcusdt" # Already formatted

def test_convert_symbol_to_api_format():
    assert convert_symbol_to_api_format("BTC_USDT") == "BTCUSDT"
    assert convert_symbol_to_api_format("ETH_BTC") == "ETHBTC"
    assert convert_symbol_to_api_format("BTCUSD_PERP") == "BTCUSD_PERP"
    assert convert_symbol_to_api_format("btcusdt") == "BTCUSDT"

# --- Test BinanceRESTClient --- 
@pytest.mark.asyncio
async def test_rest_client_initialization(mock_config_manager_for_connectors):
    rest_client = BinanceRESTClient(config_manager=mock_config_manager_for_connectors)
    assert rest_client.exchange is not None # Should initialize ccxt exchange
    await rest_client.close_exchange()

@pytest.mark.asyncio
async def test_rest_client_initialization_no_api_keys(tmp_path):
    config_dir = tmp_path / "config"
    config_dir.mkdir()
    config_file = config_dir / "config.yaml"
    config_content = """
    api:
      binance_api_key: "YOUR_BINANCE_API_KEY"
      binance_api_secret: "YOUR_BINANCE_API_SECRET"
    """
    with open(config_file, "w") as f:
        f.write(config_content)
    if hasattr(ConfigManager, 	_instance	):
        ConfigManager._instance = None
    with patch("src.config_loader.DEFAULT_CONFIG_PATH", str(config_file)):
        cm = ConfigManager(auto_reload=False)
        rest_client = BinanceRESTClient(config_manager=cm)
        assert rest_client.exchange is None # Should be None if keys are placeholders
        # Test a call, should simulate or return default
        order = await rest_client.create_order("BTCUSDT", "MARKET", "BUY", 1.0)
        assert order["id"] == "simulated_order_id"
        await rest_client.close_exchange()
    if hasattr(ConfigManager, 	_instance	):
        ConfigManager._instance = None

@pytest.mark.asyncio
async def test_rest_client_fetch_balance(mock_config_manager_for_connectors):
    rest_client = BinanceRESTClient(config_manager=mock_config_manager_for_connectors)
    with patch.object(rest_client.exchange, "fetch_balance", new_callable=AsyncMock) as mock_fetch:
        mock_fetch.return_value = {"USDT": {"free": 1000, "total": 1000}}
        balance = await rest_client.fetch_balance()
        assert balance["USDT"]["free"] == 1000
        mock_fetch.assert_called_once()
    await rest_client.close_exchange()

@pytest.mark.asyncio
async def test_rest_client_create_order(mock_config_manager_for_connectors):
    rest_client = BinanceRESTClient(config_manager=mock_config_manager_for_connectors)
    with patch.object(rest_client.exchange, "create_order", new_callable=AsyncMock) as mock_create:
        mock_create.return_value = {"id": "123", "symbol": "BTCUSDT", "status": "NEW"}
        order = await rest_client.create_order("BTC_USDT", "MARKET", "BUY", 0.01)
        assert order["id"] == "123"
        mock_create.assert_called_once_with("BTCUSDT", "MARKET", "BUY", 0.01, None, {})
    await rest_client.close_exchange()

# --- Test BinanceWebSocketConnector --- 
@pytest.fixture
def mock_kline_callback():
    return AsyncMock()

@pytest.mark.asyncio
async def test_ws_connector_get_active_pairs_and_intervals(mock_config_manager_for_connectors, mock_kline_callback):
    ws_connector = BinanceWebSocketConnector(config_manager=mock_config_manager_for_connectors, kline_callback=mock_kline_callback)
    active_streams = ws_connector._get_active_pairs_and_intervals()
    assert "btcusdt@kline_1m" in active_streams["USDT_M"]
    assert "btcusdt@kline_5m" in active_streams["USDT_M"]
    assert "ethusdt@kline_1m" in active_streams["USDT_M"]
    assert "btcusd_perp@kline_1m" in active_streams["COIN_M"]
    assert "ethusdt@kline_5m" not in active_streams["USDT_M"] # Overridden to 1m only

@pytest.mark.asyncio
async def test_ws_connector_subscribe_unsubscribe(mock_kline_callback):
    # This test requires a more involved setup with a mock WebSocket server
    # or deeper patching of the `websockets.connect` call.
    # For simplicity, we focus on the logic of forming subscription messages.
    
    # Mock config that enables only one stream for easier assertion
    class MinimalMockConfigManager:
        def get_config(self):
            return {
                "global_settings": {"v1_strategy": {"indicator_timeframes": ["1m"]}},
                "pairs": {"BTC_USDT": {"enabled": True, "contract_type": "USDT_M"}}
            }
        def register_callback(self, cb): pass
        def stop_watcher(self): pass

    ws_connector = BinanceWebSocketConnector(config_manager=MinimalMockConfigManager(), kline_callback=mock_kline_callback)
    
    mock_ws_connection = AsyncMock(spec=websockets.WebSocketClientProtocol)
    mock_ws_connection.open = True # Simulate open connection

    streams_to_sub = ["btcusdt@kline_1m"]
    await ws_connector._subscribe(mock_ws_connection, streams_to_sub)
    call_args = json.loads(mock_ws_connection.send.call_args[0][0])
    assert call_args["method"] == "SUBSCRIBE"
    assert call_args["params"] == streams_to_sub

    await ws_connector._unsubscribe(mock_ws_connection, streams_to_sub)
    call_args_unsub = json.loads(mock_ws_connection.send.call_args[0][0])
    assert call_args_unsub["method"] == "UNSUBSCRIBE"
    assert call_args_unsub["params"] == streams_to_sub

@pytest.mark.asyncio
async def test_ws_connector_process_kline_message(mock_config_manager_for_connectors, mock_kline_callback):
    ws_connector = BinanceWebSocketConnector(config_manager=mock_config_manager_for_connectors, kline_callback=mock_kline_callback)
    kline_msg_str = 	{	
        "e": "kline",
        "E": 123456789,
        "s": "BTCUSDT",
        "k": {
            "t": 123400000,
            "T": 123459999,
            "s": "BTCUSDT",
            "i": "1m",
            "o": "0.0010",
            "c": "0.0020",
            "h": "0.0025",
            "l": "0.0015",
            "v": "1000",
            "n": 100,
            "x": False, # Is kline closed?
            "q": "1.0000",
            "V": "500",
            "Q": "0.500",
            "B": "123456"
        }
    }	
    await ws_connector._process_message(json.dumps(kline_msg_str), "USDT_M")
    mock_kline_callback.assert_called_once()
    called_kline_arg = mock_kline_callback.call_args[0][0]
    assert isinstance(called_kline_arg, Kline)
    assert called_kline_arg.symbol == "BTCUSDT"
    assert called_kline_arg.interval == "1m"
    assert called_kline_arg.close == 0.0020
    assert called_kline_arg.is_closed is False

@pytest.mark.asyncio
async def test_ws_connector_start_stop_and_config_update_flow(mock_config_manager_for_connectors, mock_kline_callback):
    ws_connector = BinanceWebSocketConnector(config_manager=mock_config_manager_for_connectors, kline_callback=mock_kline_callback)
    
    # Patch the actual connection handler to prevent real WS connections during this unit test
    with patch.object(ws_connector, 	_handle_connection	, new_callable=AsyncMock) as mock_handler:
        await ws_connector.start()
        assert ws_connector._is_running
        # _handle_config_update should have been called, leading to _handle_connection calls
        # Check if tasks for USDT_M and COIN_M were created (based on config)
        await asyncio.sleep(0.1) # Allow tasks to be scheduled
        assert mock_handler.call_count >= 1 # Should be called for USDT_M and COIN_M if enabled
        
        # Simulate a config update that disables a pair
        new_config_data = mock_config_manager_for_connectors.get_config()
        new_config_data["pairs"]["BTC_USDT"]["enabled"] = False
        
        # Mock the _unsubscribe and _subscribe methods on an active connection if one existed
        # For this test, we mainly check if _handle_config_update is called and updates subscriptions
        mock_ws_conn_usdm = AsyncMock(spec=websockets.WebSocketClientProtocol)
        mock_ws_conn_usdm.open = True
        ws_connector._ws_connections["USDT_M"] = mock_ws_conn_usdm
        ws_connector._active_subscriptions["USDT_M"] = ["btcusdt@kline_1m", "btcusdt@kline_5m"]

        await ws_connector._handle_config_update(new_config_data) # Manually trigger for test control
        
        # Check if btcusdt streams were unsubscribed
        # This requires inspecting calls to _unsubscribe or checking _active_subscriptions
        assert "btcusdt@kline_1m" not in ws_connector._active_subscriptions["USDT_M"]
        assert "btcusdt@kline_5m" not in ws_connector._active_subscriptions["USDT_M"]
        # And that ethusdt@kline_1m is still there
        assert "ethusdt@kline_1m" in ws_connector._active_subscriptions["USDT_M"]

        await ws_connector.stop()
        assert not ws_connector._is_running
        mock_handler.reset_mock() # Reset for next potential calls if any




================================================
FILE: tests/unit/test_data_processor.py
================================================
import pytest
import asyncio
import pandas as pd
import numpy as np
from unittest.mock import MagicMock, patch
from collections import deque

from src.config_loader import ConfigManager
from src.data_processor import DataProcessor, MAX_KLINE_BUFFER_LENGTH
from src.models import Kline

@pytest.fixture
def mock_config_manager_for_dp():
    """Fixture that creates a mock ConfigManager for DataProcessor testing."""
    mock_cm = MagicMock(spec=ConfigManager)
    
    # Create a mock config with different enabled pairs, timeframes, and SMA periods
    mock_config = {
        "global_settings": {
            "v1_strategy": {
                "sma_short_period": 21,
                "sma_long_period": 200,
                "indicator_timeframes": ["1m", "5m", "15m"]
            }
        },
        "pairs": {
            "BTC_USDT": {
                "enabled": True,
                "contract_type": "USDT_M",
                "indicator_timeframes": ["1m", "5m"]  # Override global
            },
            "ETH_USDT": {
                "enabled": True,
                "contract_type": "USDT_M"
                # Uses global timeframes: ["1m", "5m", "15m"]
            },
            "SOL_USDT": {
                "enabled": False  # This pair should not have buffers initialized initially
            },
            "XRP_USDT": {
                "enabled": True,
                "indicator_timeframes": ["1m"]  # Just 1m timeframe
            }
        }
    }
    
    # Set up the return value for get_config method
    mock_cm.get_config.return_value = mock_config
    
    return mock_cm

@pytest.fixture
def data_processor(mock_config_manager_for_dp):
    """Fixture that initializes DataProcessor with a mock ConfigManager."""
    dp = DataProcessor(config_manager=mock_config_manager_for_dp)
    return dp

# Test Initialization
@pytest.mark.asyncio
async def test_initialization_buffers_creation(data_processor, mock_config_manager_for_dp):
    """Test that buffers are created correctly based on enabled pairs and timeframes."""
    # Check active pairs timeframes dictionary
    assert "BTCUSDT" in data_processor._active_pairs_timeframes
    assert "ETHUSDT" in data_processor._active_pairs_timeframes
    assert "XRPUSDT" in data_processor._active_pairs_timeframes
    assert "SOLUSDT" not in data_processor._active_pairs_timeframes  # Disabled in config
    
    # Check specific timeframes for each pair
    assert set(data_processor._active_pairs_timeframes["BTCUSDT"]) == {"1m", "5m"}  # Overridden from global
    assert set(data_processor._active_pairs_timeframes["ETHUSDT"]) == {"1m", "5m", "15m"}  # From global
    assert set(data_processor._active_pairs_timeframes["XRPUSDT"]) == {"1m"}  # Specific config
    
    # Check kline buffer creation for all active pairs/timeframes
    for symbol in ["BTCUSDT", "ETHUSDT", "XRPUSDT"]:
        for tf in data_processor._active_pairs_timeframes[symbol]:
            assert tf in data_processor.kline_buffers[symbol]
            assert isinstance(data_processor.kline_buffers[symbol][tf], deque)
            assert data_processor.kline_buffers[symbol][tf].maxlen == MAX_KLINE_BUFFER_LENGTH
    
    # Check that disabled pairs don't have buffers or have empty ones
    if "SOLUSDT" in data_processor.kline_buffers:
        assert not data_processor.kline_buffers["SOLUSDT"]  # Should be empty

@pytest.mark.asyncio
async def test_initialization_empty_pairs_config(mock_config_manager_for_dp):
    """Test initialization with empty pairs configuration."""
    # Set empty pairs config
    empty_config = {
        "global_settings": {
            "v1_strategy": {
                "sma_short_period": 21,
                "sma_long_period": 200,
                "indicator_timeframes": ["1m", "5m"]
            }
        },
        "pairs": {}  # Empty pairs
    }
    mock_config_manager_for_dp.get_config.return_value = empty_config
    
    # Initialize DataProcessor with empty config
    dp = DataProcessor(config_manager=mock_config_manager_for_dp)
    
    # Check that active pairs, kline_buffers and indicator_data are empty
    assert not dp._active_pairs_timeframes
    assert not dp.kline_buffers  # Check defaultdict doesn't have any pairs
    assert not dp.indicator_data

# Test Kline Processing
@pytest.mark.asyncio
async def test_process_closed_kline(data_processor):
    """Test processing a single closed Kline for an active pair/timeframe."""
    # Create a sample closed kline
    kline_closed = Kline(
        timestamp=1000,
        open=10.0,
        high=12.0,
        low=9.0,
        close=11.0,
        volume=100.0,
        is_closed=True,
        symbol="BTCUSDT",
        interval="1m"
    )
    
    # Process the kline
    await data_processor.process_kline(kline_closed)
    
    # Check that kline was added to the buffer
    assert len(data_processor.kline_buffers["BTCUSDT"]["1m"]) == 1
    assert data_processor.kline_buffers["BTCUSDT"]["1m"][0] == kline_closed
    
    # Check that indicator data was updated (should exist even if values are NA)
    indicator_df = data_processor.get_indicator_dataframe("BTCUSDT", "1m")
    assert indicator_df is not None
    assert not indicator_df.empty
    assert kline_closed.timestamp in indicator_df.index
    assert "sma_short" in indicator_df.columns
    assert "sma_long" in indicator_df.columns

@pytest.mark.asyncio
async def test_process_unclosed_kline(data_processor):
    """Test processing a single unclosed Kline for an active pair/timeframe."""
    # Create a sample unclosed kline
    kline_unclosed = Kline(
        timestamp=1000,
        open=10.0,
        high=12.0,
        low=9.0,
        close=11.0,
        volume=100.0,
        is_closed=False,
        symbol="BTCUSDT",
        interval="1m"
    )
    
    # Process the kline
    await data_processor.process_kline(kline_unclosed)
    
    # Check that kline was added to the buffer
    assert len(data_processor.kline_buffers["BTCUSDT"]["1m"]) == 1
    assert data_processor.kline_buffers["BTCUSDT"]["1m"][0] == kline_unclosed
    
    # Check if indicator data exists (should be empty since only unclosed kline was processed)
    indicator_df = data_processor.get_indicator_dataframe("BTCUSDT", "1m")
    if indicator_df is not None and not indicator_df.empty:
        # Implementation may or may not update indicators for unclosed candles
        # Just check the structure exists
        assert kline_unclosed.timestamp in indicator_df.index
        assert "sma_short" in indicator_df.columns
        assert "sma_long" in indicator_df.columns

@pytest.mark.asyncio
async def test_update_unclosed_kline(data_processor):
    """Test updating the last unclosed Kline."""
    # Create initial unclosed kline
    kline_unclosed_t1 = Kline(
        timestamp=1000,
        open=10.0,
        high=11.0,
        low=9.0,
        close=10.5,
        volume=50.0,
        is_closed=False,
        symbol="BTCUSDT",
        interval="1m"
    )
    
    # Process the initial kline
    await data_processor.process_kline(kline_unclosed_t1)
    assert len(data_processor.kline_buffers["BTCUSDT"]["1m"]) == 1
    
    # Create an updated version of the same kline (same timestamp, different data)
    kline_unclosed_t1_update = Kline(
        timestamp=1000,
        open=10.0,
        high=12.0,  # Higher high
        low=8.5,    # Lower low
        close=11.0, # Different close
        volume=75.0, # More volume
        is_closed=False,
        symbol="BTCUSDT",
        interval="1m"
    )
    
    # Process the updated kline
    await data_processor.process_kline(kline_unclosed_t1_update)
    
    # Check that the deque contains only one element (the updated kline)
    assert len(data_processor.kline_buffers["BTCUSDT"]["1m"]) == 1
    assert data_processor.kline_buffers["BTCUSDT"]["1m"][0] == kline_unclosed_t1_update
    assert data_processor.kline_buffers["BTCUSDT"]["1m"][0].high == 12.0
    assert data_processor.kline_buffers["BTCUSDT"]["1m"][0].close == 11.0

@pytest.mark.asyncio
async def test_replace_unclosed_with_closed_kline(data_processor):
    """Test replacing the last unclosed Kline with its closed version."""
    # Create initial unclosed kline
    kline_unclosed_t1 = Kline(
        timestamp=1000,
        open=10.0,
        high=11.0,
        low=9.0,
        close=10.5,
        volume=50.0,
        is_closed=False,
        symbol="BTCUSDT",
        interval="1m"
    )
    
    # Process the unclosed kline
    await data_processor.process_kline(kline_unclosed_t1)
    assert len(data_processor.kline_buffers["BTCUSDT"]["1m"]) == 1
    assert not data_processor.kline_buffers["BTCUSDT"]["1m"][0].is_closed
    
    # Create closed version of the same kline
    kline_closed_t1 = Kline(
        timestamp=1000,
        open=10.0,
        high=11.5,
        low=9.0,
        close=11.0,
        volume=100.0,
        is_closed=True,  # Now closed
        symbol="BTCUSDT",
        interval="1m"
    )
    
    # Process the closed kline
    await data_processor.process_kline(kline_closed_t1)
    
    # Check that the deque contains one element (the closed kline)
    assert len(data_processor.kline_buffers["BTCUSDT"]["1m"]) == 1
    assert data_processor.kline_buffers["BTCUSDT"]["1m"][0] == kline_closed_t1
    assert data_processor.kline_buffers["BTCUSDT"]["1m"][0].is_closed is True
    
    # Check that indicator data was updated
    indicator_df = data_processor.get_indicator_dataframe("BTCUSDT", "1m")
    assert indicator_df is not None
    assert not indicator_df.empty
    assert kline_closed_t1.timestamp in indicator_df.index

@pytest.mark.asyncio
async def test_process_kline_inactive_pair(data_processor):
    """Test processing a Kline for an inactive pair/timeframe."""
    # Create a kline for an inactive pair
    kline_inactive = Kline(
        timestamp=1000,
        open=10.0,
        high=12.0,
        low=9.0,
        close=11.0,
        volume=100.0,
        is_closed=True,
        symbol="SOLUSDT",  # Disabled in config
        interval="1m"
    )
    
    # Process the kline
    await data_processor.process_kline(kline_inactive)
    
    # Check that kline was not processed (no buffer should exist)
    if "SOLUSDT" in data_processor.kline_buffers:
        assert not data_processor.kline_buffers["SOLUSDT"]["1m"]
    
    # Check that indicator data was not created
    indicator_df = data_processor.get_indicator_dataframe("SOLUSDT", "1m")
    if indicator_df is not None:
        assert indicator_df.empty

@pytest.mark.asyncio
async def test_buffer_limit_enforcement(data_processor):
    """Test that buffer size is limited to MAX_KLINE_BUFFER_LENGTH."""
    # Generate klines with sequential timestamps
    symbol = "BTCUSDT"
    interval = "1m"
    num_klines = MAX_KLINE_BUFFER_LENGTH + 5  # More than the max buffer length
    
    for i in range(num_klines):
        kline = Kline(
            timestamp=1000 + i,
            open=10.0,
            high=12.0,
            low=9.0,
            close=11.0,
            volume=100.0,
            is_closed=True,
            symbol=symbol,
            interval=interval
        )
        await data_processor.process_kline(kline)
    
    # Check that buffer size is limited to MAX_KLINE_BUFFER_LENGTH
    assert len(data_processor.kline_buffers[symbol][interval]) == MAX_KLINE_BUFFER_LENGTH
    
    # Check that oldest klines were discarded
    # First timestamp should be the earliest retained timestamp
    first_timestamp = data_processor.kline_buffers[symbol][interval][0].timestamp
    assert first_timestamp == 1000 + (num_klines - MAX_KLINE_BUFFER_LENGTH)

# Test Indicator Calculation
@pytest.mark.asyncio
async def test_insufficient_data_for_sma(data_processor, mock_config_manager_for_dp):
    """Test case where there's insufficient data for SMA calculation."""
    # Set shorter SMA periods for easier testing
    mock_config = mock_config_manager_for_dp.get_config()
    mock_config["global_settings"]["v1_strategy"]["sma_short_period"] = 3
    mock_config["global_settings"]["v1_strategy"]["sma_long_period"] = 5
    mock_config_manager_for_dp.get_config.return_value = mock_config
    
    # Initialize with new config
    dp = DataProcessor(config_manager=mock_config_manager_for_dp)
    
    symbol = "BTCUSDT"
    interval = "1m"
    
    # Process 2 klines (less than sma_short_period of 3)
    for i in range(2):
        kline = Kline(
            timestamp=1000 + i * 60000,  # 1-minute intervals
            open=100.0,
            high=110.0,
            low=90.0,
            close=100.0 + i,  # Different close prices
            volume=100.0,
            is_closed=True,
            symbol=symbol,
            interval=interval
        )
        await dp.process_kline(kline)
    
    # Check indicator dataframe
    df = dp.get_indicator_dataframe(symbol, interval)
    assert df is not None
    assert not df.empty
    assert "sma_short" in df.columns
    assert "sma_long" in df.columns
    
    # Check that SMA values are NaN due to insufficient data
    latest_row = df.iloc[-1]
    assert pd.isna(latest_row["sma_short"])
    assert pd.isna(latest_row["sma_long"])

@pytest.mark.asyncio
async def test_correct_sma_short_calculation(data_processor, mock_config_manager_for_dp):
    """Test correct calculation of short-period SMA."""
    # Set shorter SMA periods for easier testing
    mock_config = mock_config_manager_for_dp.get_config()
    mock_config["global_settings"]["v1_strategy"]["sma_short_period"] = 3
    mock_config["global_settings"]["v1_strategy"]["sma_long_period"] = 5
    mock_config_manager_for_dp.get_config.return_value = mock_config
    
    # Initialize with new config
    dp = DataProcessor(config_manager=mock_config_manager_for_dp)
    
    symbol = "BTCUSDT"
    interval = "1m"
    close_prices = [100.0, 110.0, 120.0, 130.0]
    
    # Process exactly sma_short_period + 1 klines
    for i, close in enumerate(close_prices):
        kline = Kline(
            timestamp=1000 + i * 60000,
            open=close,
            high=close + 10,
            low=close - 10,
            close=close,
            volume=100.0,
            is_closed=True,
            symbol=symbol,
            interval=interval
        )
        await dp.process_kline(kline)
    
    # Check indicator dataframe
    df = dp.get_indicator_dataframe(symbol, interval)
    assert df is not None
    assert len(df) == len(close_prices)
    
    # Calculate expected SMA values
    expected_sma3 = sum(close_prices[-3:]) / 3  # Average of last 3 values
    
    # Check SMA values
    latest_row = df.iloc[-1]
    assert latest_row["sma_short"] == pytest.approx(expected_sma3)
    assert pd.isna(latest_row["sma_long"])  # Not enough data for long SMA

@pytest.mark.asyncio
async def test_correct_sma_long_calculation(data_processor, mock_config_manager_for_dp):
    """Test correct calculation of long-period SMA."""
    # Set shorter SMA periods for easier testing
    mock_config = mock_config_manager_for_dp.get_config()
    mock_config["global_settings"]["v1_strategy"]["sma_short_period"] = 3
    mock_config["global_settings"]["v1_strategy"]["sma_long_period"] = 5
    mock_config_manager_for_dp.get_config.return_value = mock_config
    
    # Initialize with new config
    dp = DataProcessor(config_manager=mock_config_manager_for_dp)
    
    symbol = "BTCUSDT"
    interval = "1m"
    close_prices = [100.0, 110.0, 120.0, 130.0, 140.0, 150.0]
    
    # Process exactly sma_long_period + 1 klines
    for i, close in enumerate(close_prices):
        kline = Kline(
            timestamp=1000 + i * 60000,
            open=close,
            high=close + 10,
            low=close - 10,
            close=close,
            volume=100.0,
            is_closed=True,
            symbol=symbol,
            interval=interval
        )
        await dp.process_kline(kline)
    
    # Check indicator dataframe
    df = dp.get_indicator_dataframe(symbol, interval)
    assert df is not None
    assert len(df) == len(close_prices)
    
    # Calculate expected SMA values
    expected_sma3 = sum(close_prices[-3:]) / 3  # Average of last 3 values
    expected_sma5 = sum(close_prices[-5:]) / 5  # Average of last 5 values
    
    # Check SMA values
    latest_row = df.iloc[-1]
    assert latest_row["sma_short"] == pytest.approx(expected_sma3)
    assert latest_row["sma_long"] == pytest.approx(expected_sma5)

@pytest.mark.asyncio
async def test_sma_calculation_with_duplicate_timestamps(data_processor, mock_config_manager_for_dp):
    """Test that SMA calculation correctly handles duplicate timestamps."""
    # Set shorter SMA periods for easier testing
    mock_config = mock_config_manager_for_dp.get_config()
    mock_config["global_settings"]["v1_strategy"]["sma_short_period"] = 3
    mock_config["global_settings"]["v1_strategy"]["sma_long_period"] = 5
    mock_config_manager_for_dp.get_config.return_value = mock_config
    
    # Initialize with new config
    dp = DataProcessor(config_manager=mock_config_manager_for_dp)
    
    symbol = "BTCUSDT"
    interval = "1m"
    
    # Process klines with some duplicate timestamps
    klines_data = [
        # Original klines
        (1000, 100.0, False),
        (2000, 110.0, False),
        (3000, 120.0, False),
        (4000, 130.0, False),
        (5000, 140.0, False),
        # Updates with same timestamps but different values (should replace)
        (3000, 125.0, True),  # Update and close kline at t=3000
        (5000, 145.0, True),  # Update and close kline at t=5000
    ]
    
    for timestamp, close, is_closed in klines_data:
        kline = Kline(
            timestamp=timestamp,
            open=close - 10,
            high=close + 10,
            low=close - 20,
            close=close,
            volume=100.0,
            is_closed=is_closed,
            symbol=symbol,
            interval=interval
        )
        await dp.process_kline(kline)
    
    # Check indicator dataframe
    df = dp.get_indicator_dataframe(symbol, interval)
    assert df is not None
    
    # Check no duplicate timestamps in DataFrame
    assert len(df.index) == len(set(df.index))
    
    # Check that the updated values are used in the DataFrame
    assert df.loc[3000, "close"] == 125.0
    assert df.loc[5000, "close"] == 145.0
    
    # Calculate expected SMA values (using last values after updates)
    expected_values = [100.0, 110.0, 125.0, 130.0, 145.0]
    expected_sma3 = sum(expected_values[-3:]) / 3
    expected_sma5 = sum(expected_values) / 5
    
    # Check SMA calculations
    latest_row = df.iloc[-1]  # Should be the row for timestamp 5000
    assert latest_row["sma_short"] == pytest.approx(expected_sma3)
    assert latest_row["sma_long"] == pytest.approx(expected_sma5)

# Test Getter Methods
@pytest.mark.asyncio
async def test_getters_return_correct_data(data_processor, mock_config_manager_for_dp):
    """Test that getter methods return correct data after processing."""
    # Set shorter SMA periods for easier testing
    mock_config = mock_config_manager_for_dp.get_config()
    mock_config["global_settings"]["v1_strategy"]["sma_short_period"] = 3
    mock_config["global_settings"]["v1_strategy"]["sma_long_period"] = 5
    mock_config_manager_for_dp.get_config.return_value = mock_config
    
    # Initialize with new config
    dp = DataProcessor(config_manager=mock_config_manager_for_dp)
    
    symbol = "BTCUSDT"
    interval = "1m"
    
    # Process several klines
    klines = []
    for i in range(6):  # 6 klines
        kline = Kline(
            timestamp=1000 + i * 60000,
            open=100.0 + i,
            high=110.0 + i,
            low=90.0 + i,
            close=105.0 + i,
            volume=100.0 + i * 10,
            is_closed=True,
            symbol=symbol,
            interval=interval
        )
        klines.append(kline)
        await dp.process_kline(kline)
    
    # Test get_latest_kline
    latest_kline = dp.get_latest_kline(symbol, interval)
    assert latest_kline is not None
    assert latest_kline == klines[-1]
    
    # Test get_indicator_dataframe
    df = dp.get_indicator_dataframe(symbol, interval)
    assert df is not None
    assert not df.empty
    assert len(df) == len(klines)
    
    # Test get_latest_indicators
    latest_indicators = dp.get_latest_indicators(symbol, interval)
    assert latest_indicators is not None
    assert latest_indicators["timestamp"] == klines[-1].timestamp
    assert latest_indicators["close"] == klines[-1].close
    assert not pd.isna(latest_indicators["sma_short"])
    assert not pd.isna(latest_indicators["sma_long"])

@pytest.mark.asyncio
async def test_getters_return_none_for_nonexistent_data(data_processor):
    """Test that getters return None or empty DataFrame for non-existent symbol/timeframe."""
    # Test with non-existent symbol
    assert data_processor.get_latest_kline("NONEXISTENT", "1m") is None
    df = data_processor.get_indicator_dataframe("NONEXISTENT", "1m")
    if df is not None:
        assert df.empty
    assert data_processor.get_latest_indicators("NONEXISTENT", "1m") is None
    
    # Test with valid symbol but non-existent timeframe
    assert data_processor.get_latest_kline("BTCUSDT", "NONEXISTENT") is None
    df = data_processor.get_indicator_dataframe("BTCUSDT", "NONEXISTENT")
    if df is not None:
        assert df.empty
    assert data_processor.get_latest_indicators("BTCUSDT", "NONEXISTENT") is None

# Test Configuration Hot-Reload
@pytest.mark.asyncio
async def test_adding_new_active_pair_via_config_update(data_processor, mock_config_manager_for_dp):
    """Test that config update adds a new active pair correctly."""
    # Check initial state
    assert "SOLUSDT" not in data_processor._active_pairs_timeframes  # Initially disabled
    
    # Create new config with SOLUSDT enabled
    new_config = mock_config_manager_for_dp.get_config().copy()
    new_config["pairs"]["SOL_USDT"]["enabled"] = True
    new_config["pairs"]["SOL_USDT"]["indicator_timeframes"] = ["1m", "15m"]
    
    # Trigger config update
    data_processor._handle_config_update(new_config)
    
    # Check that SOLUSDT was added to active pairs
    assert "SOLUSDT" in data_processor._active_pairs_timeframes
    assert set(data_processor._active_pairs_timeframes["SOLUSDT"]) == {"1m", "15m"}
    
    # Check that buffers were created
    assert "SOLUSDT" in data_processor.kline_buffers
    assert "1m" in data_processor.kline_buffers["SOLUSDT"]
    assert "15m" in data_processor.kline_buffers["SOLUSDT"]
    assert isinstance(data_processor.kline_buffers["SOLUSDT"]["1m"], deque)
    assert isinstance(data_processor.kline_buffers["SOLUSDT"]["15m"], deque)
    assert data_processor.kline_buffers["SOLUSDT"]["1m"].maxlen == MAX_KLINE_BUFFER_LENGTH

@pytest.mark.asyncio
async def test_disabling_existing_pair_via_config_update(data_processor, mock_config_manager_for_dp):
    """Test that config update correctly disables an active pair."""
    # Check initial state
    assert "BTCUSDT" in data_processor._active_pairs_timeframes  # Initially enabled
    
    # Create new config with BTCUSDT disabled
    new_config = mock_config_manager_for_dp.get_config().copy()
    new_config["pairs"]["BTC_USDT"]["enabled"] = False
    
    # Trigger config update
    data_processor._handle_config_update(new_config)
    
    # Check that BTCUSDT was removed from active pairs
    assert "BTCUSDT" not in data_processor._active_pairs_timeframes
    
    # Note: The current implementation might not remove old buffers, just stop processing for them
    # So we won't assert on the removal of buffers, just on the active pairs list

@pytest.mark.asyncio
async def test_changing_timeframes_via_config_update(data_processor, mock_config_manager_for_dp):
    """Test that config update correctly changes timeframes for an active pair."""
    # Check initial state for ETHUSDT
    assert "ETHUSDT" in data_processor._active_pairs_timeframes
    assert set(data_processor._active_pairs_timeframes["ETHUSDT"]) == {"1m", "5m", "15m"}
    
    # Create new config with different timeframes for ETHUSDT
    new_config = mock_config_manager_for_dp.get_config().copy()
    new_config["pairs"]["ETH_USDT"]["indicator_timeframes"] = ["5m", "30m"]  # Changed timeframes
    
    # Trigger config update
    data_processor._handle_config_update(new_config)
    
    # Check that timeframes were updated
    assert "ETHUSDT" in data_processor._active_pairs_timeframes
    assert set(data_processor._active_pairs_timeframes["ETHUSDT"]) == {"5m", "30m"}
    
    # Check that new buffer for 30m timeframe was created
    assert "30m" in data_processor.kline_buffers["ETHUSDT"]
    assert isinstance(data_processor.kline_buffers["ETHUSDT"]["30m"], deque)




================================================
FILE: tests/unit/test_models.py
================================================
import pytest
import time
from pydantic import ValidationError

from src.models import Kline, PairConfig, TradeSignal, TradeDirection, Order, OrderStatus, OrderType, OrderSide, Position

def test_kline_creation():
    ts = int(time.time() * 1000)
    kline = Kline(
        timestamp=ts, open=100, high=110, low=90, close=105, volume=1000,
        is_closed=True, symbol="BTCUSDT", interval="1m"
    )
    assert kline.timestamp == ts
    assert kline.close == 105
    assert kline.symbol == "BTCUSDT"
    assert kline.is_closed is True

def test_pair_config_creation():
    pc = PairConfig(symbol="BTC_USDT", enabled=True, leverage=20, contract_type="USDT_M")
    assert pc.symbol == "BTC_USDT"
    assert pc.leverage == 20
    assert pc.contract_type == "USDT_M"

    with pytest.raises(ValidationError):
        PairConfig(symbol="BTCUSDT", enabled=True) # Invalid symbol format for config
    
    pc_coinm = PairConfig(symbol="BTCUSD_PERP", enabled=True, contract_type="COIN_M")
    assert pc_coinm.symbol == "BTCUSD_PERP"
    assert pc_coinm.contract_type == "COIN_M"

def test_trade_signal_creation():
    ts = int(time.time() * 1000)
    signal = TradeSignal(
        timestamp=ts, symbol="ETHUSDT", config_symbol="ETH_USDT", contract_type="USDT_M",
        direction=TradeDirection.SHORT, entry_price=2000, stop_loss_price=2100, take_profit_price=1800,
        strategy_name="TestStrategy"
    )
    assert signal.symbol == "ETHUSDT"
    assert signal.direction == TradeDirection.SHORT
    assert signal.take_profit_price == 1800

def test_order_creation():
    ts = int(time.time() * 1000)
    order = Order(
        order_id="ord123", symbol="LINKUSDT", type=OrderType.LIMIT, side=OrderSide.BUY,
        quantity=100, price=15.0, status=OrderStatus.NEW, timestamp=ts
    )
    assert order.order_id == "ord123"
    assert order.type == OrderType.LIMIT
    assert order.status == OrderStatus.NEW

    market_order = Order(
        order_id="ord124", symbol="ADAUSDT", type=OrderType.MARKET, side=OrderSide.SELL,
        quantity=1000, status=OrderStatus.FILLED, timestamp=ts, avg_fill_price=0.45, filled_quantity=1000
    )
    assert market_order.type == OrderType.MARKET
    assert market_order.avg_fill_price == 0.45

def test_position_creation():
    ts = int(time.time() * 1000)
    position = Position(
        symbol="SOLUSDT", contract_type="USDT_M", side=TradeDirection.LONG, entry_price=40.0,
        quantity=10, leverage=10, margin_type="ISOLATED", entry_timestamp=ts,
        entry_order_id="entry_sol_1", sl_order_id="sl_sol_1", tp_order_id="tp_sol_1",
        current_sl_price=38.0, current_tp_price=45.0
    )
    assert position.symbol == "SOLUSDT"
    assert position.side == TradeDirection.LONG
    assert position.current_sl_price == 38.0

# Test enums
def test_trade_direction_values():
    assert TradeDirection.LONG.value == "BUY"
    assert TradeDirection.SHORT.value == "SELL"

def test_order_status_values():
    assert OrderStatus.NEW.value == "NEW"
    assert OrderStatus.FILLED.value == "FILLED"
    # ... add more checks if needed

def test_order_type_values():
    assert OrderType.MARKET.value == "MARKET"
    assert OrderType.LIMIT.value == "LIMIT"
    # ... add more checks if needed

def test_order_side_values():
    assert OrderSide.BUY.value == "BUY"
    assert OrderSide.SELL.value == "SELL"

# Test validation if any complex validators were added
# Example: Kline timestamp must be positive
@pytest.mark.parametrize("invalid_ts", [-100, 0])
def test_kline_invalid_timestamp(invalid_ts):
    # Assuming Pydantic models implicitly validate types, but explicit validators can be tested.
    # If Kline had a validator for timestamp > 0:
    # with pytest.raises(ValidationError):
    #     Kline(timestamp=invalid_ts, open=1, high=2, low=0, close=1, volume=10, is_closed=True)
    pass # No explicit validator for this in current model, Pydantic handles type (int)

@pytest.mark.parametrize(
    "symbol_input, expected_output, should_raise",
    [
        ("BTC_USDT", "BTC_USDT", False),
        ("ETH_USD", "ETH_USD", False),
        ("BTCUSD_PERP", "BTCUSD_PERP", False),
        ("BTCUSDT", "BTCUSDT", True), # Fails because _ is missing for USDT_M style
        ("btcusd_perp", "btcusd_perp", False), # Passes as it ends with PERP
    ]
)
def test_pair_config_symbol_validation(symbol_input, expected_output, should_raise):
    if should_raise:
        with pytest.raises(ValidationError):
            PairConfig(symbol=symbol_input, enabled=True)
    else:
        pc = PairConfig(symbol=symbol_input, enabled=True)
        assert pc.symbol == expected_output




================================================
FILE: tests/unit/test_monitoring.py
================================================
import pytest
import asyncio
import time
from unittest.mock import patch, MagicMock
from prometheus_client import REGISTRY

from src.monitoring import PrometheusMonitor

@pytest.fixture
def monitor():
    """Fixture that provides a PrometheusMonitor instance for testing"""
    # Use a high port number to avoid conflicts with any running services
    test_port = 9999
    monitor = PrometheusMonitor(port=test_port)
    yield monitor
    
    # Clean up after test
    monitor._server_started = False
    
    # Clear Prometheus registry to avoid interference between tests
    collectors = list(REGISTRY._collector_to_names.keys())
    for collector in collectors:
        REGISTRY.unregister(collector)


class TestPrometheusMonitor:
    """Tests for the PrometheusMonitor class"""

    def test_initialization(self, monitor):
        """Test that the monitor initializes with the correct metric types"""
        # Check counters
        assert hasattr(monitor, "bot_errors_total")
        assert hasattr(monitor, "websocket_messages_received_total")
        assert hasattr(monitor, "kline_processed_total")
        assert hasattr(monitor, "signals_generated_total")
        assert hasattr(monitor, "orders_placed_total")
        assert hasattr(monitor, "orders_failed_total")
        assert hasattr(monitor, "orders_filled_total")
        
        # Check gauges
        assert hasattr(monitor, "bot_uptime_seconds")
        assert hasattr(monitor, "indicator_calculation_duration_seconds")
        assert hasattr(monitor, "active_positions_count")
        assert hasattr(monitor, "position_pnl_unrealized")
        
        # Check enum
        assert hasattr(monitor, "websocket_connection_status")
        
        # Check info
        assert hasattr(monitor, "bot_info")
        
        # Verify internal state
        assert monitor._server_started is False
        assert isinstance(monitor.port, int)

    @patch('src.monitoring.start_http_server')
    def test_start_method(self, mock_start_http_server, monitor):
        """Test that the start method correctly initializes the HTTP server and metrics"""
        # Test normal start
        monitor.start()
        
        # Verify HTTP server was started with correct port
        mock_start_http_server.assert_called_once_with(monitor.port)
        
        # Verify server started flag is set
        assert monitor._server_started is True
        
        # Check bot_info metric was set
        # For Info metrics, we can only verify it exists as get_sample_value
        # doesn't work the same way for this type
        assert hasattr(monitor, "bot_info")
        
        # Test starting again (should log warning and do nothing)
        monitor.start()
        # Mock should still have been called only once
        mock_start_http_server.assert_called_once()

    @patch('src.monitoring.start_http_server')
    def test_start_method_error_handling(self, mock_start_http_server, monitor):
        """Test error handling when starting the HTTP server fails"""
        # Configure mock to raise an exception
        mock_start_http_server.side_effect = OSError("Port in use")
        
        # Call start method
        monitor.start()
        
        # Verify server started flag remains False
        assert monitor._server_started is False
        
        # Test with a different exception type
        mock_start_http_server.side_effect = Exception("Unknown error")
        
        # Call start method
        monitor.start()
        
        # Verify server started flag remains False
        assert monitor._server_started is False

    def test_stop_method(self, monitor):
        """Test the stop method"""
        # Set the server as started
        monitor._server_started = True
        
        # Call stop method
        monitor.stop()
        
        # Verify server started flag is reset
        assert monitor._server_started is False

    @pytest.mark.asyncio
    @patch('src.monitoring.asyncio.create_task')
    @patch('src.monitoring.start_http_server')
    async def test_uptime_task_creation(self, mock_start_http_server, mock_create_task, monitor):
        """Test that the uptime update task is created correctly"""
        # Start the monitor
        monitor.start()
        
        # Verify create_task was called with the _update_uptime_periodically coroutine
        mock_create_task.assert_called_once()
        
        # The first argument to the first call should be a coroutine
        call_args = mock_create_task.call_args[0][0]
        assert asyncio.iscoroutine(call_args)

    @pytest.mark.asyncio
    async def test_update_uptime_directly(self, monitor):
        """Test the _update_uptime_periodically method directly by calling it once"""
        # Set server as started
        monitor._server_started = True
        
        # Record the start time
        monitor.start_time = time.time() - 10  # pretend we started 10 seconds ago
        
        # Call the method once (manually)
        monitor.bot_uptime_seconds.set(time.time() - monitor.start_time)
        
        # Verify uptime is approximately 10 seconds (with some tolerance)
        uptime = REGISTRY.get_sample_value('trading_bot_uptime_seconds')
        assert uptime is not None
        assert 9.5 <= uptime <= 10.5  # Allow for small timing differences

    def test_inc_bot_error(self, monitor):
        """Test the inc_bot_error method"""
        # Call the method with different labels
        monitor.inc_bot_error(module="TestModule", error_type="TestError")
        monitor.inc_bot_error(module="TestModule", error_type="AnotherError")
        monitor.inc_bot_error(module="AnotherModule", error_type="TestError")
        # Call again with the same labels
        monitor.inc_bot_error(module="TestModule", error_type="TestError")
        
        # Verify counters are incremented correctly
        assert REGISTRY.get_sample_value('trading_bot_errors_total', 
                                       {'module': 'TestModule', 'error_type': 'TestError'}) == 2
        assert REGISTRY.get_sample_value('trading_bot_errors_total', 
                                       {'module': 'TestModule', 'error_type': 'AnotherError'}) == 1
        assert REGISTRY.get_sample_value('trading_bot_errors_total', 
                                       {'module': 'AnotherModule', 'error_type': 'TestError'}) == 1

    def test_set_websocket_status(self, monitor):
        """Test the set_websocket_status method with valid and invalid states"""
        # Test valid states
        monitor.set_websocket_status(market_type="USDT_M", status="connected")
        
        # Check connected=1, others=0
        assert REGISTRY.get_sample_value('trading_bot_websocket_connection_status', 
                                      {'market_type': 'USDT_M', 'trading_bot_websocket_connection_status': 'connected'}) == 1
        assert REGISTRY.get_sample_value('trading_bot_websocket_connection_status', 
                                      {'market_type': 'USDT_M', 'trading_bot_websocket_connection_status': 'disconnected'}) == 0
        
        # Change status
        monitor.set_websocket_status(market_type="USDT_M", status="disconnected")
        
        # Check disconnected=1, others=0
        assert REGISTRY.get_sample_value('trading_bot_websocket_connection_status', 
                                      {'market_type': 'USDT_M', 'trading_bot_websocket_connection_status': 'disconnected'}) == 1
        assert REGISTRY.get_sample_value('trading_bot_websocket_connection_status', 
                                      {'market_type': 'USDT_M', 'trading_bot_websocket_connection_status': 'connected'}) == 0
        
        # Test invalid state
        monitor.set_websocket_status(market_type="USDT_M", status="invalid_state")
        
        # Should set to "error" state
        assert REGISTRY.get_sample_value('trading_bot_websocket_connection_status', 
                                      {'market_type': 'USDT_M', 'trading_bot_websocket_connection_status': 'error'}) == 1
        assert REGISTRY.get_sample_value('trading_bot_websocket_connection_status', 
                                      {'market_type': 'USDT_M', 'trading_bot_websocket_connection_status': 'disconnected'}) == 0

    def test_inc_websocket_message(self, monitor):
        """Test the inc_websocket_message method"""
        # Call the method with different labels
        monitor.inc_websocket_message(market_type="USDT_M", message_type="kline")
        monitor.inc_websocket_message(market_type="USDT_M", message_type="kline")
        monitor.inc_websocket_message(market_type="COIN_M", message_type="depthUpdate")
        
        # Verify counters are incremented correctly
        assert REGISTRY.get_sample_value('trading_bot_websocket_messages_received_total', 
                                       {'market_type': 'USDT_M', 'message_type': 'kline'}) == 2
        assert REGISTRY.get_sample_value('trading_bot_websocket_messages_received_total', 
                                       {'market_type': 'COIN_M', 'message_type': 'depthUpdate'}) == 1

    def test_inc_kline_processed(self, monitor):
        """Test the inc_kline_processed method"""
        # Call the method with different labels
        monitor.inc_kline_processed(symbol="BTCUSDT", interval="1m")
        monitor.inc_kline_processed(symbol="BTCUSDT", interval="1m")
        monitor.inc_kline_processed(symbol="ETHUSDT", interval="5m")
        
        # Verify counters are incremented correctly
        assert REGISTRY.get_sample_value('trading_bot_klines_processed_total', 
                                       {'symbol': 'BTCUSDT', 'interval': '1m'}) == 2
        assert REGISTRY.get_sample_value('trading_bot_klines_processed_total', 
                                       {'symbol': 'ETHUSDT', 'interval': '5m'}) == 1

    def test_set_indicator_calculation_duration(self, monitor):
        """Test the set_indicator_calculation_duration method"""
        # Call the method with different labels and values
        monitor.set_indicator_calculation_duration(symbol="BTCUSDT", interval="1m", duration_seconds=0.123)
        monitor.set_indicator_calculation_duration(symbol="ETHUSDT", interval="5m", duration_seconds=0.456)
        
        # Update value for first label set
        monitor.set_indicator_calculation_duration(symbol="BTCUSDT", interval="1m", duration_seconds=0.789)
        
        # Verify gauge values reflect the last set value
        assert REGISTRY.get_sample_value('trading_bot_indicator_calculation_duration_seconds', 
                                       {'symbol': 'BTCUSDT', 'interval': '1m'}) == 0.789
        assert REGISTRY.get_sample_value('trading_bot_indicator_calculation_duration_seconds', 
                                       {'symbol': 'ETHUSDT', 'interval': '5m'}) == 0.456

    def test_inc_signal_generated(self, monitor):
        """Test the inc_signal_generated method"""
        # Call the method with different labels
        monitor.inc_signal_generated(symbol="BTCUSDT", strategy="V1_SMA", direction="LONG")
        monitor.inc_signal_generated(symbol="BTCUSDT", strategy="V1_SMA", direction="LONG")
        monitor.inc_signal_generated(symbol="ETHUSDT", strategy="V1_SMA", direction="SHORT")
        
        # Verify counters are incremented correctly
        assert REGISTRY.get_sample_value('trading_bot_signals_generated_total', 
                                       {'symbol': 'BTCUSDT', 'strategy': 'V1_SMA', 'direction': 'LONG'}) == 2
        assert REGISTRY.get_sample_value('trading_bot_signals_generated_total', 
                                       {'symbol': 'ETHUSDT', 'strategy': 'V1_SMA', 'direction': 'SHORT'}) == 1

    def test_inc_order_placed(self, monitor):
        """Test the inc_order_placed method"""
        # Call the method with different labels
        monitor.inc_order_placed(symbol="BTCUSDT", order_type="MARKET", side="BUY")
        monitor.inc_order_placed(symbol="BTCUSDT", order_type="MARKET", side="BUY")
        monitor.inc_order_placed(symbol="ETHUSDT", order_type="LIMIT", side="SELL")
        
        # Verify counters are incremented correctly
        assert REGISTRY.get_sample_value('trading_bot_orders_placed_total', 
                                       {'symbol': 'BTCUSDT', 'order_type': 'MARKET', 'side': 'BUY'}) == 2
        assert REGISTRY.get_sample_value('trading_bot_orders_placed_total', 
                                       {'symbol': 'ETHUSDT', 'order_type': 'LIMIT', 'side': 'SELL'}) == 1

    def test_inc_order_failed(self, monitor):
        """Test the inc_order_failed method"""
        # Call the method with different labels
        monitor.inc_order_failed(symbol="BTCUSDT", reason="INSUFFICIENT_BALANCE")
        monitor.inc_order_failed(symbol="BTCUSDT", reason="INSUFFICIENT_BALANCE")
        monitor.inc_order_failed(symbol="ETHUSDT", reason="PRICE_FILTER")
        
        # Verify counters are incremented correctly
        assert REGISTRY.get_sample_value('trading_bot_orders_failed_total', 
                                       {'symbol': 'BTCUSDT', 'reason': 'INSUFFICIENT_BALANCE'}) == 2
        assert REGISTRY.get_sample_value('trading_bot_orders_failed_total', 
                                       {'symbol': 'ETHUSDT', 'reason': 'PRICE_FILTER'}) == 1

    def test_inc_order_filled(self, monitor):
        """Test the inc_order_filled method"""
        # Call the method with different labels
        monitor.inc_order_filled(symbol="BTCUSDT", order_type="MARKET", side="BUY")
        monitor.inc_order_filled(symbol="BTCUSDT", order_type="MARKET", side="BUY")
        monitor.inc_order_filled(symbol="ETHUSDT", order_type="LIMIT", side="SELL")
        
        # Verify counters are incremented correctly
        assert REGISTRY.get_sample_value('trading_bot_orders_filled_total', 
                                       {'symbol': 'BTCUSDT', 'order_type': 'MARKET', 'side': 'BUY'}) == 2
        assert REGISTRY.get_sample_value('trading_bot_orders_filled_total', 
                                       {'symbol': 'ETHUSDT', 'order_type': 'LIMIT', 'side': 'SELL'}) == 1

    def test_set_active_positions_count(self, monitor):
        """Test the set_active_positions_count method"""
        # Call the method with different labels and values
        monitor.set_active_positions_count(contract_type="USDT_M", count=5)
        monitor.set_active_positions_count(contract_type="COIN_M", count=3)
        
        # Update value for first label set
        monitor.set_active_positions_count(contract_type="USDT_M", count=7)
        
        # Verify gauge values reflect the last set value
        assert REGISTRY.get_sample_value('trading_bot_active_positions_count', 
                                       {'contract_type': 'USDT_M'}) == 7
        assert REGISTRY.get_sample_value('trading_bot_active_positions_count', 
                                       {'contract_type': 'COIN_M'}) == 3

    def test_update_active_positions_gauge(self, monitor):
        """Test the update_active_positions_gauge method"""
        # Call the method
        monitor.update_active_positions_gauge(positions_usdt_m=5, positions_coin_m=3)
        
        # Verify both gauges are set correctly
        assert REGISTRY.get_sample_value('trading_bot_active_positions_count', 
                                       {'contract_type': 'USDT_M'}) == 5
        assert REGISTRY.get_sample_value('trading_bot_active_positions_count', 
                                       {'contract_type': 'COIN_M'}) == 3
        
        # Update with new values
        monitor.update_active_positions_gauge(positions_usdt_m=7, positions_coin_m=2)
        
        # Verify both gauges reflect the updated values
        assert REGISTRY.get_sample_value('trading_bot_active_positions_count', 
                                       {'contract_type': 'USDT_M'}) == 7
        assert REGISTRY.get_sample_value('trading_bot_active_positions_count', 
                                       {'contract_type': 'COIN_M'}) == 2

    def test_set_position_pnl(self, monitor):
        """Test the set_position_pnl method"""
        # Call the method with different labels and values
        monitor.set_position_pnl(symbol="BTCUSDT", pnl=10.5)
        monitor.set_position_pnl(symbol="ETHUSDT", pnl=-5.25)
        
        # Update value for first label
        monitor.set_position_pnl(symbol="BTCUSDT", pnl=15.75)
        
        # Verify gauge values reflect the last set value
        assert REGISTRY.get_sample_value('trading_bot_position_pnl_unrealized', 
                                       {'symbol': 'BTCUSDT'}) == 15.75
        assert REGISTRY.get_sample_value('trading_bot_position_pnl_unrealized', 
                                       {'symbol': 'ETHUSDT'}) == -5.25 


================================================
FILE: tests/unit/test_order_manager.py
================================================
import pytest
import asyncio
from unittest.mock import AsyncMock, MagicMock, patch

from src.config_loader import ConfigManager
from src.connectors import BinanceRESTClient
from src.order_manager import OrderManager
from src.models import TradeSignal, TradeDirection, OrderType, OrderSide, Position, OrderStatus

@pytest.fixture
def mock_config_manager_for_om():
    cm = MagicMock(spec=ConfigManager)
    cm.get_config.return_value = {
        "api": {"binance_api_key": "TEST_KEY", "binance_api_secret": "TEST_SECRET"},
        "global_settings": {
            "v1_strategy": {
                "default_margin_usdt": 50.0,
                "default_leverage": 10,
                "margin_mode": "ISOLATED"
            }
        },
        "pairs": {
            "BTC_USDT": {
                "enabled": True, 
                "contract_type": "USDT_M", 
                "margin_usdt": 100.0, # Override global
                "leverage": 20 # Override global
            },
            "ETHUSD_PERP": {
                "enabled": True, 
                "contract_type": "COIN_M", 
                "margin_coin": 0.1, # Interpreted as num_contracts for MVP test
                "leverage": 5
            }
        }
    }
    return cm

@pytest.fixture
def mock_rest_client_for_om():
    rest_client = AsyncMock(spec=BinanceRESTClient)
    # Mock exchange info for precision and limits
    rest_client.fetch_exchange_info.return_value = {
        "BTCUSDT": {
            "symbol": "BTCUSDT",
            "precision": {"amount": "0.00001", "price": "0.01"},
            "limits": {"cost": {"min": "5.0"}, "amount": {"min": "0.00001"}}
        },
        "ETHUSD_PERP": {
            "symbol": "ETHUSD_PERP",
            "precision": {"amount": "0.001", "price": "0.01"}, # COIN-M contracts might be integers or decimals
            "limits": {"cost": {"min": "5.0"}, "amount": {"min": "0.001"}}
        }
    }
    rest_client.create_order = AsyncMock(side_effect=lambda symbol, order_type, side, amount, price=None, params={}:
        AsyncMock(
            return_value={
                "id": f"mock_order_{symbol}_{int(asyncio.get_event_loop().time()*1000)}_", 
                "symbol": symbol, 
                "status": "NEW", 
                "avgPrice": str(price or params.get("stopPrice") or (50000.0 if "BTC" in symbol else 3000.0)),
                "type": order_type
            }
        )() # Call the inner AsyncMock to get the return_value
    )
    return rest_client

@pytest.fixture
def order_manager(mock_config_manager_for_om, mock_rest_client_for_om):
    om = OrderManager(config_manager=mock_config_manager_for_om, rest_client=mock_rest_client_for_om)
    # Prime the cache for exchange info to avoid repeated calls in tests unless specifically testing cache miss
    async def prime_cache():
        await om._get_exchange_info_for_symbol("BTCUSDT")
        await om._get_exchange_info_for_symbol("ETHUSD_PERP")
    asyncio.run(prime_cache())
    return om

# Tests for Precision and Filter Logic
@pytest.mark.asyncio
async def test_om_adjust_quantity_to_precision(order_manager):
    """Test quantity adjustment to precision based on step size."""
    assert order_manager._adjust_quantity_to_precision(0.123456, 0.001) == 0.123
    assert order_manager._adjust_quantity_to_precision(0.123, 0.0001) == 0.123
    assert order_manager._adjust_quantity_to_precision(123.456, 1.0) == 123.0
    assert order_manager._adjust_quantity_to_precision(0.99999, 0.00001) == 0.99999
    assert order_manager._adjust_quantity_to_precision(0.000005, 0.00001) == 0.0 # Floor behavior
    # Test with zero step size (should return original value)
    assert order_manager._adjust_quantity_to_precision(123.456, 0) == 123.456

@pytest.mark.asyncio
async def test_om_adjust_price_to_precision(order_manager):
    """Test price adjustment to precision based on tick size."""
    assert order_manager._adjust_price_to_precision(123.456, 0.01) == 123.46 # Rounds
    assert order_manager._adjust_price_to_precision(123.454, 0.01) == 123.45
    assert order_manager._adjust_price_to_precision(123.5, 1.0) == 124.0
    assert order_manager._adjust_price_to_precision(50000.557, 0.01) == 50000.56
    # Test with zero tick size (should return original value)
    assert order_manager._adjust_price_to_precision(123.456, 0) == 123.456

@pytest.mark.asyncio
async def test_om_get_symbol_filters(order_manager, mock_rest_client_for_om):
    """Test retrieving correct symbol filters from exchange info."""
    # Test for BTCUSDT
    lot_step, price_tick, min_notional = await order_manager._get_symbol_filters("BTCUSDT")
    assert lot_step == 0.00001
    assert price_tick == 0.01
    assert min_notional == 5.0
    
    # Test for ETHUSD_PERP
    lot_step, price_tick, min_notional = await order_manager._get_symbol_filters("ETHUSD_PERP")
    assert lot_step == 0.001
    assert price_tick == 0.01
    assert min_notional == 5.0
    
    # Verify cache is used (fetch_exchange_info should not be called again)
    mock_rest_client_for_om.fetch_exchange_info.reset_mock()
    await order_manager._get_symbol_filters("BTCUSDT")
    mock_rest_client_for_om.fetch_exchange_info.assert_not_called()

@pytest.mark.asyncio
async def test_om_get_symbol_filters_with_missing_data(order_manager, mock_rest_client_for_om):
    """Test handling missing filter data gracefully."""
    # Clear the cache to force a new fetch
    order_manager.exchange_info_cache = {}
    
    # Mock the response with missing data
    mock_rest_client_for_om.fetch_exchange_info.return_value = {
        "BTCUSDT": {
            "symbol": "BTCUSDT",
            # Missing precision and limits data
        }
    }
    
    lot_step, price_tick, min_notional = await order_manager._get_symbol_filters("BTCUSDT")
    assert lot_step is None
    assert price_tick is None
    assert min_notional is None

@pytest.mark.asyncio
async def test_om_get_symbol_filters_fetch_failure(order_manager, mock_rest_client_for_om):
    """Test handling exchange info fetch failure."""
    # Clear the cache to force a new fetch
    order_manager.exchange_info_cache = {}
    
    # Mock fetch_exchange_info to return None (failure)
    mock_rest_client_for_om.fetch_exchange_info.return_value = None
    
    lot_step, price_tick, min_notional = await order_manager._get_symbol_filters("BTCUSDT")
    assert lot_step is None
    assert price_tick is None
    assert min_notional is None

# Tests for Position Sizing
@pytest.mark.asyncio
async def test_om_quantity_calculation_usdt_m(order_manager, mock_rest_client_for_om):
    """Test correct quantity calculation for USDT-M pair."""
    mock_rest_client_for_om.create_order.reset_mock()
    
    signal = TradeSignal(
        symbol="BTCUSDT", config_symbol="BTC_USDT", contract_type="USDT_M",
        direction=TradeDirection.LONG, entry_price=50000.0,
        stop_loss_price=49000.0, take_profit_price=53000.0
    )
    
    await order_manager.handle_trade_signal(signal)
    
    # Expected quantity: (100 USDT margin * 20x leverage) / 50000 entry = 0.04 BTC
    expected_quantity = 0.04
    
    assert mock_rest_client_for_om.create_order.call_count == 3
    entry_call = mock_rest_client_for_om.create_order.call_args_list[0]
    assert entry_call[1]["amount"] == expected_quantity

@pytest.mark.asyncio
async def test_om_quantity_calculation_coin_m(order_manager, mock_rest_client_for_om):
    """Test correct quantity calculation for COIN-M pair (MVP: margin_coin = number of contracts)."""
    mock_rest_client_for_om.create_order.reset_mock()
    
    signal = TradeSignal(
        symbol="ETHUSD_PERP", config_symbol="ETHUSD_PERP", contract_type="COIN_M",
        direction=TradeDirection.LONG, entry_price=3000.0,
        stop_loss_price=2900.0, take_profit_price=3300.0
    )
    
    await order_manager.handle_trade_signal(signal)
    
    # For COIN-M in MVP, margin_coin (0.1) is used directly as the quantity
    expected_quantity = 0.1
    
    assert mock_rest_client_for_om.create_order.call_count == 3
    entry_call = mock_rest_client_for_om.create_order.call_args_list[0]
    assert entry_call[1]["amount"] == expected_quantity

@pytest.mark.asyncio
async def test_om_missing_margin_configuration(order_manager, mock_rest_client_for_om):
    """Test handling missing margin configuration."""
    mock_rest_client_for_om.create_order.reset_mock()
    
    # Create a new config with missing margin settings for BTC_USDT
    config = order_manager.config_manager.get_config.return_value.copy()
    config["pairs"]["BTC_USDT"].pop("margin_usdt")  # Remove margin_usdt
    config["global_settings"]["v1_strategy"].pop("default_margin_usdt")  # Remove default margin
    order_manager.config_manager.get_config.return_value = config
    
    signal = TradeSignal(
        symbol="BTCUSDT", config_symbol="BTC_USDT", contract_type="USDT_M",
        direction=TradeDirection.LONG, entry_price=50000.0,
        stop_loss_price=49000.0, take_profit_price=53000.0
    )
    
    await order_manager.handle_trade_signal(signal)
    
    # No orders should be placed due to missing margin configuration
    assert mock_rest_client_for_om.create_order.call_count == 0

@pytest.mark.asyncio
async def test_om_zero_entry_price(order_manager, mock_rest_client_for_om):
    """Test handling zero or invalid entry price."""
    mock_rest_client_for_om.create_order.reset_mock()
    
    signal = TradeSignal(
        symbol="BTCUSDT", config_symbol="BTC_USDT", contract_type="USDT_M",
        direction=TradeDirection.LONG, entry_price=0.0,  # Zero entry price
        stop_loss_price=0.0, take_profit_price=0.0
    )
    
    await order_manager.handle_trade_signal(signal)
    
    # No orders should be placed due to invalid entry price
    assert mock_rest_client_for_om.create_order.call_count == 0

# Tests for Order Placement Logic
@pytest.mark.asyncio
async def test_om_handle_trade_signal_usdt_m_long(order_manager, mock_rest_client_for_om):
    """Test correct order parameters for USDT-M LONG trade."""
    mock_rest_client_for_om.create_order.reset_mock()
    
    signal = TradeSignal(
        symbol="BTCUSDT", config_symbol="BTC_USDT", contract_type="USDT_M",
        direction=TradeDirection.LONG, entry_price=50000.0,
        stop_loss_price=49000.0, take_profit_price=53000.0
    )
    
    await order_manager.handle_trade_signal(signal)
    
    # Expected quantity: (100 USDT margin * 20x leverage) / 50000 entry = 0.04 BTC
    expected_quantity = 0.04
    
    # Check create_order calls
    assert mock_rest_client_for_om.create_order.call_count == 3
    
    # Check entry order parameters
    entry_call = mock_rest_client_for_om.create_order.call_args_list[0]
    assert entry_call[1]["symbol"] == "BTCUSDT"
    assert entry_call[1]["order_type"] == OrderType.MARKET
    assert entry_call[1]["side"] == OrderSide.BUY
    assert entry_call[1]["amount"] == expected_quantity
    
    # Check SL order parameters
    sl_call = mock_rest_client_for_om.create_order.call_args_list[1]
    assert sl_call[1]["symbol"] == "BTCUSDT"
    assert sl_call[1]["order_type"] == OrderType.STOP_MARKET
    assert sl_call[1]["side"] == OrderSide.SELL
    assert sl_call[1]["amount"] == expected_quantity
    assert sl_call[1]["params"]["stopPrice"] == 49000.00  # Adjusted to 0.01 tick
    assert sl_call[1]["params"]["reduceOnly"] == "true"
    
    # Check TP order parameters
    tp_call = mock_rest_client_for_om.create_order.call_args_list[2]
    assert tp_call[1]["symbol"] == "BTCUSDT"
    assert tp_call[1]["order_type"] == OrderType.TAKE_PROFIT_MARKET
    assert tp_call[1]["side"] == OrderSide.SELL
    assert tp_call[1]["amount"] == expected_quantity
    assert tp_call[1]["params"]["stopPrice"] == 53000.00  # Adjusted to 0.01 tick
    assert tp_call[1]["params"]["reduceOnly"] == "true"

@pytest.mark.asyncio
async def test_om_handle_trade_signal_usdt_m_short(order_manager, mock_rest_client_for_om):
    """Test correct order parameters for USDT-M SHORT trade."""
    mock_rest_client_for_om.create_order.reset_mock()
    
    signal = TradeSignal(
        symbol="BTCUSDT", config_symbol="BTC_USDT", contract_type="USDT_M",
        direction=TradeDirection.SHORT, entry_price=50000.0,
        stop_loss_price=51000.0, take_profit_price=47000.0
    )
    
    await order_manager.handle_trade_signal(signal)
    
    # Expected quantity: (100 USDT margin * 20x leverage) / 50000 entry = 0.04 BTC
    expected_quantity = 0.04
    
    # Check create_order calls
    assert mock_rest_client_for_om.create_order.call_count == 3
    
    # Check entry order parameters
    entry_call = mock_rest_client_for_om.create_order.call_args_list[0]
    assert entry_call[1]["symbol"] == "BTCUSDT"
    assert entry_call[1]["order_type"] == OrderType.MARKET
    assert entry_call[1]["side"] == OrderSide.SELL
    assert entry_call[1]["amount"] == expected_quantity
    
    # Check SL order parameters
    sl_call = mock_rest_client_for_om.create_order.call_args_list[1]
    assert sl_call[1]["symbol"] == "BTCUSDT"
    assert sl_call[1]["order_type"] == OrderType.STOP_MARKET
    assert sl_call[1]["side"] == OrderSide.BUY
    assert sl_call[1]["amount"] == expected_quantity
    assert sl_call[1]["params"]["stopPrice"] == 51000.00  # Adjusted to 0.01 tick
    assert sl_call[1]["params"]["reduceOnly"] == "true"
    
    # Check TP order parameters
    tp_call = mock_rest_client_for_om.create_order.call_args_list[2]
    assert tp_call[1]["symbol"] == "BTCUSDT"
    assert tp_call[1]["order_type"] == OrderType.TAKE_PROFIT_MARKET
    assert tp_call[1]["side"] == OrderSide.BUY
    assert tp_call[1]["amount"] == expected_quantity
    assert tp_call[1]["params"]["stopPrice"] == 47000.00  # Adjusted to 0.01 tick
    assert tp_call[1]["params"]["reduceOnly"] == "true"

@pytest.mark.asyncio
async def test_om_handle_trade_signal_coin_m_short(order_manager, mock_rest_client_for_om):
    """Test correct order parameters for COIN-M SHORT trade."""
    mock_rest_client_for_om.create_order.reset_mock()
    
    signal = TradeSignal(
        symbol="ETHUSD_PERP", config_symbol="ETHUSD_PERP", contract_type="COIN_M",
        direction=TradeDirection.SHORT, entry_price=3000.0,
        stop_loss_price=3100.0, take_profit_price=2700.0
    )
    
    await order_manager.handle_trade_signal(signal)
    
    # Expected quantity for COIN-M (margin_coin=0.1 is used as num_contracts for MVP test)
    expected_quantity = 0.1
    
    assert mock_rest_client_for_om.create_order.call_count == 3
    
    # Check entry order parameters
    entry_call = mock_rest_client_for_om.create_order.call_args_list[0]
    assert entry_call[1]["symbol"] == "ETHUSD_PERP"
    assert entry_call[1]["order_type"] == OrderType.MARKET
    assert entry_call[1]["side"] == OrderSide.SELL
    assert entry_call[1]["amount"] == expected_quantity
    
    # Check SL order parameters
    sl_call = mock_rest_client_for_om.create_order.call_args_list[1]
    assert sl_call[1]["symbol"] == "ETHUSD_PERP"
    assert sl_call[1]["order_type"] == OrderType.STOP_MARKET
    assert sl_call[1]["side"] == OrderSide.BUY
    assert sl_call[1]["amount"] == expected_quantity
    assert sl_call[1]["params"]["stopPrice"] == 3100.00
    assert sl_call[1]["params"]["reduceOnly"] == "true"
    
    # Check TP order parameters
    tp_call = mock_rest_client_for_om.create_order.call_args_list[2]
    assert tp_call[1]["symbol"] == "ETHUSD_PERP"
    assert tp_call[1]["order_type"] == OrderType.TAKE_PROFIT_MARKET
    assert tp_call[1]["side"] == OrderSide.BUY
    assert tp_call[1]["amount"] == expected_quantity
    assert tp_call[1]["params"]["stopPrice"] == 2700.00
    assert tp_call[1]["params"]["reduceOnly"] == "true"

@pytest.mark.asyncio
async def test_om_min_notional_check_usdt_m(order_manager, mock_rest_client_for_om):
    """Test minimum notional value check for USDT-M."""
    mock_rest_client_for_om.create_order.reset_mock()
    
    # Test case that passes min notional check
    signal_high_notional = TradeSignal(
        symbol="BTCUSDT", config_symbol="BTC_USDT", contract_type="USDT_M",
        direction=TradeDirection.LONG, entry_price=1.0,
        stop_loss_price=0.9, take_profit_price=1.3
    )
    await order_manager.handle_trade_signal(signal_high_notional)
    assert mock_rest_client_for_om.create_order.call_count == 3  # Orders should be placed
    mock_rest_client_for_om.create_order.reset_mock()
    
    # Test case that fails min notional check by modifying config
    # Set margin_usdt and leverage so that margin_usdt * leverage < min_notional
    order_manager.config_manager.get_config.return_value["pairs"]["BTC_USDT"]["margin_usdt"] = 0.1
    order_manager.config_manager.get_config.return_value["pairs"]["BTC_USDT"]["leverage"] = 10
    # Now notional is 0.1 * 10 = 1.0 USDT. Min notional is 5.0. Should fail.
    
    signal_low_notional = TradeSignal(
        symbol="BTCUSDT", config_symbol="BTC_USDT", contract_type="USDT_M",
        direction=TradeDirection.LONG, entry_price=50000.0,
        stop_loss_price=49000.0, take_profit_price=53000.0
    )
    await order_manager.handle_trade_signal(signal_low_notional)
    
    # No orders should be placed due to min notional check failure
    assert mock_rest_client_for_om.create_order.call_count == 0
    
    # Reset config for other tests
    order_manager.config_manager.get_config.return_value["pairs"]["BTC_USDT"]["margin_usdt"] = 100.0
    order_manager.config_manager.get_config.return_value["pairs"]["BTC_USDT"]["leverage"] = 20

@pytest.mark.asyncio
async def test_om_handle_trade_signal_zero_quantity(order_manager, mock_rest_client_for_om):
    """Test handling zero calculated quantity."""
    mock_rest_client_for_om.create_order.reset_mock()
    
    # Mock _get_symbol_filters to return a larger step_size that will cause quantity to be floored to zero
    with patch.object(order_manager, '_get_symbol_filters', new_callable=AsyncMock) as mock_filters:
        mock_filters.return_value = (0.001, 0.01, 5.0)  # Lot_step = 0.001
        
        signal = TradeSignal(
            symbol="BTCUSDT", config_symbol="BTC_USDT", contract_type="USDT_M",
            direction=TradeDirection.LONG, entry_price=10000000.0,  # Very high price
            stop_loss_price=9000000.0, take_profit_price=13000000.0
        )
        
        # Expected raw quantity: (100 * 20) / 10000000 = 0.0002
        # Adjusted with step 0.001: floor(0.0002 / 0.001) * 0.001 = 0.0
        await order_manager.handle_trade_signal(signal)
        
        # No orders should be placed due to zero quantity
        assert mock_rest_client_for_om.create_order.call_count == 0

# Tests for Error Handling
@pytest.mark.asyncio
async def test_om_exchange_info_fetch_failure(order_manager, mock_rest_client_for_om):
    """Test handling failure to fetch exchange info."""
    mock_rest_client_for_om.create_order.reset_mock()
    
    # Clear the cache to force a new fetch
    order_manager.exchange_info_cache = {}
    
    # Mock exchange_info fetch to return None (failure)
    mock_rest_client_for_om.fetch_exchange_info.return_value = None
    
    signal = TradeSignal(
        symbol="BTCUSDT", config_symbol="BTC_USDT", contract_type="USDT_M",
        direction=TradeDirection.LONG, entry_price=50000.0,
        stop_loss_price=49000.0, take_profit_price=53000.0
    )
    
    await order_manager.handle_trade_signal(signal)
    
    # No orders should be placed due to exchange info fetch failure
    assert mock_rest_client_for_om.create_order.call_count == 0

@pytest.mark.asyncio
async def test_om_entry_order_placement_failure(order_manager, mock_rest_client_for_om):
    """Test handling entry order placement failure."""
    mock_rest_client_for_om.create_order.reset_mock()
    
    # Mock the first call to create_order (entry order) to return None (failure)
    mock_rest_client_for_om.create_order.side_effect = [
        None,  # Entry order fails
        {"id": "mock_sl_order_id"},  # SL order (shouldn't be called)
        {"id": "mock_tp_order_id"}   # TP order (shouldn't be called)
    ]
    
    signal = TradeSignal(
        symbol="BTCUSDT", config_symbol="BTC_USDT", contract_type="USDT_M",
        direction=TradeDirection.LONG, entry_price=50000.0,
        stop_loss_price=49000.0, take_profit_price=53000.0
    )
    
    await order_manager.handle_trade_signal(signal)
    
    # Only entry order should be attempted, and it fails
    assert mock_rest_client_for_om.create_order.call_count == 1

@pytest.mark.asyncio
async def test_om_entry_order_rejected(order_manager, mock_rest_client_for_om):
    """Test handling entry order rejection."""
    mock_rest_client_for_om.create_order.reset_mock()
    
    # Mock the first call to create_order (entry order) to return a rejected status
    mock_rest_client_for_om.create_order.side_effect = [
        {"id": "mock_entry_order_id", "status": OrderStatus.REJECTED},  # Entry order rejected
        {"id": "mock_sl_order_id"},  # SL order (shouldn't be called)
        {"id": "mock_tp_order_id"}   # TP order (shouldn't be called)
    ]
    
    signal = TradeSignal(
        symbol="BTCUSDT", config_symbol="BTC_USDT", contract_type="USDT_M",
        direction=TradeDirection.LONG, entry_price=50000.0,
        stop_loss_price=49000.0, take_profit_price=53000.0
    )
    
    await order_manager.handle_trade_signal(signal)
    
    # Only entry order should be attempted, but SL/TP are not placed due to rejected entry
    assert mock_rest_client_for_om.create_order.call_count == 1

@pytest.mark.asyncio
async def test_om_sl_order_placement_failure(order_manager, mock_rest_client_for_om):
    """Test handling SL order placement failure."""
    mock_rest_client_for_om.create_order.reset_mock()
    
    # Mock create_order to succeed for entry but fail for SL
    mock_rest_client_for_om.create_order.side_effect = [
        {"id": "mock_entry_order_id", "status": "NEW"},  # Entry order succeeds
        None,  # SL order fails
        {"id": "mock_tp_order_id"}   # TP order should still be attempted
    ]
    
    signal = TradeSignal(
        symbol="BTCUSDT", config_symbol="BTC_USDT", contract_type="USDT_M",
        direction=TradeDirection.LONG, entry_price=50000.0,
        stop_loss_price=49000.0, take_profit_price=53000.0
    )
    
    await order_manager.handle_trade_signal(signal)
    
    # Entry order succeeds, SL fails, but TP is still attempted
    assert mock_rest_client_for_om.create_order.call_count == 3

@pytest.mark.asyncio
async def test_om_tp_order_placement_failure(order_manager, mock_rest_client_for_om):
    """Test handling TP order placement failure."""
    mock_rest_client_for_om.create_order.reset_mock()
    
    # Mock create_order to succeed for entry and SL but fail for TP
    mock_rest_client_for_om.create_order.side_effect = [
        {"id": "mock_entry_order_id", "status": "NEW"},  # Entry order succeeds
        {"id": "mock_sl_order_id"},   # SL order succeeds
        None  # TP order fails
    ]
    
    signal = TradeSignal(
        symbol="BTCUSDT", config_symbol="BTC_USDT", contract_type="USDT_M",
        direction=TradeDirection.LONG, entry_price=50000.0,
        stop_loss_price=49000.0, take_profit_price=53000.0
    )
    
    await order_manager.handle_trade_signal(signal)
    
    # All three orders should be attempted, but TP fails
    assert mock_rest_client_for_om.create_order.call_count == 3

@pytest.mark.asyncio
async def test_om_unknown_contract_type(order_manager, mock_rest_client_for_om):
    """Test handling unknown contract type."""
    mock_rest_client_for_om.create_order.reset_mock()
    
    # Create a signal with an invalid contract type
    signal = TradeSignal(
        symbol="BTCUSDT", config_symbol="BTC_USDT", contract_type="UNKNOWN_TYPE",  # Invalid type
        direction=TradeDirection.LONG, entry_price=50000.0,
        stop_loss_price=49000.0, take_profit_price=53000.0
    )
    
    await order_manager.handle_trade_signal(signal)
    
    # No orders should be placed due to unknown contract type
    assert mock_rest_client_for_om.create_order.call_count == 0




================================================
FILE: tests/unit/test_position_manager.py
================================================
import pytest
import asyncio
from unittest.mock import AsyncMock, MagicMock, patch
from threading import RLock

from src.config_loader import ConfigManager
from src.position_manager import PositionManager
from src.models import Position, Order, OrderStatus, TradeDirection, OrderType, OrderSide

@pytest.fixture
def mock_config_manager_for_pm():
    cm = MagicMock(spec=ConfigManager)
    cm.get_config.return_value = {}  # Empty config is fine for PositionManager tests
    return cm

@pytest.fixture
def position_manager(mock_config_manager_for_pm):
    return PositionManager(config_manager=mock_config_manager_for_pm)

@pytest.mark.asyncio
async def test_pm_empty_state(position_manager):
    """Test that a new PositionManager returns correct values when empty."""
    # Verify getters return correct values when empty
    assert position_manager.get_position("BTCUSDT") is None
    assert position_manager.get_all_positions() == []
    assert position_manager.has_open_position("BTCUSDT") is False
    assert position_manager.has_open_position("ETHUSDT") is False

@pytest.mark.asyncio
async def test_pm_add_get_position(position_manager):
    # Test adding a position
    pos_data = Position(
        symbol="BTCUSDT", contract_type="USDT_M", side=TradeDirection.LONG,
        entry_price=50000.0, quantity=0.01, entry_order_id="entry1",
        sl_order_id="sl1", tp_order_id="tp1"
    )
    await position_manager.add_or_update_position(pos_data)
    
    # Test retrieving the position
    retrieved_pos = position_manager.get_position("BTCUSDT")
    assert retrieved_pos is not None
    assert retrieved_pos.symbol == "BTCUSDT"
    assert retrieved_pos.entry_price == 50000.0
    assert retrieved_pos.quantity == 0.01
    assert retrieved_pos.sl_order_id == "sl1"
    
    # Test has_open_position
    assert position_manager.has_open_position("BTCUSDT") is True
    assert position_manager.has_open_position("ETHUSDT") is False
    
    # Test get_all_positions
    all_positions = position_manager.get_all_positions()
    assert len(all_positions) == 1
    assert all_positions[0].symbol == "BTCUSDT"

@pytest.mark.asyncio
async def test_pm_update_position(position_manager):
    # Add initial position
    pos_data = Position(
        symbol="ETHUSDT", contract_type="USDT_M", side=TradeDirection.SHORT,
        entry_price=3000.0, quantity=0.1, entry_order_id="entry2",
        sl_order_id="sl2", tp_order_id="tp2"
    )
    await position_manager.add_or_update_position(pos_data)
    
    # Update the position
    updated_pos_data = Position(
        symbol="ETHUSDT", contract_type="USDT_M", side=TradeDirection.SHORT,
        entry_price=3000.0, quantity=0.1, entry_order_id="entry2",
        sl_order_id="sl2_new", tp_order_id="tp2", # Changed SL order ID
        current_sl_price=3100.0, # Added SL price
        unrealized_pnl=-50.0 # Added PnL
    )
    await position_manager.add_or_update_position(updated_pos_data)
    
    # Verify the update
    retrieved_pos = position_manager.get_position("ETHUSDT")
    assert retrieved_pos.sl_order_id == "sl2_new"
    assert retrieved_pos.current_sl_price == 3100.0
    assert retrieved_pos.unrealized_pnl == -50.0

@pytest.mark.asyncio
async def test_pm_remove_position(position_manager):
    # Add a position
    pos_data = Position(
        symbol="SOLUSDT", contract_type="USDT_M", side=TradeDirection.LONG,
        entry_price=100.0, quantity=1.0, entry_order_id="entry3",
        sl_order_id="sl3", tp_order_id="tp3"
    )
    await position_manager.add_or_update_position(pos_data)
    assert position_manager.has_open_position("SOLUSDT") is True
    
    # Remove the position
    await position_manager.remove_position("SOLUSDT")
    assert position_manager.has_open_position("SOLUSDT") is False
    assert position_manager.get_position("SOLUSDT") is None
    
    # Test removing a non-existent position (should not raise error)
    await position_manager.remove_position("NONEXISTENT")

@pytest.mark.asyncio
async def test_pm_update_position_on_entry_order_fill(position_manager):
    # Add a position
    pos_data = Position(
        symbol="BTCUSDT", contract_type="USDT_M", side=TradeDirection.LONG,
        entry_price=50000.0, quantity=0.01, entry_order_id="entry1",
        sl_order_id="sl1", tp_order_id="tp1"
    )
    await position_manager.add_or_update_position(pos_data)
    
    # Simulate entry order fill with different fill price
    entry_order_fill = Order(
        order_id="entry1", symbol="BTCUSDT", type=OrderType.MARKET, side=OrderSide.BUY,
        quantity=0.01, status=OrderStatus.FILLED, timestamp=1234567890,
        avg_fill_price=50100.0, filled_quantity=0.01
    )
    await position_manager.update_position_on_order_update(entry_order_fill)
    
    # Verify entry price was updated
    updated_pos = position_manager.get_position("BTCUSDT")
    assert updated_pos.entry_price == 50100.0

@pytest.mark.asyncio
async def test_pm_update_position_on_sl_order_fill(position_manager):
    # Add a position
    pos_data = Position(
        symbol="BTCUSDT", contract_type="USDT_M", side=TradeDirection.LONG,
        entry_price=50000.0, quantity=0.01, entry_order_id="entry1",
        sl_order_id="sl1", tp_order_id="tp1"
    )
    await position_manager.add_or_update_position(pos_data)
    
    # Simulate SL order fill
    sl_order_fill = Order(
        order_id="sl1", symbol="BTCUSDT", type=OrderType.STOP_MARKET, side=OrderSide.SELL,
        quantity=0.01, status=OrderStatus.FILLED, timestamp=1234567890,
        avg_fill_price=49000.0, filled_quantity=0.01
    )
    await position_manager.update_position_on_order_update(sl_order_fill)
    
    # Verify position was removed
    assert position_manager.has_open_position("BTCUSDT") is False

@pytest.mark.asyncio
async def test_pm_update_position_on_tp_order_fill(position_manager):
    # Add a position
    pos_data = Position(
        symbol="BTCUSDT", contract_type="USDT_M", side=TradeDirection.LONG,
        entry_price=50000.0, quantity=0.01, entry_order_id="entry1",
        sl_order_id="sl1", tp_order_id="tp1"
    )
    await position_manager.add_or_update_position(pos_data)
    
    # Simulate TP order fill
    tp_order_fill = Order(
        order_id="tp1", symbol="BTCUSDT", type=OrderType.TAKE_PROFIT_MARKET, side=OrderSide.SELL,
        quantity=0.01, status=OrderStatus.FILLED, timestamp=1234567890,
        avg_fill_price=52000.0, filled_quantity=0.01
    )
    await position_manager.update_position_on_order_update(tp_order_fill)
    
    # Verify position was removed
    assert position_manager.has_open_position("BTCUSDT") is False

@pytest.mark.asyncio
async def test_pm_update_position_on_order_cancel(position_manager):
    # Add a position
    pos_data = Position(
        symbol="BTCUSDT", contract_type="USDT_M", side=TradeDirection.LONG,
        entry_price=50000.0, quantity=0.01, entry_order_id="entry1",
        sl_order_id="sl1", tp_order_id="tp1"
    )
    await position_manager.add_or_update_position(pos_data)
    
    # Simulate SL order cancellation
    sl_order_cancel = Order(
        order_id="sl1", symbol="BTCUSDT", type=OrderType.STOP_MARKET, side=OrderSide.SELL,
        quantity=0.01, status=OrderStatus.CANCELED, timestamp=1234567890
    )
    await position_manager.update_position_on_order_update(sl_order_cancel)
    
    # Verify SL order ID was cleared
    updated_pos = position_manager.get_position("BTCUSDT")
    assert updated_pos.sl_order_id is None
    assert updated_pos.tp_order_id == "tp1"  # TP order should still be there

@pytest.mark.asyncio
async def test_pm_update_position_on_entry_order_cancel(position_manager):
    # Add a position
    pos_data = Position(
        symbol="BTCUSDT", contract_type="USDT_M", side=TradeDirection.LONG,
        entry_price=50000.0, quantity=0.01, entry_order_id="entry1",
        sl_order_id="sl1", tp_order_id="tp1"
    )
    await position_manager.add_or_update_position(pos_data)
    
    # Simulate entry order cancellation
    entry_order_cancel = Order(
        order_id="entry1", symbol="BTCUSDT", type=OrderType.MARKET, side=OrderSide.BUY,
        quantity=0.01, status=OrderStatus.CANCELED, timestamp=1234567890
    )
    await position_manager.update_position_on_order_update(entry_order_cancel)
    
    # Verify position was removed
    assert position_manager.has_open_position("BTCUSDT") is False

@pytest.mark.asyncio
async def test_pm_update_position_on_order_reject(position_manager):
    # Add a position
    pos_data = Position(
        symbol="BTCUSDT", contract_type="USDT_M", side=TradeDirection.LONG,
        entry_price=50000.0, quantity=0.01, entry_order_id="entry1",
        sl_order_id="sl1", tp_order_id="tp1"
    )
    await position_manager.add_or_update_position(pos_data)
    
    # Simulate TP order rejection
    tp_order_reject = Order(
        order_id="tp1", symbol="BTCUSDT", type=OrderType.TAKE_PROFIT_MARKET, side=OrderSide.SELL,
        quantity=0.01, status=OrderStatus.REJECTED, timestamp=1234567890
    )
    await position_manager.update_position_on_order_update(tp_order_reject)
    
    # Verify TP order ID was cleared
    updated_pos = position_manager.get_position("BTCUSDT")
    assert updated_pos.tp_order_id is None
    assert updated_pos.sl_order_id == "sl1"  # SL order should still be there

@pytest.mark.asyncio
async def test_pm_update_position_on_unrelated_order(position_manager):
    """Test that unrelated order updates don't affect positions."""
    # Add a position
    pos_data = Position(
        symbol="BTCUSDT", contract_type="USDT_M", side=TradeDirection.LONG,
        entry_price=50000.0, quantity=0.01, entry_order_id="entry1",
        sl_order_id="sl1", tp_order_id="tp1"
    )
    await position_manager.add_or_update_position(pos_data)
    
    # Create a snapshot of the position before the update
    original_pos = position_manager.get_position("BTCUSDT")
    
    # Simulate an order update with an unrelated order ID
    unrelated_order = Order(
        order_id="unrelated123", symbol="BTCUSDT", type=OrderType.MARKET, side=OrderSide.BUY,
        quantity=0.01, status=OrderStatus.FILLED, timestamp=1234567890
    )
    await position_manager.update_position_on_order_update(unrelated_order)
    
    # Verify position state remains unchanged
    updated_pos = position_manager.get_position("BTCUSDT")
    assert updated_pos.entry_order_id == original_pos.entry_order_id
    assert updated_pos.sl_order_id == original_pos.sl_order_id
    assert updated_pos.tp_order_id == original_pos.tp_order_id
    assert updated_pos.entry_price == original_pos.entry_price

@pytest.mark.asyncio
async def test_pm_update_position_on_order_for_nonexistent_position(position_manager):
    """Test handling order updates for symbols with no tracked position."""
    # Ensure no position exists
    assert position_manager.has_open_position("XYZUSDT") is False
    
    # Simulate an order update for a symbol with no position
    order = Order(
        order_id="xyz123", symbol="XYZUSDT", type=OrderType.MARKET, side=OrderSide.BUY,
        quantity=0.01, status=OrderStatus.FILLED, timestamp=1234567890
    )
    # This should not raise an error
    await position_manager.update_position_on_order_update(order)
    
    # Verify no position was created
    assert position_manager.has_open_position("XYZUSDT") is False

@pytest.mark.asyncio
async def test_pm_reconcile_positions_with_exchange(position_manager):
    # Mock REST client
    mock_rest_client = AsyncMock()
    mock_rest_client.fetch_positions.return_value = [
        {
            "symbol": "BTCUSDT",
            "contracts": 0.01,
            "entryPrice": 50000.0,
            "marginType": "ISOLATED",
            "leverage": 20,
            "unrealizedPnl": 100.0,
            "liquidationPrice": 45000.0,
            "markPrice": 51000.0
        },
        {
            "symbol": "ETHUSDT",
            "contracts": -0.1,  # Negative for SHORT
            "entryPrice": 3000.0,
            "marginType": "ISOLATED",
            "leverage": 10,
            "unrealizedPnl": -50.0,
            "liquidationPrice": 3300.0,
            "markPrice": 3050.0
        }
    ]
    
    # Add a position that doesn't exist on exchange
    pos_data = Position(
        symbol="SOLUSDT", contract_type="USDT_M", side=TradeDirection.LONG,
        entry_price=100.0, quantity=1.0, entry_order_id="entry3",
        sl_order_id="sl3", tp_order_id="tp3"
    )
    await position_manager.add_or_update_position(pos_data)
    
    # Reconcile
    await position_manager.reconcile_positions_with_exchange(mock_rest_client)
    
    # Verify positions from exchange were added
    btc_pos = position_manager.get_position("BTCUSDT")
    assert btc_pos is not None
    assert btc_pos.side == TradeDirection.LONG
    assert btc_pos.entry_price == 50000.0
    assert btc_pos.quantity == 0.01
    assert btc_pos.unrealized_pnl == 100.0
    
    eth_pos = position_manager.get_position("ETHUSDT")
    assert eth_pos is not None
    assert eth_pos.side == TradeDirection.SHORT
    assert eth_pos.entry_price == 3000.0
    assert eth_pos.quantity == 0.1
    assert eth_pos.unrealized_pnl == -50.0
    
    # Verify position not on exchange was removed
    assert position_manager.has_open_position("SOLUSDT") is False

@pytest.mark.asyncio
async def test_pm_reconcile_positions_with_zero_quantity(position_manager):
    """Test reconciling with an exchange position that has zero quantity."""
    # Mock REST client with a zero-quantity position
    mock_rest_client = AsyncMock()
    mock_rest_client.fetch_positions.return_value = [
        {
            "symbol": "BTCUSDT",
            "contracts": 0,  # Zero quantity position
            "entryPrice": 50000.0,
            "marginType": "ISOLATED",
            "leverage": 20
        }
    ]
    
    # Add a position for BTCUSDT in manager
    pos_data = Position(
        symbol="BTCUSDT", contract_type="USDT_M", side=TradeDirection.LONG,
        entry_price=50000.0, quantity=0.01, entry_order_id="entry1"
    )
    await position_manager.add_or_update_position(pos_data)
    assert position_manager.has_open_position("BTCUSDT") is True
    
    # Reconcile
    await position_manager.reconcile_positions_with_exchange(mock_rest_client)
    
    # Verify position was removed (because exchange shows zero quantity)
    assert position_manager.has_open_position("BTCUSDT") is False

@pytest.mark.asyncio
async def test_pm_reconcile_positions_with_exchange_error(position_manager):
    """Test reconciliation when fetch_positions returns None or raises an exception."""
    # Add a position that should remain untouched if fetch_positions fails
    pos_data = Position(
        symbol="BTCUSDT", contract_type="USDT_M", side=TradeDirection.LONG,
        entry_price=50000.0, quantity=0.01, entry_order_id="entry1"
    )
    await position_manager.add_or_update_position(pos_data)
    
    # Case 1: fetch_positions returns None
    mock_rest_client1 = AsyncMock()
    mock_rest_client1.fetch_positions.return_value = None
    
    # Reconcile - should not modify positions
    await position_manager.reconcile_positions_with_exchange(mock_rest_client1)
    assert position_manager.has_open_position("BTCUSDT") is True
    
    # Case 2: fetch_positions raises an exception
    mock_rest_client2 = AsyncMock()
    mock_rest_client2.fetch_positions.side_effect = Exception("API Error")
    
    # Reconcile - should not modify positions
    await position_manager.reconcile_positions_with_exchange(mock_rest_client2)
    assert position_manager.has_open_position("BTCUSDT") is True

@pytest.mark.asyncio
async def test_pm_thread_safety(position_manager):
    # This test is more conceptual than practical in a unit test environment
    # In a real multi-threaded environment, we'd need to test with actual threads
    
    # Verify the lock exists and is a RLock
    assert hasattr(position_manager, "_lock")
    assert isinstance(position_manager._lock, RLock)
    
    # Test that methods use the lock (we can't directly test this without mocking the lock)
    # But we can verify the methods work correctly
    pos_data = Position(
        symbol="BTCUSDT", contract_type="USDT_M", side=TradeDirection.LONG,
        entry_price=50000.0, quantity=0.01, entry_order_id="entry1",
        sl_order_id="sl1", tp_order_id="tp1"
    )
    await position_manager.add_or_update_position(pos_data)
    assert position_manager.get_position("BTCUSDT") is not None
    
    # Simulate concurrent operations
    await asyncio.gather(
        position_manager.add_or_update_position(pos_data),
        position_manager.get_position("BTCUSDT"),
        position_manager.get_all_positions()
    )
    # If no exceptions, the lock is working as expected



================================================
FILE: tests/unit/test_signal_engine.py
================================================
import pytest
import asyncio
import pandas as pd
import time
from unittest.mock import MagicMock, AsyncMock, patch

from src.config_loader import ConfigManager
from src.data_processor import DataProcessor
from src.signal_engine import SignalEngineV1
from src.models import TradeSignal, TradeDirection, Kline

@pytest.fixture
def mock_config_manager_for_se():
    cm = MagicMock(spec=ConfigManager)
    cm.get_config.return_value = {
        "global_settings": {
            "v1_strategy": {
                "sma_short_period": 3,
                "sma_long_period": 5,
                "min_signal_interval_minutes": 15,
                "tp_sl_ratio": 2.0
            }
        },
        "pairs": {
            "BTC_USDT": {"enabled": True, "contract_type": "USDT_M"},
            "ETH_USDT": {
                "enabled": True, 
                "contract_type": "USDT_M",
                "min_signal_interval_minutes": 0  # For testing without wait
            },
            "SOL_USDT": {
                "enabled": True,
                "contract_type": "USDT_M",
                "tp_sl_ratio": 3.5  # Custom R:R ratio for testing
            }
        }
    }
    return cm

@pytest.fixture
def mock_data_processor_for_se():
    dp = MagicMock(spec=DataProcessor)
    return dp

@pytest.fixture
def signal_engine_v1(mock_config_manager_for_se, mock_data_processor_for_se):
    return SignalEngineV1(config_manager=mock_config_manager_for_se, data_processor=mock_data_processor_for_se)

# Helper to create a DataFrame for mock_data_processor
def create_mock_df(sma_short_prev, sma_long_prev, sma_short_curr, sma_long_curr, close_curr=100, low_lookback=[90,91,89], high_lookback=[110,109,111]):
    # Ensure lookback arrays are long enough for pivot logic if needed
    # Create enough past data for pivot calculation (e.g., 30 candles)
    past_lows = low_lookback * 10  # Repeat to make it 30 long
    past_highs = high_lookback * 10
    past_closes = [close_curr - 1] * 30  # Dummy past closes

    data = {
        "timestamp": list(range(1000, 32000, 1000)),  # 31 points for previous, 1 for current
        "open": [close_curr-1]*30 + [close_curr-1, close_curr-0.5],
        "high": past_highs + [max(high_lookback), close_curr + 2],
        "low": past_lows + [min(low_lookback), close_curr - 2],
        "close": past_closes + [close_curr-1, close_curr],
        "volume": [100]*32,
        "is_closed": [True]*31 + [True],  # Current candle is also closed for signal generation
        "sma_short": [sma_short_prev -1]*30 + [sma_short_prev, sma_short_curr],
        "sma_long": [sma_long_prev-1]*30 + [sma_long_prev, sma_long_curr],
    }
    df = pd.DataFrame(data)
    df.set_index("timestamp", inplace=True)
    return df

# Helper to create a shorter DataFrame with specific values
def create_limited_df(rows=5, with_na=False):
    """Creates a small DataFrame with limited rows - useful for testing insufficient data scenarios"""
    data = {
        "timestamp": list(range(1000, 1000 + rows * 1000, 1000)),
        "open": [99] * rows,
        "high": [101] * rows,
        "low": [98] * rows,
        "close": [100] * rows,
        "volume": [100] * rows,
        "is_closed": [True] * rows,
        "sma_short": [99] * rows,
        "sma_long": [100] * rows
    }
    
    # Set some values to NA if requested
    if with_na:
        data["sma_short"][-1] = pd.NA
    
    df = pd.DataFrame(data)
    df.set_index("timestamp", inplace=True)
    return df

# 1. Test Signal Generation Logic
@pytest.mark.asyncio
async def test_se_no_signal_if_not_enough_data(signal_engine_v1, mock_data_processor_for_se):
    # Test with empty DataFrame
    mock_data_processor_for_se.get_indicator_dataframe.return_value = pd.DataFrame()  # Empty DF
    signal = await signal_engine_v1.check_signal("BTCUSDT", "BTC_USDT")
    assert signal is None

    # Test with None DataFrame
    mock_data_processor_for_se.get_indicator_dataframe.return_value = None
    signal = await signal_engine_v1.check_signal("BTCUSDT", "BTC_USDT")
    assert signal is None

    # Test with only one row
    mock_data_processor_for_se.get_indicator_dataframe.return_value = create_mock_df(10,20,11,19)[:1]  # Only one row
    signal = await signal_engine_v1.check_signal("BTCUSDT", "BTC_USDT")
    assert signal is None

@pytest.mark.asyncio
async def test_se_no_signal_if_sma_na(signal_engine_v1, mock_data_processor_for_se):
    # Test with NA in latest SMA short
    df_with_na = create_mock_df(10, 20, 11, 19)
    df_with_na.loc[df_with_na.index[-1], "sma_short"] = pd.NA
    mock_data_processor_for_se.get_indicator_dataframe.return_value = df_with_na
    signal = await signal_engine_v1.check_signal("BTCUSDT", "BTC_USDT")
    assert signal is None

    # Test with NA in latest SMA long
    df_with_na = create_mock_df(10, 20, 11, 19)
    df_with_na.loc[df_with_na.index[-1], "sma_long"] = pd.NA
    mock_data_processor_for_se.get_indicator_dataframe.return_value = df_with_na
    signal = await signal_engine_v1.check_signal("BTCUSDT", "BTC_USDT")
    assert signal is None

    # Test with NA in previous SMA short
    df_with_na = create_mock_df(10, 20, 11, 19)
    df_with_na.loc[df_with_na.index[-2], "sma_short"] = pd.NA
    mock_data_processor_for_se.get_indicator_dataframe.return_value = df_with_na
    signal = await signal_engine_v1.check_signal("BTCUSDT", "BTC_USDT")
    assert signal is None

    # Test with NA in previous SMA long
    df_with_na = create_mock_df(10, 20, 11, 19)
    df_with_na.loc[df_with_na.index[-2], "sma_long"] = pd.NA
    mock_data_processor_for_se.get_indicator_dataframe.return_value = df_with_na
    signal = await signal_engine_v1.check_signal("BTCUSDT", "BTC_USDT")
    assert signal is None

@pytest.mark.asyncio
async def test_se_no_signal_if_no_crossover(signal_engine_v1, mock_data_processor_for_se):
    # Test when short > long, and still short > long (no crossover)
    mock_df = create_mock_df(sma_short_prev=101, sma_long_prev=100, sma_short_curr=102, sma_long_curr=99)
    mock_data_processor_for_se.get_indicator_dataframe.return_value = mock_df
    signal = await signal_engine_v1.check_signal("ETHUSDT", "ETH_USDT")
    assert signal is None

    # Test when short < long, and still short < long (no crossover)
    mock_df = create_mock_df(sma_short_prev=99, sma_long_prev=100, sma_short_curr=98, sma_long_curr=101)
    mock_data_processor_for_se.get_indicator_dataframe.return_value = mock_df
    signal = await signal_engine_v1.check_signal("ETHUSDT", "ETH_USDT")
    assert signal is None

    # Test when short = long, and still short = long (no crossover)
    mock_df = create_mock_df(sma_short_prev=100, sma_long_prev=100, sma_short_curr=100, sma_long_curr=100)
    mock_data_processor_for_se.get_indicator_dataframe.return_value = mock_df
    signal = await signal_engine_v1.check_signal("ETHUSDT", "ETH_USDT")
    assert signal is None

@pytest.mark.asyncio
async def test_se_long_signal_sma_crossover(signal_engine_v1, mock_data_processor_for_se):
    # prev: short <= long, curr: short > long
    mock_df = create_mock_df(sma_short_prev=99, sma_long_prev=100, sma_short_curr=101, sma_long_curr=100, close_curr=100.5, low_lookback=[90,88,89])
    mock_data_processor_for_se.get_indicator_dataframe.return_value = mock_df
    
    signal = await signal_engine_v1.check_signal("ETHUSDT", "ETH_USDT")  # ETH_USDT has min_interval 0
    assert signal is not None
    assert signal.direction == TradeDirection.LONG
    assert signal.symbol == "ETHUSDT"
    assert signal.config_symbol == "ETH_USDT"
    assert signal.contract_type == "USDT_M"
    assert signal.entry_price == 100.5  # latest close
    assert signal.stop_loss_price == 88  # min of low_lookback
    # Risk = 100.5 - 88 = 12.5. TP = 100.5 + (12.5 * 2.0) = 100.5 + 25 = 125.5
    assert signal.take_profit_price == 125.5
    assert signal.strategy_name == "V1_SMA_Crossover"
    assert signal.signal_kline is not None
    assert signal.signal_kline.close == 100.5
    assert signal.signal_kline.timestamp == mock_df.index[-1]
    assert signal.details is not None
    assert signal.details["sma_short_at_signal"] == 101
    assert signal.details["sma_long_at_signal"] == 100
    assert signal.details["sma_short_previous"] == 99
    assert signal.details["sma_long_previous"] == 100
    assert signal.details["pivot_used_for_sl"] == 88

@pytest.mark.asyncio
async def test_se_short_signal_sma_crossover(signal_engine_v1, mock_data_processor_for_se):
    # prev: short >= long, curr: short < long
    mock_df = create_mock_df(sma_short_prev=101, sma_long_prev=100, sma_short_curr=99, sma_long_curr=100, close_curr=99.5, high_lookback=[110,112,111])
    mock_data_processor_for_se.get_indicator_dataframe.return_value = mock_df

    signal = await signal_engine_v1.check_signal("ETHUSDT", "ETH_USDT")
    assert signal is not None
    assert signal.direction == TradeDirection.SHORT
    assert signal.symbol == "ETHUSDT"
    assert signal.config_symbol == "ETH_USDT"
    assert signal.entry_price == 99.5
    assert signal.stop_loss_price == 112  # max of high_lookback
    # Risk = 112 - 99.5 = 12.5. TP = 99.5 - (12.5 * 2.0) = 99.5 - 25 = 74.5
    assert signal.take_profit_price == 74.5
    assert signal.signal_kline is not None
    assert signal.signal_kline.close == 99.5
    assert signal.details is not None
    assert signal.details["sma_short_at_signal"] == 99
    assert signal.details["sma_long_at_signal"] == 100
    assert signal.details["sma_short_previous"] == 101
    assert signal.details["sma_long_previous"] == 100
    assert signal.details["pivot_used_for_sl"] == 112

# 2. Test SL/TP Calculation
@pytest.mark.asyncio
async def test_se_sl_tp_calculation_long(signal_engine_v1, mock_data_processor_for_se):
    # Test a more complex case with specific pivot lows
    low_lookback = [90, 88, 89, 85, 87]  # The pivot low should be 85
    mock_df = create_mock_df(
        sma_short_prev=99, sma_long_prev=100, 
        sma_short_curr=101, sma_long_curr=100, 
        close_curr=100.5, 
        low_lookback=low_lookback
    )
    mock_data_processor_for_se.get_indicator_dataframe.return_value = mock_df
    
    signal = await signal_engine_v1.check_signal("ETHUSDT", "ETH_USDT")
    assert signal is not None
    assert signal.direction == TradeDirection.LONG
    assert signal.stop_loss_price == 85  # min of low_lookback
    # Risk = 100.5 - 85 = 15.5. TP = 100.5 + (15.5 * 2.0) = 100.5 + 31 = 131.5
    assert signal.take_profit_price == 131.5

@pytest.mark.asyncio
async def test_se_sl_tp_calculation_short(signal_engine_v1, mock_data_processor_for_se):
    # Test a more complex case with specific pivot highs
    high_lookback = [110, 112, 115, 111, 113]  # The pivot high should be 115
    mock_df = create_mock_df(
        sma_short_prev=101, sma_long_prev=100, 
        sma_short_curr=99, sma_long_curr=100, 
        close_curr=99.5, 
        high_lookback=high_lookback
    )
    mock_data_processor_for_se.get_indicator_dataframe.return_value = mock_df
    
    signal = await signal_engine_v1.check_signal("ETHUSDT", "ETH_USDT")
    assert signal is not None
    assert signal.direction == TradeDirection.SHORT
    assert signal.stop_loss_price == 115  # max of high_lookback
    # Risk = 115 - 99.5 = 15.5. TP = 99.5 - (15.5 * 2.0) = 99.5 - 31 = 68.5
    assert signal.take_profit_price == 68.5

@pytest.mark.asyncio
async def test_se_custom_tp_sl_ratio(signal_engine_v1, mock_data_processor_for_se):
    # Test TP calculation with a custom R:R ratio for SOL_USDT (3.5)
    mock_df = create_mock_df(
        sma_short_prev=99, sma_long_prev=100, 
        sma_short_curr=101, sma_long_curr=100, 
        close_curr=100.5, 
        low_lookback=[90, 88, 89]
    )
    mock_data_processor_for_se.get_indicator_dataframe.return_value = mock_df
    
    signal = await signal_engine_v1.check_signal("SOLUSDT", "SOL_USDT")
    assert signal is not None
    assert signal.direction == TradeDirection.LONG
    assert signal.stop_loss_price == 88
    # Risk = 100.5 - 88 = 12.5. TP = 100.5 + (12.5 * 3.5) = 100.5 + 43.75 = 144.25
    assert signal.take_profit_price == 144.25

@pytest.mark.asyncio
async def test_se_no_signal_if_insufficient_pivot_data(signal_engine_v1, mock_data_processor_for_se):
    # Create a DataFrame that's too small for proper pivot calculation (< 3 rows)
    small_df = create_limited_df(rows=2)
    mock_data_processor_for_se.get_indicator_dataframe.return_value = small_df
    
    signal = await signal_engine_v1.check_signal("ETHUSDT", "ETH_USDT")
    assert signal is None

@pytest.mark.asyncio
async def test_se_sl_tp_calculation_invalid_risk(signal_engine_v1, mock_data_processor_for_se):
    # SL is worse than entry for LONG (pivot low > entry price)
    mock_df_bad_sl_long = create_mock_df(
        sma_short_prev=99, sma_long_prev=100, 
        sma_short_curr=101, sma_long_curr=100, 
        close_curr=90, 
        low_lookback=[95, 96, 97]  # min low is 95, which is > entry price 90
    )
    mock_data_processor_for_se.get_indicator_dataframe.return_value = mock_df_bad_sl_long
    signal = await signal_engine_v1.check_signal("ETHUSDT", "ETH_USDT")
    assert signal is None

    # SL is worse than entry for SHORT (pivot high < entry price)
    mock_df_bad_sl_short = create_mock_df(
        sma_short_prev=101, sma_long_prev=100, 
        sma_short_curr=99, sma_long_curr=100, 
        close_curr=110, 
        high_lookback=[105, 106, 104]  # max high is 106, which is < entry price 110
    )
    mock_data_processor_for_se.get_indicator_dataframe.return_value = mock_df_bad_sl_short
    signal = await signal_engine_v1.check_signal("ETHUSDT", "ETH_USDT")
    assert signal is None

@pytest.mark.asyncio
async def test_se_long_signal_signal_kline_content(signal_engine_v1, mock_data_processor_for_se):
    # Test that signal_kline contains the correct data from the last DataFrame row
    mock_df = create_mock_df(
        sma_short_prev=99, sma_long_prev=100, 
        sma_short_curr=101, sma_long_curr=100, 
        close_curr=100.5
    )
    mock_data_processor_for_se.get_indicator_dataframe.return_value = mock_df
    
    signal = await signal_engine_v1.check_signal("ETHUSDT", "ETH_USDT")
    assert signal is not None
    assert signal.signal_kline is not None
    assert signal.signal_kline.timestamp == mock_df.index[-1]
    assert signal.signal_kline.open == mock_df.iloc[-1]["open"]
    assert signal.signal_kline.high == mock_df.iloc[-1]["high"]
    assert signal.signal_kline.low == mock_df.iloc[-1]["low"]
    assert signal.signal_kline.close == mock_df.iloc[-1]["close"]
    assert signal.signal_kline.volume == mock_df.iloc[-1]["volume"]
    assert signal.signal_kline.is_closed == mock_df.iloc[-1]["is_closed"]
    assert signal.signal_kline.symbol == "ETHUSDT"
    assert signal.signal_kline.interval == "1m"  # The default interval used by SignalEngineV1

# 3. Test Filters
@pytest.mark.asyncio
async def test_se_signal_interval_filter(signal_engine_v1, mock_data_processor_for_se):
    # BTC_USDT has min_interval_minutes = 15
    mock_df = create_mock_df(
        sma_short_prev=99, sma_long_prev=100, 
        sma_short_curr=101, sma_long_curr=100, 
        close_curr=100.5
    )
    mock_data_processor_for_se.get_indicator_dataframe.return_value = mock_df

    # First signal should pass
    signal1 = await signal_engine_v1.check_signal("BTCUSDT", "BTC_USDT")
    assert signal1 is not None
    assert signal_engine_v1.last_signal_time["BTCUSDT"] > 0

    # Second signal immediately after should be filtered
    signal2 = await signal_engine_v1.check_signal("BTCUSDT", "BTC_USDT")
    assert signal2 is None

    # Simulate time passing (less than interval)
    signal_engine_v1.last_signal_time["BTCUSDT"] = time.time() - (10 * 60)  # 10 minutes ago
    signal3 = await signal_engine_v1.check_signal("BTCUSDT", "BTC_USDT")
    assert signal3 is None 

    # Simulate time passing (more than interval)
    signal_engine_v1.last_signal_time["BTCUSDT"] = time.time() - (20 * 60)  # 20 minutes ago
    signal4 = await signal_engine_v1.check_signal("BTCUSDT", "BTC_USDT")
    assert signal4 is not None

@pytest.mark.asyncio
async def test_se_signal_interval_is_pair_specific(signal_engine_v1, mock_data_processor_for_se):
    # Setup: BTC_USDT has interval=15, ETH_USDT has interval=0
    mock_df = create_mock_df(
        sma_short_prev=99, sma_long_prev=100, 
        sma_short_curr=101, sma_long_curr=100, 
        close_curr=100.5
    )
    mock_data_processor_for_se.get_indicator_dataframe.return_value = mock_df
    
    # Generate signals for both pairs
    btc_signal = await signal_engine_v1.check_signal("BTCUSDT", "BTC_USDT")
    eth_signal = await signal_engine_v1.check_signal("ETHUSDT", "ETH_USDT")
    
    # Both should work the first time
    assert btc_signal is not None
    assert eth_signal is not None
    
    # Try immediate second signals
    btc_signal2 = await signal_engine_v1.check_signal("BTCUSDT", "BTC_USDT")
    eth_signal2 = await signal_engine_v1.check_signal("ETHUSDT", "ETH_USDT")
    
    # BTC should be filtered, ETH should still generate (interval=0)
    assert btc_signal2 is None
    assert eth_signal2 is not None

# 4. Test Helper Methods
@pytest.mark.asyncio
async def test_se_get_pair_specific_config(signal_engine_v1):
    # Test getting config for BTC_USDT (uses global values)
    btc_config = signal_engine_v1._get_pair_specific_config("BTC_USDT")
    assert btc_config["sma_short_period"] == 3
    assert btc_config["sma_long_period"] == 5
    assert btc_config["min_signal_interval_minutes"] == 15
    assert btc_config["tp_sl_ratio"] == 2.0
    assert btc_config["contract_type"] == "USDT_M"
    
    # Test getting config for ETH_USDT (has custom min_signal_interval_minutes)
    eth_config = signal_engine_v1._get_pair_specific_config("ETH_USDT")
    assert eth_config["sma_short_period"] == 3
    assert eth_config["sma_long_period"] == 5
    assert eth_config["min_signal_interval_minutes"] == 0  # Overridden
    assert eth_config["tp_sl_ratio"] == 2.0
    assert eth_config["contract_type"] == "USDT_M"
    
    # Test getting config for SOL_USDT (has custom tp_sl_ratio)
    sol_config = signal_engine_v1._get_pair_specific_config("SOL_USDT")
    assert sol_config["sma_short_period"] == 3
    assert sol_config["sma_long_period"] == 5
    assert sol_config["min_signal_interval_minutes"] == 15
    assert sol_config["tp_sl_ratio"] == 3.5  # Overridden
    assert sol_config["contract_type"] == "USDT_M"
    
    # Test getting config for unknown pair (should use global values)
    unknown_config = signal_engine_v1._get_pair_specific_config("XRP_USDT")
    assert unknown_config["sma_short_period"] == 3
    assert unknown_config["sma_long_period"] == 5
    assert unknown_config["min_signal_interval_minutes"] == 15
    assert unknown_config["tp_sl_ratio"] == 2.0
    assert unknown_config["contract_type"] == "USDT_M"

@pytest.mark.asyncio
async def test_se_find_recent_pivot_logic(signal_engine_v1):
    # Test _find_recent_pivot directly (it's a protected method, but crucial)
    data = {
        "timestamp": range(10), 
        "low": [10, 8, 9, 7, 10, 6, 8, 9, 7, 11],
        "high": [20, 22, 21, 23, 20, 24, 22, 21, 23, 19],
        "is_closed": [True]*10
    }
    df = pd.DataFrame(data).set_index("timestamp")
    
    # Test for LONG direction with different lookbacks
    # For lookback=5, it should look at indices 4,5,6,7,8 (lows: 10, 6, 8, 9, 7). Min is 6.
    pivot_l_5 = signal_engine_v1._find_recent_pivot(df, lookback=5, direction=TradeDirection.LONG)
    assert pivot_l_5 == 6
    
    # For lookback=3, it should look at indices 6,7,8 (lows: 8, 9, 7). Min is 7.
    pivot_l_3 = signal_engine_v1._find_recent_pivot(df, lookback=3, direction=TradeDirection.LONG)
    assert pivot_l_3 == 7
    
    # Test for SHORT direction with different lookbacks
    # For lookback=5, it should look at indices 4,5,6,7,8 (highs: 20, 24, 22, 21, 23). Max is 24.
    pivot_h_5 = signal_engine_v1._find_recent_pivot(df, lookback=5, direction=TradeDirection.SHORT)
    assert pivot_h_5 == 24
    
    # For lookback=3, it should look at indices 6,7,8 (highs: 22, 21, 23). Max is 23.
    pivot_h_3 = signal_engine_v1._find_recent_pivot(df, lookback=3, direction=TradeDirection.SHORT)
    assert pivot_h_3 == 23
    
    # Test with insufficient data
    assert signal_engine_v1._find_recent_pivot(df[:2], lookback=5, direction=TradeDirection.LONG) is None
    
    # Test with exactly 3 rows (minimum required)
    three_row_df = df[:3]
    pivot_l_min = signal_engine_v1._find_recent_pivot(three_row_df, lookback=5, direction=TradeDirection.LONG)
    assert pivot_l_min == 8  # Min of [10, 8]
    
    # Test with flat values
    flat_data = {
        "timestamp": range(5),
        "low": [10, 10, 10, 10, 10],
        "high": [20, 20, 20, 20, 20],
        "is_closed": [True]*5
    }
    flat_df = pd.DataFrame(flat_data).set_index("timestamp")
    pivot_l_flat = signal_engine_v1._find_recent_pivot(flat_df, lookback=3, direction=TradeDirection.LONG)
    assert pivot_l_flat == 10
    pivot_h_flat = signal_engine_v1._find_recent_pivot(flat_df, lookback=3, direction=TradeDirection.SHORT)
    assert pivot_h_flat == 20




================================================
FILE: .cursor/rules/projectrules.mdc
================================================
---
description: 
globs: 
alwaysApply: true
---
---
title: Binance Futures Trading Bot Rules
description: Guidelines for AI assistance with this trading bot project
---

# Project Overview
This is a Binance Futures Trading Bot that implements automated trading strategies for cryptocurrency futures markets. The bot connects to Binance API (both USDT-M and Coin-M perpetual futures), processes market data, generates trading signals based on technical indicators, and executes trades according to predefined risk management rules.

# Code Style
- Use Python 3.11+ compatible code
- Follow PEP 8 style guidelines
- Use type hints for all function parameters and return values
- Prefer async/await patterns for I/O operations
- Use descriptive variable and function names
- Add docstrings to all classes and public methods

# Architecture Guidelines
- Maintain clear separation between components (connectors, data processing, signal generation, order management)
- Use dependency injection for better testability
- Implement proper error handling and logging
- Ensure all external API calls have appropriate error handling and retry mechanisms
- Use configuration files for all adjustable parameters

# Trading Strategy Implementation
- The primary V1 strategy uses SMA 21 crossing SMA 200 on various timeframes
- Stop loss should be based on recent pivot points
- Take profit should be calculated using risk-reward ratio from config
- Implement buffer periods to avoid false signals
- Support both USDT-M and Coin-M contract types

# Security Considerations
- Never hardcode API keys or secrets
- Use environment variables or secure config files
- Implement proper error handling for API responses
- Validate all user inputs and configuration parameters
- Log sensitive operations but never log credentials

# Testing Requirements
- Write unit tests for all core components
- Mock external API calls in tests
- Include integration tests for critical workflows
- Test error handling and edge cases

# Documentation Standards
- Maintain comprehensive README with setup and usage instructions
- Document all configuration options
- Include architecture diagrams where helpful
- Provide troubleshooting guides for common issues

# Performance Considerations
- Optimize memory usage for long-running processes
- Implement connection pooling for API requests
- Use efficient data structures for time series data
- Consider resource usage when processing large datasets





================================================
FILE: docs/ARCHITECTURE.md
================================================
# Architecture Overview

This document provides an overview of the system architecture for the Binance Futures Trading Bot. The bot is designed with a modular approach to ensure separation of concerns, testability, and extensibility.

## Core Principles

- **Modularity**: Each major function (data ingestion, signal generation, order execution, etc.) is handled by a distinct module.
- **Asynchronous Operations**: Leverages `asyncio` for efficient handling of I/O-bound tasks like network requests and WebSocket communication.
- **Configurability**: Most operational parameters are externalized to a YAML configuration file, supporting hot-reloading.
- **Event-Driven**: The bot primarily reacts to real-time market events (k-line updates) and internal signals.
- **Testability**: Modules are designed to be unit-testable, with dependencies injectable or mockable.

## System Components

The following diagram illustrates the high-level interaction between the core components:

```mermaid
graph TD
    subgraph User_Interaction
        ConfigFile[config.yaml]
    end

    subgraph Bot_Core_Application
        MainApp[Main Application (main.py)]
        ConfigMgr[ConfigManager (config_loader.py)]
        Scheduler[Async Event Loop]
    end

    subgraph Data_Pipeline
        BinanceWS[Binance WebSocket API]
        WSConnector[WebSocketConnector (connectors.py)]
        DataProcessor[DataProcessor (data_processor.py)]
    end

    subgraph Trading_Logic
        SignalEngine[SignalEngineV1 (signal_engine.py)]
        OrderManager[OrderManager (order_manager.py)]
        PositionManager[PositionManager (position_manager.py)]
    end

    subgraph External_Services
        BinanceREST[Binance REST API]
        RESTClient[RESTClient (connectors.py)]
    end

    subgraph Monitoring_System
        Prometheus[Prometheus Server]
        Metrics[PrometheusMonitor (monitoring.py)]
    end

    ConfigFile --> ConfigMgr
    ConfigMgr --> MainApp
    ConfigMgr --> WSConnector
    ConfigMgr --> DataProcessor
    ConfigMgr --> SignalEngine
    ConfigMgr --> OrderManager
    ConfigMgr --> PositionManager
    ConfigMgr --> RESTClient
    ConfigMgr --> Metrics

    MainApp -- Manages/Orchestrates --> WSConnector
    MainApp -- Manages/Orchestrates --> DataProcessor
    MainApp -- Manages/Orchestrates --> SignalEngine
    MainApp -- Manages/Orchestrates --> OrderManager
    MainApp -- Manages/Orchestrates --> PositionManager
    MainApp -- Manages/Orchestrates --> RESTClient
    MainApp -- Manages/Orchestrates --> Metrics
    MainApp -- Uses --> Scheduler

    BinanceWS -- Streams Data --> WSConnector
    WSConnector -- Raw Kline Data --> MainApp
    MainApp -- Kline Data --> DataProcessor
    DataProcessor -- Indicator Data --> SignalEngine
    SignalEngine -- Trade Signals --> MainApp
    MainApp -- Trade Signals --> OrderManager
    
    OrderManager -- Executes Orders via --> RESTClient
    RESTClient -- Interacts with --> BinanceREST
    PositionManager -- Tracks Positions --> MainApp # Position updates can come from OrderManager or UserDataStream
    OrderManager -- Updates --> PositionManager # After successful order execution

    Metrics -- Exposes Data to --> Prometheus
```

### 1. Main Application (`src/main.py`)
- **Responsibilities**: 
    - Initializes and orchestrates all other modules.
    - Manages the main asynchronous event loop.
    - Handles startup, graceful shutdown, and signal handling (SIGINT, SIGTERM).
    - Routes data between components (e.g., k-line data from WebSocket connector to Data Processor, signals from Signal Engine to Order Manager).
    - Responds to configuration changes detected by the `ConfigManager`.

### 2. Configuration Manager (`src/config_loader.py`)
- **Responsibilities**:
    - Loads trading parameters, API keys, and other settings from `config/config.yaml`.
    - Provides access to configuration values for all other modules.
    - Implements hot-reloading: monitors the configuration file for changes and notifies registered callbacks in other modules to apply updates dynamically.
    - Handles creation of default `config.yaml` from `config.yaml.example` if it doesn_t exist.

### 3. Connectors (`src/connectors.py`)
   Contains modules for interacting with Binance APIs.
   - **`BinanceWebSocketConnector`**:
     - Establishes and maintains WebSocket connections to Binance Futures for real-time market data (k-lines, potentially order book depth, user data streams in future).
     - Subscribes to streams for configured trading pairs and timeframes.
     - Parses incoming JSON messages into structured `Kline` objects (defined in `src/models.py`).
     - Passes `Kline` data to the Main Application via a callback for further processing.
     - Handles connection management, automatic reconnections, and subscription updates on configuration changes.
   - **`BinanceRESTClient`**:
     - Interacts with the Binance Futures REST API for actions like placing orders, fetching account balance, getting open positions, setting leverage/margin mode, and retrieving exchange information (symbol precision, limits).
     - Uses the `ccxt` library for standardized API interaction.
     - Manages API authentication (API key and secret).
     - Implements retry logic for transient API errors (using `tenacity`).
     - Provides a simulation mode if API keys are not configured or are placeholders, allowing basic testing without live trading.

### 4. Data Models (`src/models.py`)
- **Responsibilities**:
    - Defines Pydantic data models for structured representation of various entities used throughout the application. This ensures data consistency and provides validation.
    - Key models include:
        - `Kline`: Represents a single k-line/candlestick data point.
        - `PairConfig`: Represents configuration for a specific trading pair.
        - `TradeSignal`: Represents a trading signal generated by the strategy engine.
        - `Order`: Represents a trading order (entry, SL, TP).
        - `Position`: Represents an open trading position.
        - Enums for `TradeDirection`, `OrderStatus`, `OrderType`, `OrderSide`, etc.

### 5. Data Processor (`src/data_processor.py`)
- **Responsibilities**:
    - Receives raw `Kline` objects from the Main Application (originating from the `WebSocketConnector`).
    - Maintains rolling buffers (e.g., `collections.deque` of `Kline` objects) for each active trading pair and timeframe.
    - Calculates technical indicators (e.g., SMAs for V1 strategy) based on the k-line data in the buffers.
    - Stores calculated indicators, typically in a Pandas DataFrame associated with each pair/timeframe buffer for easy access and analysis.
    - Provides methods for other modules (like `SignalEngine`) to retrieve the latest k-line data and calculated indicators.
    - Updates its internal state and buffers based on configuration changes (e.g., new pairs enabled, indicator timeframes changed).

### 6. Signal Engine (`src/signal_engine.py`)
- **Responsibilities**:
    - Implements the trading strategy logic (e.g., V1 SMA Crossover).
    - Uses data provided by the `DataProcessor` (k-lines and indicators) to identify potential trading opportunities.
    - When a trading condition is met (e.g., SMA crossover), it generates a `TradeSignal` object.
    - Includes logic for signal filtering, such as minimum interval between signals for the same pair, and buffer time for crossover confirmation.
    - Calculates initial stop-loss (SL) and take-profit (TP) levels for the generated signal based on strategy rules (e.g., recent pivot lows/highs for SL, fixed R:R ratio for TP).
    - Passes the `TradeSignal` to the Main Application for execution.

### 7. Order Manager (`src/order_manager.py`)
- **Responsibilities**:
    - Receives `TradeSignal` objects from the Main Application.
    - Determines position size based on configured margin (fixed USDT amount for USDT-M, fixed coin amount for COIN-M in MVP) and leverage.
    - Fetches symbol-specific trading rules (precision for price/quantity, minimum notional value) from `BinanceRESTClient` to ensure orders are valid.
    - Constructs and places market entry orders, and associated stop-market SL and take-profit-market TP orders (with `reduceOnly=true`) via the `BinanceRESTClient`.
    - Sets margin type (ISOLATED/CROSSED) and leverage for the pair before placing trades if necessary.
    - Handles specifics for USDT-M and COIN-M contracts.
    - Logs order placement details and outcomes.
    - (Future Enhancement) Could interact with `PositionManager` to update position state after orders are confirmed.

### 8. Position Manager (`src/position_manager.py`)
- **Responsibilities**:
    - Tracks currently open trading positions managed by the bot.
    - Stores details for each position: symbol, side (LONG/SHORT), entry price, quantity, entry/SL/TP order IDs, unrealized PnL, etc.
    - Updates position status based on order fill events (e.g., entry filled, SL/TP hit, manual close). This is crucial and would typically be driven by a user data WebSocket stream or polling order statuses.
    - Provides methods to query current open positions.
    - (Future Enhancement) Handles reconciliation of positions with the exchange on startup or periodically.
    - (Future Enhancement) Manages trailing stops or other dynamic exit strategies.

### 9. Monitoring (`src/monitoring.py`)
- **Responsibilities**:
    - Implements a Prometheus metrics exporter.
    - Exposes key operational metrics such as:
        - Bot uptime, error counts.
        - WebSocket connection status, messages received.
        - K-lines processed, indicator calculation times.
        - Signals generated, orders placed/filled/failed.
        - Active position counts, PnL (if available).
    - Starts an HTTP server on a configurable port to serve the `/metrics` endpoint for Prometheus to scrape.

## Data Flow Example (V1 SMA Crossover Strategy)

1. **Configuration**: `ConfigManager` loads `config.yaml`.
2. **Initialization**: `MainApp` initializes all components using the loaded configuration.
3. **WebSocket Connection**: `WebSocketConnector` connects to Binance and subscribes to k-line streams for enabled pairs (e.g., BTCUSDT 1m, 5m, etc.).
4. **Kline Reception**: `WebSocketConnector` receives a k-line update, parses it into a `Kline` object, and passes it to `MainApp`.
5. **Data Processing**: `MainApp` forwards the `Kline` to `DataProcessor`.
   - `DataProcessor` appends the k-line to the relevant buffer (e.g., BTCUSDT, 1m).
   - It then recalculates indicators (e.g., 21 SMA, 200 SMA) for that buffer and updates its internal DataFrame.
6. **Signal Check**: If the k-line is closed (for 1m timeframe as per V1 strategy):
   - `MainApp` (or a callback mechanism) triggers `SignalEngineV1` to check for signals on BTCUSDT.
   - `SignalEngineV1` requests the latest indicator DataFrame for BTCUSDT 1m from `DataProcessor`.
   - It checks for SMA crossover conditions (e.g., 21 SMA crosses above 200 SMA).
   - If a crossover is confirmed (and passes filters like `min_signal_interval_minutes` and `buffer_time_candles`):
     - It calculates SL (e.g., recent low) and TP (e.g., entry + (entry-SL) * R:R).
     - It creates a `TradeSignal` object (e.g., LONG BTCUSDT).
     - It returns the `TradeSignal` to `MainApp`.
7. **Order Execution**: `MainApp` receives the `TradeSignal` and passes it to `OrderManager`.
   - `OrderManager` determines position size (e.g., 100 USDT margin, 10x leverage for BTCUSDT).
   - It fetches BTCUSDT trading rules (precision, min notional) from `RESTClient` (cached if possible).
   - It adjusts quantity and prices to meet precision requirements.
   - It calls `RESTClient` to:
     - Set leverage and margin mode for BTCUSDT (if not already set or changed).
     - Place a MARKET BUY order (entry).
     - Place a STOP_MARKET SELL order (SL) with `reduceOnly=true`.
     - Place a TAKE_PROFIT_MARKET SELL order (TP) with `reduceOnly=true`.
8. **Position Tracking**: 
   - `OrderManager` (or `MainApp` upon order confirmation) informs `PositionManager` about the new potential position, including the order IDs for entry, SL, and TP.
   - `PositionManager` creates a new `Position` entry.
   - (Ideally, a User Data Stream via `WebSocketConnector` would provide real-time order fill updates, which would then be routed to `PositionManager` to confirm the position is active or closed).
9. **Monitoring**: Throughout this process, modules update metrics via `PrometheusMonitor` (e.g., k-lines processed, signals generated, orders placed).

## Future Enhancements Considerations

- **User Data Stream**: Integrate a user data WebSocket stream for real-time updates on order fills, account balance changes, and position updates. This would make position management more robust and reactive.
- **Database Integration**: For persistent storage of trades, historical performance, and potentially k-line data for backtesting.
- **Advanced Strategies**: The modular design allows for new strategy engines to be developed and plugged in.
- **Web UI/Dashboard**: A user interface for monitoring the bot, managing settings, and viewing performance.
- **Backtesting Engine**: To test strategies on historical data before live deployment.

This architecture provides a solid foundation for a reliable and extensible trading bot.



================================================
FILE: docs/CONFIGURATION_GUIDE.md
================================================
# Configuration Guide

This document provides a detailed explanation of all options available in the `config/config.yaml` file for the Binance Futures Trading Bot.

## Root Level Configuration

```yaml
api:
  # ... see API section
global_settings:
  # ... see Global Settings section
pairs:
  # ... see Pairs section
logging:
  # ... see Logging section
monitoring:
  # ... see Monitoring section
```

## 1. API Configuration (`api`)

This section contains your Binance API credentials.

```yaml
api:
  binance_api_key: "YOUR_BINANCE_API_KEY"    # Your Binance API Key
  binance_api_secret: "YOUR_BINANCE_API_SECRET" # Your Binance API Secret
  # testnet: false # Optional: Set to true to use Binance Testnet. Default is false (mainnet).
```

- **`binance_api_key`**: (Required) Your public API key from Binance. Ensure API restrictions are set appropriately (e.g., enable Futures trading, disable withdrawals if not needed by other tools).
- **`binance_api_secret`**: (Required) Your secret API key from Binance. Keep this confidential.
- **`testnet`**: (Optional) Boolean. If set to `true`, the bot will connect to the Binance Futures Testnet. If `false` or omitted, it connects to the mainnet. It is highly recommended to test thoroughly on testnet before trading with real funds.

## 2. Global Settings (`global_settings`)

These settings apply to all trading pairs unless overridden in the specific pair's configuration.

```yaml
global_settings:
  v1_strategy: # Settings specific to the V1 SMA Crossover strategy
    sma_short_period: 21
    sma_long_period: 200
    min_signal_interval_minutes: 60
    tp_sl_ratio: 2.0
    default_margin_usdt: 50.0
    default_leverage: 10
    margin_mode: "ISOLATED" # or "CROSSED"
    indicator_timeframes: ["1m", "5m", "15m", "1h", "4h"]
    # buffer_time_candles: 3 # Optional: Number of candles for buffer time after crossover
    # pivot_lookback_candles: 30 # Optional: Lookback period for SL pivot calculation

  risk_management:
    # dynamic_sizing_enabled: false # Optional: Enable dynamic position sizing (e.g., % of balance)
    # max_account_risk_per_trade_pct: 1.0 # Optional: If dynamic sizing, max % of account to risk
    # max_concurrent_trades: 5 # Optional: Limit on total concurrent open positions
```

### 2.1. V1 Strategy (`v1_strategy`)

Parameters for the default SMA (Simple Moving Average) crossover strategy.

- **`sma_short_period`**: Integer. The period for the shorter SMA (e.g., 21).
- **`sma_long_period`**: Integer. The period for the longer SMA (e.g., 200).
- **`min_signal_interval_minutes`**: Integer. Minimum time in minutes to wait between generating new signals for the *same trading pair* to avoid over-trading. Set to `0` to disable this wait.
- **`tp_sl_ratio`**: Float. The Take Profit to Stop Loss ratio (Risk/Reward Ratio). For example, `2.0` means the Take Profit distance will be twice the Stop Loss distance from the entry price.
- **`default_margin_usdt`**: Float. For USDT-M pairs, the default amount of USDT to allocate as margin for a new trade if not specified per pair. This is used for fixed margin position sizing.
- **`default_leverage`**: Integer. The default leverage to use for new trades if not specified per pair (e.g., 10 for 10x leverage).
- **`margin_mode`**: String. The margin mode to use: `"ISOLATED"` or `"CROSSED"`. It is generally recommended to use `"ISOLATED"` for better risk control per position.
- **`indicator_timeframes`**: List of strings. The k-line timeframes the bot should subscribe to and use for calculating indicators for each pair. Examples: `["1m", "5m", "15m", "1h", "4h"]`. The V1 strategy primarily uses the `1m` timeframe for signal generation based on the provided documents, but other timeframes are fetched for potential future strategy enhancements or multi-timeframe analysis.
- **`buffer_time_candles`**: (Optional) Integer. Number of candles the crossover condition must persist before a signal is considered valid. This helps filter out false signals during choppy markets. (As per "Binance Futures Trading Bot Strategy Improvements (2).txt")
- **`pivot_lookback_candles`**: (Optional) Integer. The lookback period (number of candles) used to determine recent pivot highs/lows for stop-loss placement. (As per "Binance Futures Trading Bot Strategy Improvements (2).txt")

### 2.2. Risk Management (`risk_management`)

Global risk parameters (some are placeholders for future enhancements).

- **`dynamic_sizing_enabled`**: (Optional) Boolean. If `true`, enables dynamic position sizing (e.g., risking a fixed percentage of account balance per trade). If `false` (default), uses fixed margin allocation (`default_margin_usdt` or pair-specific `margin_usdt`). *MVP focuses on fixed margin.*
- **`max_account_risk_per_trade_pct`**: (Optional) Float. If `dynamic_sizing_enabled` is `true`, this is the maximum percentage of the total account balance to risk on a single trade (e.g., `1.0` for 1%).
- **`max_concurrent_trades`**: (Optional) Integer. The maximum number of trades the bot can have open simultaneously across all pairs.

## 3. Pairs Configuration (`pairs`)

This section defines the specific trading pairs the bot will monitor and trade. You can list multiple pairs.

```yaml
pairs:
  BTC_USDT: # User-defined name for the pair, used internally
    enabled: true
    contract_type: "USDT_M" # "USDT_M" or "COIN_M"
    leverage: 20 # Optional: Overrides global_settings.v1_strategy.default_leverage
    margin_usdt: 100.0 # Optional: For USDT_M, overrides global_settings.v1_strategy.default_margin_usdt
    # margin_coin: 0.01 # Optional: For COIN_M, amount of base coin for margin (e.g., 0.01 BTC for BTCUSD_PERP)
    # indicator_timeframes: ["1m", "15m"] # Optional: Overrides global_settings.v1_strategy.indicator_timeframes for this pair
    # min_signal_interval_minutes: 30 # Optional: Overrides global setting for this pair
    # tp_sl_ratio: 1.5 # Optional: Overrides global setting for this pair

  ETH_USDT:
    enabled: true
    contract_type: "USDT_M"
    # Uses global settings for leverage, margin_usdt, etc.

  BTCUSD_PERP: # Example for a COIN-M contract
    enabled: false # This pair is currently disabled
    contract_type: "COIN_M"
    leverage: 5
    margin_coin: 0.002 # e.g., 0.002 BTC for this contract
```

For each pair (e.g., `BTC_USDT`, `ETHUSD_PERP`): 
- The key (e.g., `BTC_USDT`) is a user-defined identifier. The bot will convert this to the format Binance API expects (e.g., `BTCUSDT` or `BTCUSD_PERP`).
  - For USDT-margined perpetuals, use the format `BASE_QUOTE` (e.g., `BTC_USDT`).
  - For COIN-margined perpetuals, use the format `BASEUSD_PERP` (e.g., `BTCUSD_PERP`).
- **`enabled`**: Boolean. If `true`, the bot will actively trade this pair. If `false`, it will be ignored.
- **`contract_type`**: String. Specifies the type of futures contract:
    - `"USDT_M"`: For USDT-margined contracts (e.g., BTC/USDT, ETH/USDT).
    - `"COIN_M"`: For COIN-margined contracts (e.g., BTC/USD, ETH/USD perpetuals).
- **`leverage`**: (Optional) Integer. Pair-specific leverage. Overrides `global_settings.v1_strategy.default_leverage`.
- **`margin_usdt`**: (Optional) Float. For `USDT_M` contracts, the amount of USDT to use as margin for trades on this specific pair. Overrides `global_settings.v1_strategy.default_margin_usdt`.
- **`margin_coin`**: (Optional) Float. For `COIN_M` contracts, the amount of the base coin (e.g., BTC for BTCUSD_PERP) to use as margin for trades on this specific pair. *Note: For COIN-M, position sizing is typically in terms of number of contracts. This `margin_coin` value might be interpreted as the number of contracts to trade for MVP if fixed sizing is used, or as the coin margin if the API supports that directly for sizing.*
- **`indicator_timeframes`**: (Optional) List of strings. Pair-specific k-line timeframes. Overrides `global_settings.v1_strategy.indicator_timeframes`.
- **`min_signal_interval_minutes`**: (Optional) Integer. Pair-specific minimum signal interval. Overrides `global_settings.v1_strategy.min_signal_interval_minutes`.
- **`tp_sl_ratio`**: (Optional) Float. Pair-specific Take Profit / Stop Loss ratio. Overrides `global_settings.v1_strategy.tp_sl_ratio`.

## 4. Logging Configuration (`logging`)

Controls how the bot logs information.

```yaml
logging:
  level: "INFO" # Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
  # file: "logs/bot.log" # Optional: Path to a log file. If omitted, logs to console only.
  # rotation_size_mb: 10 # Optional: Max size in MB before log file rotates.
  # rotation_backup_count: 5 # Optional: Number of backup log files to keep.
```

- **`level`**: String. The minimum logging level to output. Options (from least to most verbose): `CRITICAL`, `ERROR`, `WARNING`, `INFO`, `DEBUG`.
- **`file`**: (Optional) String. Path to the file where logs should be saved. If commented out or omitted, logs will only be printed to the console.
- **`rotation_size_mb`**: (Optional) Integer. If `file` is specified, this is the maximum size in megabytes a log file can reach before it is rotated (e.g., `bot.log` becomes `bot.log.1`).
- **`rotation_backup_count`**: (Optional) Integer. If `file` and `rotation_size_mb` are specified, this is the number of old log files to keep.

## 5. Monitoring Configuration (`monitoring`)

Settings for the Prometheus metrics exporter.

```yaml
monitoring:
  prometheus_port: 8000 # Port for the Prometheus metrics HTTP server
  # enabled: true # Optional: Set to false to disable Prometheus exporter. Defaults to true.
```

- **`prometheus_port`**: Integer. The TCP port on which the bot will expose Prometheus metrics. Default is `8000`.
- **`enabled`**: (Optional) Boolean. Set to `false` to disable the Prometheus metrics server. Defaults to `true` if the section exists.

## Hot Reloading

The bot monitors the `config/config.yaml` file for changes. Most settings (API keys excluded for security during runtime) can be updated live without restarting the bot. This includes:
- Logging levels
- Enabling/disabling pairs
- Leverage, margin settings for pairs
- Strategy parameters like `min_signal_interval_minutes`, `tp_sl_ratio`
- Indicator timeframes

When the file is saved, the bot will detect the changes and apply them. Check the bot's logs for confirmation of reloaded configurations.

---

*Always ensure your configuration is validated and tested on a testnet environment before deploying with real funds. Incorrect configurations can lead to unintended trading behavior and financial loss.*



================================================
FILE: docs/TROUBLESHOOTING.md
================================================
# Troubleshooting Guide

This document provides solutions for common issues you might encounter when running the Binance Futures Trading Bot.

## Connection Issues

### WebSocket Connection Failures

**Symptoms:**
- Repeated log messages about WebSocket connection failures
- Bot not receiving market data

**Possible Solutions:**
1. **Check Internet Connection**: Ensure your server has a stable internet connection.
2. **Verify API Endpoints**: Confirm Binance API endpoints are accessible from your location.
3. **Check Firewall Settings**: Make sure outbound WebSocket connections are allowed.
4. **Proxy Configuration**: If using a proxy, verify it's correctly configured.

```bash
# Test connectivity to Binance WebSocket endpoint
ping fstream.binance.com
```

### REST API Connection Issues

**Symptoms:**
- Error messages when placing orders
- Failed account balance retrieval

**Possible Solutions:**
1. **Verify API Keys**: Ensure your API keys are valid and have the correct permissions.
2. **Check IP Restrictions**: If you've set IP restrictions on your API keys, verify your server's IP is allowed.
3. **Rate Limits**: You might be hitting Binance's rate limits. Check logs for 429 errors and consider reducing request frequency.

## Configuration Issues

### Bot Not Trading Expected Pairs

**Symptoms:**
- Some configured pairs are not being traded
- No signals generated for certain pairs

**Possible Solutions:**
1. **Check Pair Configuration**: Ensure the pair is correctly formatted and `enabled: true` is set.
2. **Verify Symbol Existence**: Confirm the trading pair exists on Binance Futures.
3. **Check Logs**: Look for any error messages related to the specific pair.

### Strategy Parameters Not Taking Effect

**Symptoms:**
- Bot behavior doesn't match configured strategy parameters

**Possible Solutions:**
1. **Config Hot-Reload**: Verify the configuration was properly reloaded (check logs).
2. **Parameter Scope**: Some parameters might be pair-specific. Check if you've set them at the correct level.
3. **Restart Bot**: Some core parameters might require a bot restart to take effect.

## Trading Issues

### No Signals Generated

**Symptoms:**
- Bot is running but not generating any trade signals

**Possible Solutions:**
1. **Market Conditions**: The strategy conditions might not be met in current market conditions.
2. **Check Indicator Calculation**: Verify indicators are being calculated correctly.
3. **Signal Interval**: Check if `min_signal_interval_minutes` is set too high.
4. **Buffer Time**: If using buffer time, the crossover might need to persist for several candles.

### Orders Failing

**Symptoms:**
- Signals generated but orders not placed
- Error messages when placing orders

**Possible Solutions:**
1. **Insufficient Funds**: Ensure your account has sufficient balance.
2. **Leverage/Margin Settings**: Check if the configured leverage is allowed for the pair.
3. **Minimum Notional**: The calculated position size might be below the minimum notional value required by Binance.
4. **Symbol Precision**: Order quantities might not meet the symbol's precision requirements.

### Unexpected Position Sizes

**Symptoms:**
- Position sizes differ from what you expected based on configuration

**Possible Solutions:**
1. **Check Margin Settings**: Verify `margin_usdt` or `margin_coin` settings.
2. **Leverage Configuration**: Confirm the leverage setting is applied correctly.
3. **Price Impact**: For market orders, the execution price might differ from the signal price.

## Monitoring Issues

### Prometheus Metrics Not Available

**Symptoms:**
- Cannot access metrics at http://your-server:8000/metrics

**Possible Solutions:**
1. **Port Configuration**: Verify the `prometheus_port` setting.
2. **Firewall Settings**: Ensure the configured port is accessible.
3. **Metrics Enabled**: Check that monitoring is enabled in the configuration.

## Logging Issues

### Missing or Insufficient Logs

**Symptoms:**
- Not enough information in logs to diagnose issues

**Possible Solutions:**
1. **Log Level**: Set `logging.level` to "DEBUG" for more detailed logs.
2. **Log File Configuration**: Ensure the log file path is writable if using file logging.

## Performance Issues

### High CPU Usage

**Symptoms:**
- Bot process consuming excessive CPU resources

**Possible Solutions:**
1. **Too Many Pairs**: Reduce the number of active trading pairs.
2. **Timeframe Overload**: Limit the number of indicator timeframes being processed.
3. **Indicator Calculation**: Some indicators might be computationally expensive.

### Memory Leaks

**Symptoms:**
- Increasing memory usage over time

**Possible Solutions:**
1. **Buffer Size**: Check if k-line buffers are growing unbounded.
2. **Restart Periodically**: Consider implementing a scheduled restart.

## Testnet vs. Mainnet

### Testing on Testnet

Before trading with real funds, test thoroughly on Binance Futures Testnet:

1. Create a Testnet account at https://testnet.binancefuture.com/
2. Generate API keys for the Testnet
3. Configure the bot with `testnet: true` in the API section
4. Verify all functionality works as expected

### Moving to Mainnet

When ready to trade with real funds:

1. Generate new API keys on the main Binance platform
2. Update your configuration with the new keys
3. Set `testnet: false` or remove the testnet parameter
4. Start with small position sizes to verify everything works correctly

## Getting Help

If you encounter issues not covered in this guide:

1. Check the detailed logs for error messages
2. Review the [Binance API documentation](https://binance-docs.github.io/apidocs/futures/en/)
3. Open an issue on the project's GitHub repository with:
   - Detailed description of the issue
   - Relevant log excerpts
   - Configuration (with sensitive information redacted)
   - Steps to reproduce the problem



================================================
FILE: scripts/__init__.py
================================================



================================================
FILE: scripts/backtest.py
================================================
#!/usr/bin/env python3
import pandas as pd
import numpy as np
import logging
from datetime import datetime
import os
from pathlib import Path
from typing import Dict, Optional, List, Tuple, Any
import yaml
import matplotlib.pyplot as plt
from pydantic import BaseModel
import asyncio
from decimal import Decimal, getcontext, ROUND_DOWN

# Set decimal precision for financial calculations
getcontext().prec = 28

# Import necessary models and utilities
from src.models import Kline, TradeSignal, TradeDirection
from src.config_loader import ConfigManager
from src.data_processor import DataProcessor
from src.signal_engine import SignalEngineV1

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger('backtest')

class BacktestPosition(BaseModel):
    symbol: str
    entry_price: float
    entry_time: int
    quantity: float
    direction: TradeDirection
    stop_loss: float
    take_profit: float
    status: str = "OPEN"  # OPEN, CLOSED_TP, CLOSED_SL, CLOSED_EXIT
    exit_price: Optional[float] = None
    exit_time: Optional[int] = None
    profit_loss: Optional[float] = None
    profit_loss_percent: Optional[float] = None
    
class BacktestResults(BaseModel):
    initial_balance: float
    final_balance: float
    total_trades: int
    winning_trades: int
    losing_trades: int
    win_rate: float
    avg_profit_percent: float
    avg_loss_percent: float
    max_drawdown: float
    profit_factor: float
    total_fees: float
    
class Backtester:
    def __init__(self, config_path: str, data_file: str):
        self.config_path = config_path
        self.data_file = data_file
        self.config_manager = ConfigManager(config_path)
        self.data_processor = DataProcessor(self.config_manager)
        self.signal_engine = SignalEngineV1(self.config_manager, self.data_processor)
        
        # Backtest specific properties
        self.initial_balance = Decimal('10000.0')  # Default USDT
        self.current_balance = self.initial_balance
        self.positions: List[BacktestPosition] = []
        self.trade_history: List[BacktestPosition] = []
        self.equity_curve: List[Tuple[int, float]] = []  # (timestamp, balance)
        
        # Load backtest settings from config
        self._load_backtest_config()
        
    def _load_backtest_config(self):
        """Load backtesting specific configuration"""
        config = self.config_manager.get_config()
        backtest_settings_from_config = config.get("backtesting")  # Get potential None or dict

        # Ensure backtest_config is a dictionary to safely call .get() on it
        backtest_config = backtest_settings_from_config if isinstance(backtest_settings_from_config, dict) else {}
        
        self.initial_balance = Decimal(str(backtest_config.get("initial_balance_usdt", 10000.0)))
        self.current_balance = self.initial_balance
        self.fee_percent = Decimal(str(backtest_config.get("fee_percent", 0.04))) / Decimal('100')  # Convert to decimal
        self.slippage_percent = Decimal(str(backtest_config.get("slippage_percent", 0.01))) / Decimal('100')  # Convert to decimal
        
    def load_historical_data(self) -> List[Kline]:
        """Load historical data from CSV file and convert to Kline objects"""
        logger.info(f"Loading historical data from {self.data_file}")
        
        try:
            # Load data from CSV
            df = pd.read_csv(self.data_file)
            
            # Convert 'Open time' from string to timestamp
            df['timestamp'] = pd.to_datetime(df['Open time']).astype(np.int64) // 10**6  # Convert to milliseconds
            
            # Create list of Kline objects
            klines = []
            for _, row in df.iterrows():
                kline = Kline(
                    timestamp=int(row['timestamp']),
                    open=float(row['Open']),
                    high=float(row['High']),
                    low=float(row['Low']),
                    close=float(row['Close']),
                    volume=float(row['Volume']),
                    quote_asset_volume=float(row.get('Taker buy base asset volume', 0)),
                    number_of_trades=int(row.get('Number of trades', 0)),
                    is_closed=True,  # All historical data is considered closed
                    symbol="BTCUSDT",  # Default symbol, will be overridden in process_data_async
                    interval="1m"  # Default interval, will be overridden in process_data_async
                )
                klines.append(kline)
            
            logger.info(f"Loaded {len(klines)} data points")
            return klines
        except Exception as e:
            logger.error(f"Error loading data: {e}")
            raise

    async def process_data_async(self, klines: List[Kline], symbol: str = "BTCUSDT", interval: str = "1m") -> pd.DataFrame:
        """
        Process historical Kline data through the data processor
        """
        logger.info(f"Processing {len(klines)} klines for {symbol} {interval}")
        
        # Update klines with symbol and interval
        for kline in klines:
            kline.symbol = symbol
            kline.interval = interval
            
            # Process each kline through the data processor
            await self.data_processor.process_kline(kline)
        
        logger.info(f"Finished processing klines and calculating indicators")
        
        # Return the dataframe with indicators
        return self.data_processor.indicator_data[symbol][interval]
        
    async def generate_signals(self, df: pd.DataFrame, symbol: str = "BTCUSDT", config_symbol: str = "BTC_USDT") -> List[TradeSignal]:
        """
        Generate trading signals for the historical data
        """
        logger.info(f"Generating signals for {symbol}")
        
        signals = []
        
        # Disable the time-based filtering temporarily for backtest
        # Store the original last_signal_time
        original_last_signal_time = self.signal_engine.last_signal_time.copy()
        self.signal_engine.last_signal_time = {}
        
        # Add debug info about the dataframe
        logger.info(f"DataFrame shape: {df.shape}, columns: {df.columns.tolist()}")
        logger.info(f"First few rows of DataFrame:\n{df.head(2)}")
        
        # Add debug logging for SMA values
        valid_sma_rows = df[pd.notna(df['sma_short']) & pd.notna(df['sma_long'])]
        logger.info(f"Number of rows with valid SMA calculations: {len(valid_sma_rows)} out of {len(df)}")
        
        if len(valid_sma_rows) > 0:
            # Log some sample rows to check for crossover potential
            logger.info(f"First 5 valid SMA rows:\n{valid_sma_rows[['close', 'sma_short', 'sma_long']].head(5)}")
            
            # Temporarily make the dataframe accessible to the signal engine
            # Store the original data to restore later
            original_df = self.data_processor.indicator_data.get(symbol, {}).get("1m", None)
            self.data_processor.indicator_data.setdefault(symbol, {})["1m"] = valid_sma_rows
            
            # Iterate through each potential signal candle
            for i in range(1, len(valid_sma_rows)):
                current = valid_sma_rows.iloc[i]
                previous = valid_sma_rows.iloc[i-1]
                
                # Log potential crossovers for debugging
                crossed_up = (previous['sma_short'] <= previous['sma_long'] and 
                             current['sma_short'] > current['sma_long'])
                crossed_down = (previous['sma_short'] >= previous['sma_long'] and
                               current['sma_short'] < current['sma_long'])
                
                if crossed_up or crossed_down:
                    logger.debug(f"Potential crossover at index {i}, timestamp: {current.name}")
                    logger.debug(f"Previous: short={previous['sma_short']}, long={previous['sma_long']}")
                    logger.debug(f"Current: short={current['sma_short']}, long={current['sma_long']}")
                    
                    # Set up a specific slice of data for this timestamp to check for signals
                    kline_slice = valid_sma_rows[:i+1]  # Include data up to current point only
                    self.data_processor.indicator_data[symbol]["1m"] = kline_slice
                    
                    # Check for signal at this point using the signal engine
                    signal = await self.signal_engine.check_signal(symbol, config_symbol)
                    
                    if signal:
                        # Custom field to store the timestamp for the backtest simulation
                        signal.timestamp = int(current.name)
                        signals.append(signal)
                        logger.info(f"Generated {signal.direction.value} signal at {datetime.fromtimestamp(current.name/1000)}")
            
            # Restore the original dataframe
            if original_df is not None:
                self.data_processor.indicator_data[symbol]["1m"] = original_df
            else:
                if symbol in self.data_processor.indicator_data and "1m" in self.data_processor.indicator_data[symbol]:
                    del self.data_processor.indicator_data[symbol]["1m"]
        
        # Restore the original last_signal_time
        self.signal_engine.last_signal_time = original_last_signal_time
        
        logger.info(f"Generated {len(signals)} signals")
        return signals

    def simulate_trading(self, signals: List[TradeSignal], df: pd.DataFrame):
        """
        Simulate trading based on generated signals
        """
        logger.info(f"Starting trading simulation with {len(signals)} signals")
        
        # Handle the case where no signals were generated
        if not signals:
            logger.warning("No signals provided to simulate_trading. Exiting simulation.")
            # Initialize the equity curve with initial balance
            if df is not None and not df.empty:
                self.equity_curve = [(df.iloc[0]['timestamp'], float(self.initial_balance))]
            else:
                self.equity_curve = [(int(datetime.now().timestamp() * 1000), float(self.initial_balance))]
            self.final_balance = float(self.current_balance)
            self.total_fees = Decimal('0.0')
            return [], self.equity_curve
        
        # Get configuration
        config = self.config_manager.get_config()
        pair_configs = config.get("pairs", {})
        global_v1_config = config.get("global_settings", {}).get("v1_strategy", {})
        
        # Get symbol specific config
        symbol_config = None
        for cfg_sym, details in pair_configs.items():
            if cfg_sym.upper() == signals[0].config_symbol.upper():
                symbol_config = details
                break
        
        # Check if symbol_config was found
        if not symbol_config:
            logger.error(f"Configuration for {signals[0].config_symbol} not found. Cannot simulate trades.")
            # Initialize the equity curve with initial balance
            if df is not None and not df.empty:
                self.equity_curve = [(df.iloc[0]['timestamp'], float(self.initial_balance))]
            else:
                self.equity_curve = [(int(datetime.now().timestamp() * 1000), float(self.initial_balance))]
            self.final_balance = float(self.current_balance)
            self.total_fees = Decimal('0.0')
            return [], self.equity_curve
        
        # Set leverage and margin
        leverage = Decimal(str(symbol_config.get("leverage", global_v1_config.get("default_leverage", 10))))
        fixed_margin_usdt = Decimal(str(symbol_config.get("margin_usdt", global_v1_config.get("default_margin_usdt", 50.0))))
        
        # Track current positions
        open_positions = []
        closed_positions = []
        
        # Track equity curve
        equity_curve = [(df.iloc[0]['timestamp'], float(self.initial_balance))]
        
        # Iterate through each candle
        current_balance = self.initial_balance
        total_fees = Decimal('0.0')
        
        for i in range(len(df)):
            current_candle = df.iloc[i]
            current_time = current_candle['timestamp']
            
            # Check for signals at this timestamp
            new_signals = [s for s in signals if s.timestamp == current_time]
            
            # Process open positions first (check for TP/SL)
            for pos in list(open_positions):
                # Check if TP hit
                if (pos.direction == TradeDirection.LONG and current_candle['high'] >= pos.take_profit) or \
                   (pos.direction == TradeDirection.SHORT and current_candle['low'] <= pos.take_profit):
                    # Close at take profit
                    pos.status = "CLOSED_TP"
                    pos.exit_price = pos.take_profit
                    pos.exit_time = current_time
                    
                    # Calculate P&L using Decimal for precision
                    if pos.direction == TradeDirection.LONG:
                        pos.profit_loss = float(
                            (Decimal(str(pos.exit_price)) - Decimal(str(pos.entry_price))) * 
                            Decimal(str(pos.quantity)) * leverage
                        )
                    else:  # SHORT
                        pos.profit_loss = float(
                            (Decimal(str(pos.entry_price)) - Decimal(str(pos.exit_price))) * 
                            Decimal(str(pos.quantity)) * leverage
                        )
                    
                    # Account for fees
                    entry_fee = Decimal(str(pos.entry_price)) * Decimal(str(pos.quantity)) * self.fee_percent
                    exit_fee = Decimal(str(pos.exit_price)) * Decimal(str(pos.quantity)) * self.fee_percent
                    fee = entry_fee + exit_fee
                    pos.profit_loss = float(Decimal(str(pos.profit_loss)) - fee)
                    total_fees += fee
                    
                    # Update balance
                    current_balance += Decimal(str(pos.profit_loss))
                    
                    # Calculate percent P&L
                    pos.profit_loss_percent = float(
                        (Decimal(str(pos.profit_loss)) / 
                        (Decimal(str(pos.entry_price)) * Decimal(str(pos.quantity)))) * Decimal('100')
                    )
                    
                    # Log
                    logger.info(f"TP HIT: {pos.direction.value} {pos.symbol} closed at {pos.exit_price}, "
                                f"P&L: ${pos.profit_loss:.2f} ({pos.profit_loss_percent:.2f}%)")
                    
                    # Move to closed positions
                    closed_positions.append(pos)
                    open_positions.remove(pos)
                
                # Check if SL hit
                elif (pos.direction == TradeDirection.LONG and current_candle['low'] <= pos.stop_loss) or \
                     (pos.direction == TradeDirection.SHORT and current_candle['high'] >= pos.stop_loss):
                    # Close at stop loss
                    pos.status = "CLOSED_SL"
                    pos.exit_price = pos.stop_loss
                    pos.exit_time = current_time
                    
                    # Calculate P&L using Decimal for precision
                    if pos.direction == TradeDirection.LONG:
                        pos.profit_loss = float(
                            (Decimal(str(pos.exit_price)) - Decimal(str(pos.entry_price))) * 
                            Decimal(str(pos.quantity)) * leverage
                        )
                    else:  # SHORT
                        pos.profit_loss = float(
                            (Decimal(str(pos.entry_price)) - Decimal(str(pos.exit_price))) * 
                            Decimal(str(pos.quantity)) * leverage
                        )
                    
                    # Account for fees
                    entry_fee = Decimal(str(pos.entry_price)) * Decimal(str(pos.quantity)) * self.fee_percent
                    exit_fee = Decimal(str(pos.exit_price)) * Decimal(str(pos.quantity)) * self.fee_percent
                    fee = entry_fee + exit_fee
                    pos.profit_loss = float(Decimal(str(pos.profit_loss)) - fee)
                    total_fees += fee
                    
                    # Update balance
                    current_balance += Decimal(str(pos.profit_loss))
                    
                    # Calculate percent P&L
                    pos.profit_loss_percent = float(
                        (Decimal(str(pos.profit_loss)) / 
                        (Decimal(str(pos.entry_price)) * Decimal(str(pos.quantity)))) * Decimal('100')
                    )
                    
                    # Log
                    logger.info(f"SL HIT: {pos.direction.value} {pos.symbol} closed at {pos.exit_price}, "
                                f"P&L: ${pos.profit_loss:.2f} ({pos.profit_loss_percent:.2f}%)")
                    
                    # Move to closed positions
                    closed_positions.append(pos)
                    open_positions.remove(pos)
            
            # Process new signals and open positions
            for signal in new_signals:
                # Calculate position size
                position_size = fixed_margin_usdt / Decimal(str(signal.entry_price))
                
                # Apply slippage to entry
                entry_price = Decimal(str(signal.entry_price))
                if signal.direction == TradeDirection.LONG:
                    entry_price *= (Decimal('1') + self.slippage_percent)  # Higher for buys
                else:
                    entry_price *= (Decimal('1') - self.slippage_percent)  # Lower for sells
                
                # Create new position
                new_position = BacktestPosition(
                    symbol=signal.symbol,
                    entry_price=float(entry_price),
                    entry_time=current_time,
                    quantity=float(position_size),
                    direction=signal.direction,
                    stop_loss=signal.stop_loss_price,
                    take_profit=signal.take_profit_price,
                    status="OPEN"
                )
                
                # Calculate entry fee
                entry_fee = entry_price * position_size * self.fee_percent
                total_fees += entry_fee
                
                # Log
                logger.info(f"OPEN: {signal.direction.value} {signal.symbol} at {float(entry_price)}, "
                            f"Size: {float(position_size)}, SL: {signal.stop_loss_price}, TP: {signal.take_profit_price}")
                
                # Add to open positions
                open_positions.append(new_position)
            
            # Track equity at each step
            equity_curve.append((current_time, float(current_balance)))
        
        # Close any remaining open positions at the last price
        last_candle = df.iloc[-1]
        for pos in list(open_positions):
            pos.status = "CLOSED_EXIT"
            pos.exit_price = float(last_candle['close'])
            pos.exit_time = last_candle['timestamp']
            
            # Calculate P&L using Decimal
            if pos.direction == TradeDirection.LONG:
                pos.profit_loss = float(
                    (Decimal(str(pos.exit_price)) - Decimal(str(pos.entry_price))) * 
                    Decimal(str(pos.quantity)) * leverage
                )
            else:  # SHORT
                pos.profit_loss = float(
                    (Decimal(str(pos.entry_price)) - Decimal(str(pos.exit_price))) * 
                    Decimal(str(pos.quantity)) * leverage
                )
            
            # Account for fees
            entry_fee = Decimal(str(pos.entry_price)) * Decimal(str(pos.quantity)) * self.fee_percent
            exit_fee = Decimal(str(pos.exit_price)) * Decimal(str(pos.quantity)) * self.fee_percent
            fee = entry_fee + exit_fee
            pos.profit_loss = float(Decimal(str(pos.profit_loss)) - fee)
            total_fees += fee
            
            # Update balance
            current_balance += Decimal(str(pos.profit_loss))
            
            # Calculate percent P&L
            pos.profit_loss_percent = float(
                (Decimal(str(pos.profit_loss)) / 
                (Decimal(str(pos.entry_price)) * Decimal(str(pos.quantity)))) * Decimal('100')
            )
            
            # Log
            logger.info(f"CLOSE AT END: {pos.direction.value} {pos.symbol} closed at {pos.exit_price}, "
                        f"P&L: ${pos.profit_loss:.2f} ({pos.profit_loss_percent:.2f}%)")
            
            # Move to closed positions
            closed_positions.append(pos)
        
        # Save results
        self.positions = closed_positions
        self.equity_curve = equity_curve
        self.final_balance = float(current_balance)
        self.total_fees = float(total_fees)
        
        logger.info(f"Trading simulation completed. Final balance: ${float(current_balance):.2f}, "
                    f"P&L: ${float(current_balance - self.initial_balance):.2f}, "
                    f"Total fees: ${float(total_fees):.2f}")
        
        return closed_positions, equity_curve

    def analyze_results(self):
        """
        Analyze backtest results and generate performance metrics
        """
        if not self.positions:
            logger.warning("No positions to analyze")
            return None
        
        # Extract performance metrics
        total_trades = len(self.positions)
        winning_trades = len([p for p in self.positions if p.profit_loss and p.profit_loss > 0])
        losing_trades = len([p for p in self.positions if p.profit_loss and p.profit_loss <= 0])
        
        # Calculate win rate
        win_rate = winning_trades / total_trades if total_trades > 0 else 0
        
        # Calculate average profit/loss
        profit_trades = [p.profit_loss_percent for p in self.positions if p.profit_loss and p.profit_loss > 0]
        loss_trades = [p.profit_loss_percent for p in self.positions if p.profit_loss and p.profit_loss <= 0]
        
        avg_profit = sum(profit_trades) / len(profit_trades) if profit_trades else 0
        avg_loss = sum(loss_trades) / abs(len(loss_trades)) if loss_trades else 0
        
        # Calculate drawdown
        equity_values = [balance for _, balance in self.equity_curve]
        max_dd = 0
        peak = equity_values[0]
        
        for value in equity_values:
            if value > peak:
                peak = value
            dd = (peak - value) / peak
            if dd > max_dd:
                max_dd = dd
        
        # Calculate profit factor
        total_profit = sum([p.profit_loss for p in self.positions if p.profit_loss and p.profit_loss > 0])
        total_loss = abs(sum([p.profit_loss for p in self.positions if p.profit_loss and p.profit_loss <= 0]))
        profit_factor = total_profit / total_loss if total_loss > 0 else float('inf')
        
        # Create results object
        results = BacktestResults(
            initial_balance=float(self.initial_balance),
            final_balance=self.final_balance,
            total_trades=total_trades,
            winning_trades=winning_trades,
            losing_trades=losing_trades,
            win_rate=win_rate,
            avg_profit_percent=avg_profit,
            avg_loss_percent=avg_loss,
            max_drawdown=max_dd,
            profit_factor=profit_factor,
            total_fees=self.total_fees
        )
        
        # Log summary
        logger.info("\n===== BACKTEST RESULTS =====")
        logger.info(f"Initial Balance: ${float(self.initial_balance):.2f}")
        logger.info(f"Final Balance: ${self.final_balance:.2f}")
        logger.info(f"Net Profit/Loss: ${self.final_balance - float(self.initial_balance):.2f} "
                    f"({((self.final_balance / float(self.initial_balance)) - 1) * 100:.2f}%)")
        logger.info(f"Total Trades: {total_trades}")
        logger.info(f"Winning Trades: {winning_trades} ({win_rate*100:.2f}%)")
        logger.info(f"Losing Trades: {losing_trades}")
        logger.info(f"Average Profit: {avg_profit:.2f}%")
        logger.info(f"Average Loss: {avg_loss:.2f}%")
        logger.info(f"Profit Factor: {profit_factor:.2f}")
        logger.info(f"Maximum Drawdown: {max_dd*100:.2f}%")
        logger.info(f"Total Fees: ${self.total_fees:.2f}")
        logger.info("===========================\n")
        
        return results
    
    def plot_equity_curve(self, save_path: Optional[str] = None):
        """Plot equity curve and save to file if path provided"""
        if not self.equity_curve:
            logger.warning("No equity data to plot")
            return
        
        # Convert timestamps to datetime for better readability
        times = [datetime.fromtimestamp(ts/1000) for ts, _ in self.equity_curve]
        balances = [balance for _, balance in self.equity_curve]
        
        plt.figure(figsize=(12, 6))
        plt.plot(times, balances)
        plt.title('Equity Curve')
        plt.xlabel('Date')
        plt.ylabel('Balance (USDT)')
        plt.grid(True)
        
        if save_path:
            save_dir = os.path.dirname(save_path)
            if save_dir and not os.path.exists(save_dir):
                os.makedirs(save_dir)
            plt.savefig(save_path)
            logger.info(f"Equity curve saved to {save_path}")
        else:
            plt.show()

async def run_backtest(config_path: str, data_file: str, symbol: str = "BTCUSDT", config_symbol: str = "BTC_USDT"):
    """
    Run a complete backtest
    
    Args:
        config_path: Path to configuration file
        data_file: Path to historical data CSV file
        symbol: Trading symbol in API format (e.g., "BTCUSDT")
        config_symbol: Trading symbol in config format (e.g., "BTC_USDT")
    """
    # Initialize backtester
    backtester = Backtester(config_path, data_file)
    
    # Load and process data
    kline_objects = backtester.load_historical_data()
    processed_df = await backtester.process_data_async(kline_objects, symbol=symbol)
    
    # Generate signals
    signals = await backtester.generate_signals(processed_df, symbol=symbol, config_symbol=config_symbol)
    
    # Simulate trading
    positions, equity_curve = backtester.simulate_trading(signals, processed_df)
    
    # Analyze results
    results = backtester.analyze_results()
    
    # Create basic results if no trades were executed
    if results is None:
        logger.info("No trade results to analyze. Creating default results.")
        results = BacktestResults(
            initial_balance=float(backtester.initial_balance),
            final_balance=float(backtester.current_balance),
            total_trades=0,
            winning_trades=0,
            losing_trades=0,
            win_rate=0.0,
            avg_profit_percent=0.0,
            avg_loss_percent=0.0,
            max_drawdown=0.0,
            profit_factor=0.0,
            total_fees=0.0
        )
    
    # Plot equity curve
    results_dir = Path("backtest_results")
    results_dir.mkdir(exist_ok=True)
    backtester.plot_equity_curve(
        save_path=str(results_dir / f"{symbol}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png")
    )
    
    return results, positions, equity_curve

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='Binance Futures Trading Bot Backtester')
    parser.add_argument('--config', type=str, default='config/config.yaml', help='Path to configuration file')
    parser.add_argument('--data', type=str, required=True, help='Path to historical data CSV file')
    parser.add_argument('--symbol', type=str, default='BTCUSDT', help='Trading symbol in API format')
    parser.add_argument('--config-symbol', type=str, default='BTC_USDT', help='Trading symbol in config format')
    
    args = parser.parse_args()
    
    # Run backtest
    asyncio.run(run_backtest(args.config, args.data, args.symbol, args.config_symbol)) 


================================================
FILE: src/__init__.py
================================================



================================================
FILE: src/config_loader.py
================================================
import yaml
import os
import logging
import time
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
from threading import Lock

logger = logging.getLogger(__name__)

DEFAULT_CONFIG_PATH = os.path.join(os.path.dirname(os.path.dirname(__file__)), "config", "config.yaml")
EXAMPLE_CONFIG_PATH = os.path.join(os.path.dirname(os.path.dirname(__file__)), "config", "config.yaml.example")

class ConfigChangeHandler(FileSystemEventHandler):
    def __init__(self, config_manager):
        self.config_manager = config_manager

    def on_modified(self, event):
        if not event.is_directory and event.src_path == self.config_manager.config_file_path:
            logger.info(f"Configuration file {event.src_path} changed. Reloading...")
            self.config_manager.load_config()

class ConfigManager:
    _instance = None
    _lock = Lock()

    def __new__(cls, *args, **kwargs):
        if not cls._instance:
            with cls._lock:
                if not cls._instance:
                    cls._instance = super(ConfigManager, cls).__new__(cls)
        return cls._instance

    def __init__(self, config_file_path=None, auto_reload=True):
        # Ensure __init__ is only run once for the singleton instance
        if not hasattr(self, '_initialized'):
            with self._lock:
                if not hasattr(self, '_initialized'): 
                    self.config_file_path = config_file_path or DEFAULT_CONFIG_PATH
                    self.config_data = {}
                    self._callbacks = []
                    self.observer = None
                    self.auto_reload = auto_reload
                    self._ensure_config_file_exists()
                    self.load_config()
                    if self.auto_reload:
                        self._start_watcher()
                    self._initialized = True

    def _ensure_config_file_exists(self):
        if not os.path.exists(self.config_file_path):
            logger.warning(
                f"Config file not found at {self.config_file_path}. "
                f"Attempting to copy from {EXAMPLE_CONFIG_PATH}."
            )
            try:
                config_dir = os.path.dirname(self.config_file_path)
                if not os.path.exists(config_dir):
                    os.makedirs(config_dir)
                
                with open(EXAMPLE_CONFIG_PATH, 'r') as src, open(self.config_file_path, 'w') as dst:
                    dst.write(src.read())
                logger.info(f"Successfully copied example config to {self.config_file_path}. Please review and update it.")
            except Exception as e:
                logger.error(f"Could not copy example config: {e}. Please create {self.config_file_path} manually.")
                # Potentially raise an error or exit if config is critical for startup

    def load_config(self):
        try:
            with open(self.config_file_path, 'r') as f:
                new_config_data = yaml.safe_load(f)
            if new_config_data:
                self.config_data = new_config_data
                logger.info(f"Configuration loaded successfully from {self.config_file_path}")
                self._notify_callbacks()
            else:
                logger.warning(f"Configuration file {self.config_file_path} is empty or invalid.")
        except FileNotFoundError:
            logger.error(f"Configuration file not found: {self.config_file_path}")
            # Fallback to empty or default config if appropriate, or raise error
            self.config_data = {}
        except yaml.YAMLError as e:
            logger.error(f"Error parsing YAML configuration file {self.config_file_path}: {e}")
            # Keep old config or fallback
        except Exception as e:
            logger.error(f"An unexpected error occurred while loading configuration: {e}")

    def get_config(self):
        with self._lock: # Ensure thread-safe access to config_data
            return self.config_data.copy() # Return a copy to prevent modification

    def get_specific_config(self, key_path, default=None):
        """ Fetches a specific config value using a dot-separated key path. E.g., 'api.binance_api_key' """
        try:
            value = self.config_data
            for key in key_path.split('.'):
                if isinstance(value, dict):
                    value = value[key]
                else:
                    # If at any point value is not a dict and we still have keys, path is invalid
                    logger.warning(f"Invalid key path '{key_path}' at segment '{key}'.")
                    return default
            return value
        except KeyError:
            logger.debug(f"Config key '{key_path}' not found. Returning default: {default}")
            return default
        except Exception as e:
            logger.error(f"Error getting specific config '{key_path}': {e}")
            return default

    def register_callback(self, callback):
        if callable(callback):
            self._callbacks.append(callback)
        else:
            logger.warning("Attempted to register a non-callable callback.")

    def unregister_callback(self, callback):
        """Remove a previously registered callback."""
        if callback in self._callbacks:
            self._callbacks.remove(callback)
            logger.debug(f"Callback {callback.__name__ if hasattr(callback, '__name__') else callback} unregistered.")
        else:
            logger.warning(f"Attempted to unregister a callback that was not registered.")

    def _notify_callbacks(self):
        for callback in self._callbacks:
            try:
                callback(self.get_config())
            except Exception as e:
                logger.error(f"Error executing config update callback {callback.__name__}: {e}")

    def _start_watcher(self):
        if self.observer:
            self.observer.stop()
            self.observer.join() # Wait for the thread to finish

        event_handler = ConfigChangeHandler(self)
        self.observer = Observer()
        # Observe the directory containing the config file, as some editors modify files by creating a new one and renaming.
        config_dir = os.path.dirname(self.config_file_path) or '.'
        self.observer.schedule(event_handler, config_dir, recursive=False)
        
        try:
            self.observer.start()
            logger.info(f"Started watching configuration file {self.config_file_path} for changes.")
        except Exception as e:
            logger.error(f"Error starting configuration file watcher: {e}")
            self.observer = None # Ensure observer is None if it failed to start

    def stop_watcher(self):
        if self.observer and self.observer.is_alive():
            self.observer.stop()
            self.observer.join()
            logger.info("Stopped configuration file watcher.")

# Example usage (typically in main.py or similar entry point):
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    
    # Create a dummy config.yaml for testing
    dummy_config_content = """
    api:
      binance_api_key: "TEST_KEY"
      binance_api_secret: "TEST_SECRET"
    logging:
      level: "DEBUG"
    """
    if not os.path.exists(os.path.dirname(DEFAULT_CONFIG_PATH)):
        os.makedirs(os.path.dirname(DEFAULT_CONFIG_PATH))
    with open(DEFAULT_CONFIG_PATH, "w") as f:
        f.write(dummy_config_content)

    config_manager = ConfigManager()
    print("Initial config:", config_manager.get_config())
    print("API Key:", config_manager.get_specific_config("api.binance_api_key"))
    print("Logging Level:", config_manager.get_specific_config("logging.level"))

    def my_config_update_handler(new_config):
        print("Callback: Config updated! New logging level:", new_config.get("logging", {}).get("level"))

    config_manager.register_callback(my_config_update_handler)

    print(f"\nSimulating config file change. Please modify {DEFAULT_CONFIG_PATH} and save.")
    print("(e.g., change logging.level to INFO)")
    print("Watching for 30 seconds... Press Ctrl+C to stop early.")
    
    try:
        time.sleep(30) # Keep alive to observe changes
    except KeyboardInterrupt:
        print("\nExiting example.")
    finally:
        config_manager.stop_watcher()
        # Clean up dummy config
        # os.remove(DEFAULT_CONFIG_PATH)




================================================
FILE: src/connectors.py
================================================
import ccxt.async_support as ccxt
import asyncio
import websockets
import json
import logging
import time
import random
from typing import Callable, List, Dict, Any, Optional, Literal

from src.config_loader import ConfigManager
from src.models import Kline # Assuming Kline model is in src.models

logger = logging.getLogger(__name__)

# Symbol conversion utility (can be moved to utils.py later)
def convert_symbol_to_ws_format(config_symbol: str) -> str:
    """Converts BTC_USDT to btcusdt, BTCUSD_PERP to btcusd_perp"""
    if "_" in config_symbol:
        if config_symbol.endswith("_PERP"):
            return config_symbol.replace("_PERP", "_perp").lower()
        return config_symbol.replace("_", "").lower()
    return config_symbol.lower() # Fallback for already formatted or simple symbols

def convert_symbol_to_api_format(config_symbol: str) -> str:
    """Converts BTC_USDT to BTCUSDT, BTCUSD_PERP to BTCUSD_PERP"""
    if "_" in config_symbol:
        if config_symbol.endswith("_PERP"):
            return config_symbol.upper()
        return config_symbol.replace("_", "").upper()
    return config_symbol.upper()

class BinanceRESTClient:
    def __init__(self, config_manager: ConfigManager):
        self.config_manager = config_manager
        self.exchange = None
        self._initialize_exchange()

    def _initialize_exchange(self):
        config = self.config_manager.get_config()
        api_key = config.get("api", {}).get("binance_api_key")
        api_secret = config.get("api", {}).get("binance_api_secret")
        is_testnet = config.get("api", {}).get("testnet", False)

        if not api_key or not api_secret or "YOUR_" in api_key: # Basic check for placeholder
            logger.warning("API key/secret not found or placeholders used. REST client will operate in simulated mode (no real calls).")
            self.exchange = None 
            return

        self.exchange = ccxt.binance({
            "apiKey": api_key,
            "secret": api_secret,
            "options": {
                "defaultType": "future",
            },
        })
        if is_testnet:
            self.exchange.set_sandbox_mode(True)
            logger.info("Binance REST Client initialized in Testnet mode.")
        else:
            logger.info("Binance REST Client initialized in Mainnet mode.")

    async def close_exchange(self):
        if self.exchange:
            await self.exchange.close()
            logger.info("CCXT exchange instance closed.")

    async def fetch_exchange_info(self, params={}):
        if not self.exchange: return None
        try:
            markets = await self.exchange.load_markets()
            return markets 
        except Exception as e:
            logger.error(f"Error fetching exchange info: {e}")
            return None

    async def fetch_balance(self, params={}):
        if not self.exchange: return None # Or simulate a balance for testing
        try:
            balance = await self.exchange.fetch_balance(params)
            return balance
        except Exception as e:
            logger.error(f"Error fetching balance: {e}")
            return None

    async def create_order(self, symbol: str, order_type: str, side: str, amount: float, price: Optional[float] = None, params={}):
        if not self.exchange: 
            logger.info(f"Simulated order: {side} {amount} {symbol} at {price or 'market'}")
            return {"id": f"simulated_order_{int(time.time())}", "symbol": symbol, "status": "NEW", "type": order_type, "side": side, "amount": amount, "price": price}
        try:
            api_symbol = convert_symbol_to_api_format(symbol)
            order = await self.exchange.create_order(api_symbol, order_type, side, amount, price, params)
            logger.info(f"Order created: {order}")
            return order
        except Exception as e:
            logger.error(f"Error creating order for {symbol}: {e}")
            return None

    async def cancel_order(self, order_id: str, symbol: str, params={}):
        if not self.exchange: 
            logger.info(f"Simulated cancel order: {order_id} for {symbol}")
            return {"id": order_id, "status": "CANCELED"}
        try:
            api_symbol = convert_symbol_to_api_format(symbol)
            response = await self.exchange.cancel_order(order_id, api_symbol, params)
            return response
        except Exception as e:
            logger.error(f"Error cancelling order {order_id} for {symbol}: {e}")
            return None

    async def fetch_open_orders(self, symbol: Optional[str] = None, params={}):
        if not self.exchange: return []
        try:
            api_symbol = convert_symbol_to_api_format(symbol) if symbol else None
            open_orders = await self.exchange.fetch_open_orders(api_symbol, params=params)
            return open_orders
        except Exception as e:
            logger.error(f"Error fetching open orders for {symbol}: {e}")
            return []

    async def fetch_position(self, symbol: str, params={}):
        if not self.exchange: return None
        try:
            api_symbol = convert_symbol_to_api_format(symbol)
            positions = await self.exchange.fetch_positions([api_symbol], params=params)
            for position in positions:
                # CCXT position symbol format might vary, ensure robust matching
                if position.get("symbol") == api_symbol or position.get("info", {}).get("symbol") == api_symbol:
                    return position
            return None 
        except Exception as e:
            logger.error(f"Error fetching position for {symbol}: {e}")
            return None

    async def fetch_positions(self, symbols: Optional[List[str]] = None, params={}):
        if not self.exchange: return []
        try:
            api_symbols = [convert_symbol_to_api_format(s) for s in symbols] if symbols else None
            positions = await self.exchange.fetch_positions(api_symbols, params=params)
            return positions
        except Exception as e:
            logger.error(f"Error fetching positions: {e}")
            return []

    async def set_leverage(self, symbol: str, leverage: int, params={}):
        if not self.exchange: 
            logger.info(f"Simulated set leverage: {leverage}x for {symbol}")
            return True 
        try:
            api_symbol = convert_symbol_to_api_format(symbol)
            response = await self.exchange.set_leverage(leverage, api_symbol, params)
            logger.info(f"Leverage set for {symbol} to {leverage}x: {response}")
            return response
        except Exception as e:
            logger.error(f"Error setting leverage for {symbol} to {leverage}x: {e}")
            return False

    async def set_margin_mode(self, symbol: str, margin_mode: str, params={}):
        if not self.exchange: 
            logger.info(f"Simulated set margin mode: {margin_mode} for {symbol}")
            return True
        try:
            api_symbol = convert_symbol_to_api_format(symbol)
            response = await self.exchange.set_margin_mode(margin_mode.upper(), api_symbol, params)
            logger.info(f"Margin mode set for {symbol} to {margin_mode.upper()}: {response}")
            return response
        except Exception as e:
            logger.error(f"Error setting margin mode for {symbol} to {margin_mode.upper()}: {e}")
            return False

    async def fetch_historical_klines(self, symbol: str, timeframe: str = "1m", since: Optional[int] = None, limit: Optional[int] = None, params={}):
        if not self.exchange: return []
        try:
            api_symbol = convert_symbol_to_api_format(symbol)
            klines_data = await self.exchange.fetch_ohlcv(api_symbol, timeframe, since, limit, params)
            # Convert to Kline model before returning
            klines = [
                Kline(
                    timestamp=k[0],
                    open=float(k[1]),
                    high=float(k[2]),
                    low=float(k[3]),
                    close=float(k[4]),
                    volume=float(k[5]),
                    is_closed=True, # fetch_ohlcv usually returns closed candles
                    symbol=api_symbol, # Use the API symbol
                    interval=timeframe
                ) for k in klines_data
            ]
            return klines
        except Exception as e:
            logger.error(f"Error fetching historical klines for {symbol} {timeframe}: {e}")
            return []

class BinanceWebSocketConnector:
    def __init__(self, config_manager: ConfigManager, kline_callback: Callable[[Kline, str], asyncio.Task]):
        self.config_manager = config_manager
        self.kline_callback = kline_callback
        self.ws_url_usdm_mainnet = "wss://fstream.binance.com/stream"
        self.ws_url_usdm_testnet = "wss://stream.binancefuture.com/stream" # Testnet URL for USDM
        self.ws_url_coinm_mainnet = "wss://dstream.binance.com/stream"
        self.ws_url_coinm_testnet = "wss://dstream.binancefuture.com/stream" # Testnet URL for COINM
        self._ws_connections: Dict[str, websockets.WebSocketClientProtocol] = {}
        self._active_subscriptions: Dict[str, List[str]] = {"USDT_M": [], "COIN_M": []}
        self._is_running = False
        self._reconnect_delay = 5
        self._tasks: List[asyncio.Task] = []
        self._is_testnet = self.config_manager.get_config().get("api", {}).get("testnet", False)

    def _get_ws_url(self, market_type: str) -> str:
        if market_type == "USDT_M":
            return self.ws_url_usdm_testnet if self._is_testnet else self.ws_url_usdm_mainnet
        elif market_type == "COIN_M":
            return self.ws_url_coinm_testnet if self._is_testnet else self.ws_url_coinm_mainnet
        raise ValueError(f"Invalid market type: {market_type}")

    def _get_active_pairs_and_intervals(self) -> Dict[str, List[str]]:
        config = self.config_manager.get_config()
        pairs_config = config.get("pairs", {})
        global_intervals = config.get("global_settings", {}).get("v1_strategy", {}).get("indicator_timeframes", ["1m"])
        
        active_streams_usdm: List[str] = []
        active_streams_coinm: List[str] = []

        for pair_symbol_config, pair_details in pairs_config.items():
            if pair_details.get("enabled", False):
                ws_symbol = convert_symbol_to_ws_format(pair_symbol_config)
                intervals_to_subscribe = pair_details.get("indicator_timeframes", global_intervals)
                contract_type = pair_details.get("contract_type", "USDT_M")
                
                for interval in intervals_to_subscribe:
                    stream_name = f"{ws_symbol}@kline_{interval}"
                    if contract_type == "COIN_M":
                        active_streams_coinm.append(stream_name)
                    else:
                        active_streams_usdm.append(stream_name)
        return {"USDT_M": active_streams_usdm, "COIN_M": active_streams_coinm}

    async def _subscribe(self, ws: websockets.WebSocketClientProtocol, streams: List[str]):
        if not streams: return
        sub_payload = {
            "method": "SUBSCRIBE",
            "params": streams,
            "id": int(time.time() * 1000)
        }
        await ws.send(json.dumps(sub_payload))
        logger.info(f"Subscribed to streams: {streams} on {ws.remote_address}")

    async def _unsubscribe(self, ws: websockets.WebSocketClientProtocol, streams: List[str]):
        if not streams or not ws or not ws.open: return
        unsub_payload = {
            "method": "UNSUBSCRIBE",
            "params": streams,
            "id": int(time.time() * 1000)
        }
        try:
            await ws.send(json.dumps(unsub_payload))
            logger.info(f"Unsubscribed from streams: {streams} on {ws.remote_address}")
        except Exception as e:
            logger.error(f"Error unsubscribing from {streams}: {e}")

    async def _handle_connection(self, market_type: Literal["USDT_M", "COIN_M"]):
        ws_url = self._get_ws_url(market_type)
        while self._is_running:
            try:
                current_streams_for_market = self._active_subscriptions[market_type]
                if not current_streams_for_market:
                    logger.debug(f"No active streams for {market_type}, connection loop sleeping.")
                    await asyncio.sleep(self._reconnect_delay) 
                    continue

                async with websockets.connect(ws_url, ping_interval=20, ping_timeout=10) as ws:
                    self._ws_connections[market_type] = ws
                    logger.info(f"Connected to Binance Futures {market_type} WebSocket ({'Testnet' if self._is_testnet else 'Mainnet'}): {ws_url}")
                    await self._subscribe(ws, current_streams_for_market)
                    self._reconnect_delay = 5 
                    async for message in ws:
                        await self._process_message(message, market_type)
            except (websockets.exceptions.ConnectionClosedError, websockets.exceptions.ConnectionClosedOK) as e:
                logger.warning(f"WebSocket connection closed for {market_type}: {e}. Reconnecting...")
            except ConnectionRefusedError:
                logger.error(f"Connection refused for {market_type} WebSocket. Check network or Binance status.")
            except Exception as e:
                logger.error(f"Error in {market_type} WebSocket handler: {e}. Reconnecting...")
            finally:
                if market_type in self._ws_connections:
                    del self._ws_connections[market_type]
                if self._is_running:
                    await asyncio.sleep(self._reconnect_delay)
                    self._reconnect_delay = min(self._reconnect_delay * 1.5, 60) 
                    self._reconnect_delay += random.uniform(0,1)

    async def _process_message(self, message_str: str, market_type: str):
        try:
            data = json.loads(message_str)
            if "stream" in data and "@kline_" in data["stream"]:
                kline_data = data["data"]["k"]
                kline_obj = Kline(
                    timestamp=kline_data["t"],
                    open=float(kline_data["o"]),
                    high=float(kline_data["h"]),
                    low=float(kline_data["l"]),
                    close=float(kline_data["c"]),
                    volume=float(kline_data["v"]),
                    quote_asset_volume=float(kline_data["q"]) if "q" in kline_data else 0.0,
                    number_of_trades=int(kline_data["n"]) if "n" in kline_data else 0,
                    is_closed=kline_data["x"],
                    symbol=kline_data["s"], 
                    interval=kline_data["i"]
                )
                # Ensure kline_callback is awaited if it's a coroutine
                if asyncio.iscoroutinefunction(self.kline_callback):
                    await self.kline_callback(kline_obj, market_type)
                else:
                    self.kline_callback(kline_obj, market_type) # If it's a regular function
            elif "result" in data and data["result"] is None: 
                logger.debug(f"Subscription/Unsubscription confirmed: {data}")
            elif "error" in data:
                logger.error(f"WebSocket error message: {data}")
        except json.JSONDecodeError:
            logger.error(f"Failed to decode JSON message: {message_str}")
        except Exception as e:
            logger.error(f"Error processing WebSocket message: {e} - Message: {message_str}")

    async def start(self):
        if self._is_running:
            logger.warning("WebSocket connector already running.")
            return
        self._is_running = True
        self._is_testnet = self.config_manager.get_config().get("api", {}).get("testnet", False)
        self.config_manager.register_callback(self._handle_config_update) 
        await self._handle_config_update(self.config_manager.get_config()) # Initial subscription setup
        logger.info("Binance WebSocket Connector started.")

    async def _handle_config_update(self, new_config: Dict):
        logger.info("Configuration updated, re-evaluating WebSocket subscriptions...")
        self._is_testnet = new_config.get("api", {}).get("testnet", False) # Update testnet status
        new_target_streams = self._get_active_pairs_and_intervals()

        for market_type in ["USDT_M", "COIN_M"]:
            current_ws = self._ws_connections.get(market_type)
            old_streams = self._active_subscriptions.get(market_type, [])
            new_streams_for_market = new_target_streams.get(market_type, [])

            streams_to_add = list(set(new_streams_for_market) - set(old_streams))
            streams_to_remove = list(set(old_streams) - set(new_streams_for_market))

            if current_ws and current_ws.open:
                if streams_to_remove:
                    await self._unsubscribe(current_ws, streams_to_remove)
                if streams_to_add:
                    await self._subscribe(current_ws, streams_to_add)
            elif streams_to_add: 
                # If no connection, but new streams, start a new connection task if not already planned
                # Check if a task for this market_type is already running or scheduled
                is_task_active = False
                for task in self._tasks:
                    # This check is a bit simplistic; ideally, tasks would be identifiable
                    if market_type in str(task): # Heuristic to check if task is for this market type
                        is_task_active = True
                        break
                if not is_task_active:
                    logger.info(f"No active connection for {market_type}, but new streams detected. Scheduling connection.")
                    task = asyncio.create_task(self._handle_connection(market_type))
                    self._tasks.append(task)
            
            self._active_subscriptions[market_type] = new_streams_for_market
            
            # If all streams for a market type are removed and a connection exists, close it.
            if not new_streams_for_market and current_ws and current_ws.open:
                logger.info(f"All streams for {market_type} removed. Closing WebSocket connection.")
                await current_ws.close()
                if market_type in self._ws_connections:
                    del self._ws_connections[market_type]
            # If no streams and no task, ensure no new tasks are created for this market type
            elif not new_streams_for_market:
                 logger.debug(f"No streams for {market_type}, ensuring no connection task is active or created.")

        # Initial connection tasks if not already started
        for market_type in ["USDT_M", "COIN_M"]:
            if self._active_subscriptions.get(market_type) and market_type not in self._ws_connections:
                is_task_active = False
                for task in self._tasks:
                    if market_type in str(task):
                        is_task_active = True
                        break
                if not is_task_active:
                    logger.info(f"Initial streams for {market_type} detected. Scheduling connection.")
                    task = asyncio.create_task(self._handle_connection(market_type))
                    self._tasks.append(task)

    async def stop(self):
        logger.info("Stopping Binance WebSocket Connector...")
        self._is_running = False
        self.config_manager.unregister_callback(self._handle_config_update)
        for market_type, ws in list(self._ws_connections.items()): # Iterate over a copy
            if ws and ws.open:
                logger.info(f"Closing WebSocket connection for {market_type}...")
                await ws.close()
        self._ws_connections.clear()
        
        # Cancel and await pending tasks
        for task in self._tasks:
            if not task.done():
                task.cancel()
        
        if self._tasks:
            results = await asyncio.gather(*self._tasks, return_exceptions=True)
            for i, result in enumerate(results):
                if isinstance(result, asyncio.CancelledError):
                    logger.debug(f"Task {self._tasks[i]} was cancelled.")
                elif isinstance(result, Exception):
                    logger.error(f"Task {self._tasks[i]} raised an exception during stop: {result}")
        self._tasks.clear()
        logger.info("Binance WebSocket Connector stopped.")




================================================
FILE: src/data_processor.py
================================================
import pandas as pd
from collections import deque, defaultdict
import logging
from typing import Dict, Deque, Optional, List, Tuple, Callable

from src.models import Kline
from src.config_loader import ConfigManager
from src.connectors import convert_symbol_to_api_format # For consistent symbol usage

logger = logging.getLogger(__name__)

# Define a maximum length for k-line deques to prevent memory issues
# Needs to be at least max(sma_long_period) + some buffer for calculations
# For SMA 200, we need at least 200 candles. Let's use a bit more.
MAX_KLINE_BUFFER_LENGTH = 300 

class DataProcessor:
    def __init__(self, config_manager: ConfigManager):
        self.config_manager = config_manager
        # Structure: self.kline_buffers[api_symbol][interval] = deque([Kline, ...])
        self.kline_buffers: Dict[str, Dict[str, Deque[Kline]]] = defaultdict(lambda: defaultdict(lambda: deque(maxlen=MAX_KLINE_BUFFER_LENGTH)))
        # Structure: self.indicator_data[api_symbol][interval] = pd.DataFrame with columns [timestamp, open, high, low, close, volume, sma_short, sma_long]
        self.indicator_data: Dict[str, Dict[str, pd.DataFrame]] = defaultdict(lambda: defaultdict(pd.DataFrame))
        
        self.config_manager.register_callback(self._handle_config_update) # Listen for config changes
        self._active_pairs_timeframes: Dict[str, List[str]] = {}
        self._initialize_buffers_from_config()

    def _handle_config_update(self, new_config: Dict):
        logger.info("DataProcessor: Configuration updated. Re-initializing buffers and settings.")
        self._initialize_buffers_from_config(new_config)

    def _initialize_buffers_from_config(self, config: Optional[Dict] = None):
        if config is None:
            config = self.config_manager.get_config()
        
        new_active_pairs_timeframes: Dict[str, List[str]] = {}
        pairs_config = config.get("pairs", {})
        global_settings = config.get("global_settings", {})
        default_timeframes = global_settings.get("v1_strategy", {}).get("indicator_timeframes", ["1m"])

        for pair_symbol_config, pair_details in pairs_config.items():
            if pair_details.get("enabled", False):
                api_symbol = convert_symbol_to_api_format(pair_symbol_config)
                timeframes_for_pair = pair_details.get("indicator_timeframes", default_timeframes)
                new_active_pairs_timeframes[api_symbol] = timeframes_for_pair
                # Ensure buffers exist for newly active pairs/timeframes
                for tf in timeframes_for_pair:
                    if tf not in self.kline_buffers[api_symbol]:
                        self.kline_buffers[api_symbol][tf] = deque(maxlen=MAX_KLINE_BUFFER_LENGTH)
                    if tf not in self.indicator_data[api_symbol]:
                        self.indicator_data[api_symbol][tf] = pd.DataFrame()
        
        # Cleanup buffers for pairs/timeframes that are no longer active (optional, to save memory)
        # For simplicity, we are not removing old buffers now, but this could be added.
        self._active_pairs_timeframes = new_active_pairs_timeframes
        logger.debug(f"DataProcessor initialized/updated for pairs and timeframes: {self._active_pairs_timeframes}")

    async def process_kline(self, kline: Kline, market_type: Optional[str] = None):
        """ Process an incoming Kline object. market_type is for context if needed. """
        api_symbol = kline.symbol # Assuming kline.symbol is already in API format (e.g., BTCUSDT)
        interval = kline.interval

        if api_symbol not in self._active_pairs_timeframes or interval not in self._active_pairs_timeframes.get(api_symbol, []):
            # logger.debug(f"Skipping kline for inactive pair/timeframe: {api_symbol} {interval}")
            return

        # Add to deque. If it's an update to the last candle, replace it.
        # Kline data from Binance WS usually gives the current (non-closed) candle and then the closed one.
        # We are interested in closed candles for SMA calculation primarily.
        
        buffer = self.kline_buffers[api_symbol][interval]
        if kline.is_closed:
            if buffer and buffer[-1].timestamp == kline.timestamp:
                if not buffer[-1].is_closed:
                    buffer[-1] = kline # Replace the non-closed one with the closed one
            else:
                buffer.append(kline)
            self._update_indicators(api_symbol, interval)
        else: # Kline is not closed (current, ongoing candle)
            if buffer and buffer[-1].timestamp == kline.timestamp:
                buffer[-1] = kline # Update the last (current) candle
            else:
                buffer.append(kline) # Add as new current candle

    def _update_indicators(self, api_symbol: str, interval: str):
        kline_deque = self.kline_buffers[api_symbol][interval]
        if not kline_deque:
            return
        
        df_data = {
            "timestamp": [k.timestamp for k in kline_deque],
            "open": [k.open for k in kline_deque],
            "high": [k.high for k in kline_deque],
            "low": [k.low for k in kline_deque],
            "close": [k.close for k in kline_deque],
            "volume": [k.volume for k in kline_deque],
            "is_closed": [k.is_closed for k in kline_deque]
        }
        df = pd.DataFrame(df_data)
        df.set_index("timestamp", inplace=True, drop=False) # Keep timestamp column too
        df.sort_index(inplace=True) # Ensure time order
        df = df[~df.index.duplicated(keep="last")] # Remove duplicate timestamps, keep last update

        if df.empty:
            return

        config = self.config_manager.get_config()
        sma_short_period = config.get("global_settings", {}).get("v1_strategy", {}).get("sma_short_period", 21)
        sma_long_period = config.get("global_settings", {}).get("v1_strategy", {}).get("sma_long_period", 200)

        if len(df) >= sma_short_period:
            df["sma_short"] = df["close"].rolling(window=sma_short_period).mean()
        else:
            df["sma_short"] = pd.NA

        if len(df) >= sma_long_period:
            df["sma_long"] = df["close"].rolling(window=sma_long_period).mean()
        else:
            df["sma_long"] = pd.NA
        
        self.indicator_data[api_symbol][interval] = df

    def get_latest_kline(self, api_symbol: str, interval: str) -> Optional[Kline]:
        if api_symbol in self.kline_buffers and interval in self.kline_buffers[api_symbol]:
            if self.kline_buffers[api_symbol][interval]:
                return self.kline_buffers[api_symbol][interval][-1]
        return None

    def get_indicator_dataframe(self, api_symbol: str, interval: str) -> Optional[pd.DataFrame]:
        if api_symbol in self.indicator_data and interval in self.indicator_data[api_symbol]:
            return self.indicator_data[api_symbol][interval].copy() # Return a copy
        return None

    def get_latest_indicators(self, api_symbol: str, interval: str) -> Optional[pd.Series]:
        df = self.get_indicator_dataframe(api_symbol, interval)
        if df is not None and not df.empty:
            return df.iloc[-1]
        return None




================================================
FILE: src/main.py
================================================
import asyncio
import logging
import signal
import os
from typing import Optional

# Let's use absolute imports to be consistent and avoid potential issues
from src.config_loader import ConfigManager
from src.connectors import BinanceRESTClient, BinanceWebSocketConnector, convert_symbol_to_api_format
from src.data_processor import DataProcessor
from src.signal_engine import SignalEngineV1
from src.order_manager import OrderManager
from src.position_manager import PositionManager
from src.models import Kline, Order, TradeSignal  # For type hinting
# from src.monitoring import PrometheusMonitor # If implementing Prometheus

# Setup basic logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.StreamHandler(),
        # logging.FileHandler("app.log") # Add file handler if needed from config
    ]
)
logger = logging.getLogger("main_app")

class TradingBot:
    def __init__(self) -> None:
        self.config_manager = ConfigManager()
        self._configure_logging()
        
        self.rest_client = BinanceRESTClient(config_manager=self.config_manager)
        self.position_manager = PositionManager(config_manager=self.config_manager)
        self.order_manager = OrderManager(config_manager=self.config_manager, rest_client=self.rest_client)
        # Note: PositionManager updates rely on user data stream (to be implemented) or periodic reconciliation
        # Direct linking could be done if needed: self.order_manager.position_manager = self.position_manager

        self.data_processor = DataProcessor(config_manager=self.config_manager)
        self.ws_connector = BinanceWebSocketConnector(
            config_manager=self.config_manager, 
            kline_callback=self._handle_kline_data
        )
        self.signal_engine_v1 = SignalEngineV1(config_manager=self.config_manager, data_processor=self.data_processor)
        
        self.running = False
        self.active_trading_pairs = []  # List of config_symbols (e.g. BTC_USDT)

        self.config_manager.register_callback(self._handle_app_config_update)

    def _configure_logging(self) -> None:
        """Configure logging based on settings from config."""
        log_level_str = self.config_manager.get_specific_config("logging.level", "INFO").upper()
        log_level = getattr(logging, log_level_str, logging.INFO)
        logging.getLogger().setLevel(log_level)  # Set root logger level
        for handler in logging.getLogger().handlers:
            handler.setLevel(log_level)
        logger.info(f"Logging level set to {log_level_str}")
        # TODO: Add file logging based on config if specified

    async def _handle_kline_data(self, kline: Kline, market_type: str) -> None:
        """
        Process incoming kline data from WebSocket and trigger signal checks when appropriate.
        Includes error handling to prevent WebSocket callback crashes.
        """
        try:
            # Process the kline data through DataProcessor
            await self.data_processor.process_kline(kline, market_type)
        except Exception as e:
            logger.error(f"Error processing kline for {kline.symbol}: {e}", exc_info=True)
            return  # Skip signal check if data processing fails

        # For V1, only check signals on closed 1m candles
        if kline.interval == "1m" and kline.is_closed:
            try:
                # Find the config_symbol corresponding to kline.symbol (API format)
                config = self.config_manager.get_config()
                target_config_symbol = None
                for cfg_sym, details in config.get("pairs", {}).items():
                    if convert_symbol_to_api_format(cfg_sym) == kline.symbol and details.get("enabled"):
                        target_config_symbol = cfg_sym
                        break
                
                if not target_config_symbol:
                    return  # No enabled config symbol found for this API symbol
                
                # Check if a position is already open for this symbol
                if not self.position_manager.has_open_position(kline.symbol):
                    signal = await self.signal_engine_v1.check_signal(kline.symbol, target_config_symbol)
                    if signal:
                        logger.info(f"Signal generated for {signal.symbol}: {signal.direction.value}")
                        # Double check no position exists
                        if not self.position_manager.has_open_position(signal.symbol):
                            try:
                                await self.order_manager.handle_trade_signal(signal)
                                logger.info(f"Signal processed by OrderManager. Position tracking update will be handled via reconciliation or user data stream.")
                                # Note: In the current architecture, position updates rely on:
                                # 1. User data stream (to be implemented in future)
                                # 2. Periodic reconciliation
                            except Exception as e:
                                logger.error(f"Error handling trade signal for {signal.symbol}: {e}", exc_info=True)
                        else:
                            logger.info(f"Signal for {signal.symbol} ignored, position already open.")
                else:
                    logger.debug(f"Skipping signal check for {kline.symbol}, position already open.")
            except Exception as e:
                logger.error(f"Error during signal processing for {kline.symbol}: {e}", exc_info=True)

    async def _handle_order_update_data(self, order_data: Order) -> None:
        """Handle order updates from user data stream (to be implemented)."""
        logger.info(f"Main: Received order update: {order_data.symbol} ID {order_data.order_id} Status {order_data.status}")
        try:
            await self.position_manager.update_position_on_order_update(order_data)
        except Exception as e:
            logger.error(f"Error updating position based on order update: {e}", exc_info=True)

    def _handle_app_config_update(self, new_config: dict) -> None:
        """Handle configuration updates affecting the main application."""
        logger.info("MainApp: Detected configuration change. Applying updates...")
        self._configure_logging()  # Update log level if changed
        
        # Update active trading pairs
        self.active_trading_pairs = [
            cfg_sym for cfg_sym, details in new_config.get("pairs", {}).items() if details.get("enabled")
        ]
        logger.info(f"Updated active trading pairs: {self.active_trading_pairs}")

    async def start(self) -> None:
        """Start the trading bot and all its components."""
        if self.running:
            logger.warning("Bot is already running.")
            return
        
        logger.info("Starting Binance Futures Trading Bot...")
        self.running = True

        # Initial config load for active pairs
        self._handle_app_config_update(self.config_manager.get_config())

        # Reconcile positions with exchange on startup
        logger.info("Reconciling positions with exchange on startup...")
        try:
            await self.position_manager.reconcile_positions_with_exchange(self.rest_client)
            logger.info("Position reconciliation completed.")
        except Exception as e:
            logger.error(f"Error during position reconciliation: {e}", exc_info=True)

        # Start WebSocket connector
        try:
            await self.ws_connector.start()
            logger.info("WebSocket connector started successfully.")
        except Exception as e:
            logger.error(f"Failed to start WebSocket connector: {e}", exc_info=True)
            self.running = False
            return

        logger.info("Bot is now running. Press Ctrl+C to stop.")
        
        # Main event loop - keep the application alive
        try:
            while self.running:
                await asyncio.sleep(1)
        except asyncio.CancelledError:
            logger.info("Main bot loop cancelled.")

    async def stop(self) -> None:
        """Stop the trading bot and all its components gracefully."""
        if not self.running:
            logger.info("Bot is not running.")
            return
        
        logger.info("Stopping Binance Futures Trading Bot...")
        self.running = False

        # Stop WebSocket connector
        if self.ws_connector:
            try:
                await self.ws_connector.stop()
                logger.info("WebSocket connector stopped successfully.")
            except Exception as e:
                logger.error(f"Error stopping WebSocket connector: {e}", exc_info=True)
        
        # Close REST client connection
        if self.rest_client:
            try:
                await self.rest_client.close_exchange()
                logger.info("REST client closed successfully.")
            except Exception as e:
                logger.error(f"Error closing REST client: {e}", exc_info=True)

        # Stop config watcher
        if self.config_manager:
            try:
                self.config_manager.stop_watcher()
                logger.info("Config manager watcher stopped successfully.")
            except Exception as e:
                logger.error(f"Error stopping config watcher: {e}", exc_info=True)
        
        logger.info("Bot has stopped.")


def handle_sigterm(sig, frame) -> None:
    """
    Handle SIGTERM signal for graceful shutdown.
    Only sets the running flag to False, letting the main loop handle the actual shutdown.
    """
    logger.info("SIGTERM received, initiating graceful shutdown...")
    # Simply set the running flag to False
    if "bot_instance" in globals() and bot_instance:
        bot_instance.running = False
    else:
        logger.warning("Bot instance not found for SIGTERM handler.")

async def main() -> None:
    """Main entry point for the application."""
    global bot_instance  # Make bot instance accessible to signal handler
    bot_instance = None
    
    try:
        bot_instance = TradingBot()
        
        # Register signal handlers for graceful shutdown
        signal.signal(signal.SIGTERM, handle_sigterm)
        
        await bot_instance.start()
    except KeyboardInterrupt:
        logger.info("KeyboardInterrupt received, stopping bot...")
    except Exception as e:
        logger.error(f"Unhandled exception in main: {e}", exc_info=True)
    finally:
        if bot_instance and bot_instance.running:
            await bot_instance.stop()

if __name__ == "__main__":
    # Ensure a config file exists for the bot to run, copy from example if not
    # ConfigManager handles this internally now.
    asyncio.run(main())




================================================
FILE: src/models.py
================================================
from typing import Optional, List, Dict, Any, Literal
from pydantic import BaseModel, Field, validator
import time
from enum import Enum

# Enum for trade direction
class TradeDirection(str, Enum):
    LONG = "BUY"
    SHORT = "SELL"

class Kline(BaseModel):
    timestamp: int # Kline start time in milliseconds
    open: float
    high: float
    low: float
    close: float
    volume: float
    quote_asset_volume: Optional[float] = None # Volume in quote asset
    number_of_trades: Optional[int] = None
    is_closed: bool # True if this kline is closed
    symbol: Optional[str] = None # Trading pair symbol, e.g., BTCUSDT
    interval: Optional[str] = None # Kline interval, e.g., 1m, 5m, 1h

class PairConfig(BaseModel):
    enabled: bool = True
    symbol: str # e.g. BTC_USDT (config format), will be converted for API/WS
    contract_type: Literal["USDT_M", "COIN_M"] = "USDT_M"

    # V1 Strategy specific (can be overridden from global)
    sma_short_period: Optional[int] = None
    sma_long_period: Optional[int] = None
    min_signal_interval_minutes: Optional[int] = None
    tp_sl_ratio: Optional[float] = None
    margin_usdt: Optional[float] = None # For USDT-M
    margin_coin: Optional[float] = None # For COIN-M, in base currency units
    leverage: Optional[int] = None
    margin_mode: Optional[Literal["ISOLATED", "CROSSED"]] = None

    # V2 Strategy specific (can be overridden from global)
    strategy_v2_enabled: Optional[bool] = None
    # ... other V2 params like ema_short_period_1m, stochrsi_k_1m etc.

    # Filter overrides
    volume_filter_enabled: Optional[bool] = None
    # ... other filter params ...

    # Risk management overrides
    dynamic_sizing_enabled: Optional[bool] = None
    risk_percent_per_trade: Optional[float] = None

    @validator("symbol")
    def symbol_format(cls, value):
        # Basic validation, can be expanded
        if "_" in value:
            # BTC_USDT format is valid
            pass
        elif value.endswith("PERP"):
            # BTCUSD_PERP format is valid
            pass
        else:
            # Neither BTC_USDT nor ending with PERP
            raise ValueError("Symbol in config should generally be in format BASE_QUOTE, e.g., BTC_USDT or end with PERP for COIN-M e.g. BTCUSD_PERP")
        return value

class TradeSignal(BaseModel):
    timestamp: int = Field(default_factory=lambda: int(time.time() * 1000))
    symbol: str # e.g., BTCUSDT (API format)
    config_symbol: str # e.g., BTC_USDT (Config format, for logging/reference)
    contract_type: Literal["USDT_M", "COIN_M"]
    direction: TradeDirection
    entry_price: float # Estimated entry price at signal time (e.g., current close)
    stop_loss_price: float
    take_profit_price: float
    strategy_name: str = "V1_SMA_Crossover" # Or V2_MultiTF_EMA, etc.
    signal_kline: Optional[Kline] = None # The kline that triggered the signal
    details: Optional[Dict[str, Any]] = None # e.g., SMA values, pivot points used for SL

class OrderStatus(str, Enum):
    NEW = "NEW"
    PARTIALLY_FILLED = "PARTIALLY_FILLED"
    FILLED = "FILLED"
    CANCELED = "CANCELED"
    PENDING_CANCEL = "PENDING_CANCEL" 
    REJECTED = "REJECTED"
    EXPIRED = "EXPIRED"

class OrderType(str, Enum):
    LIMIT = "LIMIT"
    MARKET = "MARKET"
    STOP_LOSS = "STOP_LOSS" 
    STOP_LOSS_LIMIT = "STOP_LOSS_LIMIT" 
    TAKE_PROFIT = "TAKE_PROFIT" 
    TAKE_PROFIT_LIMIT = "TAKE_PROFIT_LIMIT" 
    LIMIT_MAKER = "LIMIT_MAKER"
    STOP = "STOP" 
    STOP_MARKET = "STOP_MARKET"
    TAKE_PROFIT_MARKET = "TAKE_PROFIT_MARKET"
    TRAILING_STOP_MARKET = "TRAILING_STOP_MARKET"

class OrderSide(str, Enum):
    BUY = "BUY"
    SELL = "SELL"

class Order(BaseModel):
    order_id: str # Exchange order ID
    client_order_id: Optional[str] = None # Custom order ID
    symbol: str # API format, e.g., BTCUSDT
    type: OrderType
    side: OrderSide
    quantity: float # Order quantity
    price: Optional[float] = None # For LIMIT orders
    stop_price: Optional[float] = None # For STOP_MARKET, TAKE_PROFIT_MARKET etc.
    status: OrderStatus
    timestamp: int # Order creation/update timestamp (milliseconds)
    avg_fill_price: Optional[float] = None
    filled_quantity: Optional[float] = None
    reduce_only: Optional[bool] = False
    commission: Optional[float] = None
    commission_asset: Optional[str] = None

class Position(BaseModel):
    symbol: str # API format, e.g., BTCUSDT
    contract_type: Literal["USDT_M", "COIN_M"]
    side: TradeDirection # LONG or SHORT
    entry_price: float
    quantity: float # Size of the position
    margin_type: Optional[Literal["ISOLATED", "CROSSED"]] = None
    leverage: Optional[int] = None
    unrealized_pnl: Optional[float] = None
    liquidation_price: Optional[float] = None
    mark_price: Optional[float] = None
    entry_timestamp: int = Field(default_factory=lambda: int(time.time() * 1000))
    entry_order_id: Optional[str] = None
    sl_order_id: Optional[str] = None
    tp_order_id: Optional[str] = None
    current_sl_price: Optional[float] = None
    current_tp_price: Optional[float] = None
    trailing_sl_active: Optional[bool] = False

# Example usage (not part of the module, just for illustration)
if __name__ == "__main__":
    kline_data = {
        "timestamp": int(time.time() * 1000),
        "open": 40000.0, "high": 40100.0, "low": 39900.0, "close": 40050.0,
        "volume": 100.0, "is_closed": True, "symbol": "BTCUSDT", "interval": "1m"
    }
    kline_obj = Kline(**kline_data)
    print(f"Kline: {kline_obj.json(indent=2)}")

    pair_cfg_data = {"symbol": "BTC_USDT", "leverage": 20, "margin_usdt": 100}
    pair_cfg_obj = PairConfig(**pair_cfg_data)
    print(f"PairConfig: {pair_cfg_obj.json(indent=2)}")

    signal_data = {
        "symbol": "BTCUSDT", "config_symbol": "BTC_USDT", "contract_type": "USDT_M",
        "direction": TradeDirection.LONG, "entry_price": 40050.0,
        "stop_loss_price": 39800.0, "take_profit_price": 40800.0,
        "details": {"sma_short": 40020, "sma_long": 40000}
    }
    signal_obj = TradeSignal(**signal_data)
    print(f"TradeSignal: {signal_obj.json(indent=2)}")

    order_data = {
        "order_id": "12345", "symbol": "BTCUSDT", "type": OrderType.MARKET, "side": OrderSide.BUY,
        "quantity": 0.001, "status": OrderStatus.FILLED, "timestamp": int(time.time() * 1000),
        "avg_fill_price": 40055.0, "filled_quantity": 0.001
    }
    order_obj = Order(**order_data)
    print(f"Order: {order_obj.json(indent=2)}")

    position_data = {
        "symbol": "BTCUSDT", "contract_type": "USDT_M", "side": TradeDirection.LONG, "entry_price": 40055.0,
        "quantity": 0.001, "leverage": 20, "margin_type": "ISOLATED"
    }
    position_obj = Position(**position_data)
    print(f"Position: {position_obj.json(indent=2)}")




================================================
FILE: src/monitoring.py
================================================
from prometheus_client import start_http_server, Counter, Gauge, Enum, Info
import time
import logging
import asyncio

logger = logging.getLogger(__name__)

class PrometheusMonitor:
    def __init__(self, port: int = 8000):
        self.port = port
        self.start_time = time.time()

        # --- General Metrics ---
        self.bot_info = Info(
            "trading_bot_info", 
            "Information about the trading bot"
        )
        self.bot_uptime_seconds = Gauge(
            "trading_bot_uptime_seconds", 
            "Time in seconds since the bot started"
        )
        self.bot_errors_total = Counter(
            "trading_bot_errors_total", 
            "Total number of critical errors encountered by the bot",
            ["module", "error_type"]
        )

        # --- WebSocket Metrics ---
        self.websocket_connection_status = Enum(
            "trading_bot_websocket_connection_status",
            "Status of the WebSocket connection",
            ["market_type"], # e.g., USDT_M, COIN_M
            states=["connected", "disconnected", "connecting", "error"]
        )
        self.websocket_messages_received_total = Counter(
            "trading_bot_websocket_messages_received_total",
            "Total number of messages received via WebSocket",
            ["market_type", "message_type"] # e.g., kline, depthUpdate, userData
        )

        # --- Data Processing Metrics ---
        self.kline_processed_total = Counter(
            "trading_bot_klines_processed_total",
            "Total number of klines processed",
            ["symbol", "interval"]
        )
        self.indicator_calculation_duration_seconds = Gauge(
            "trading_bot_indicator_calculation_duration_seconds",
            "Duration of the last indicator calculation cycle",
            ["symbol", "interval"]
        )

        # --- Signal Engine Metrics ---
        self.signals_generated_total = Counter(
            "trading_bot_signals_generated_total",
            "Total number of trade signals generated",
            ["symbol", "strategy", "direction"] # e.g., BTCUSDT, V1_SMA, LONG
        )

        # --- Order Management Metrics ---
        self.orders_placed_total = Counter(
            "trading_bot_orders_placed_total",
            "Total number of orders placed",
            ["symbol", "order_type", "side"]
        )
        self.orders_failed_total = Counter(
            "trading_bot_orders_failed_total",
            "Total number of orders that failed to place or were rejected",
            ["symbol", "reason"]
        )
        self.orders_filled_total = Counter(
            "trading_bot_orders_filled_total",
            "Total number of orders filled",
            ["symbol", "order_type", "side"]
        )

        # --- Position Management Metrics ---
        self.active_positions_count = Gauge(
            "trading_bot_active_positions_count",
            "Current number of active positions",
            ["contract_type"] # USDT_M, COIN_M
        )
        self.position_pnl_unrealized = Gauge(
            "trading_bot_position_pnl_unrealized",
            "Unrealized PnL for an active position",
            ["symbol"]
        )

        self._server_started = False

    def start(self):
        if self._server_started:
            logger.warning("Prometheus metrics server already started.")
            return
        try:
            start_http_server(self.port)
            self._server_started = True
            logger.info(f"Prometheus metrics server started on port {self.port}")
            # Set initial info
            self.bot_info.info({"version": "0.1.0-mvp", "name": "BinanceFuturesBot"})
            # Start periodic update of uptime
            asyncio.create_task(self._update_uptime_periodically())
        except OSError as e:
            logger.error(f"Could not start Prometheus server on port {self.port}: {e}. Metrics will not be available.")
        except Exception as e:
            logger.error(f"An unexpected error occurred while starting Prometheus server: {e}")

    async def _update_uptime_periodically(self):
        while self._server_started: # Or a separate running flag for the task
            self.bot_uptime_seconds.set(time.time() - self.start_time)
            await asyncio.sleep(5) # Update every 5 seconds

    def stop(self):
        # The prometheus_client library doesn\t provide a direct way to stop the HTTP server cleanly.
        # It runs in a separate daemon thread. For a real production app, this might need a custom server.
        # For this project, we assume the process termination will handle it.
        logger.info("Prometheus metrics server stopping (typically handled by process exit).")
        self._server_started = False # To stop uptime updates

    # --- Helper methods to update metrics ---
    def inc_bot_error(self, module: str, error_type: str = "general"):
        self.bot_errors_total.labels(module=module, error_type=error_type).inc()

    def set_websocket_status(self, market_type: str, status: str):
        # Ensure status is one of the Enum states
        valid_states = self.websocket_connection_status._states
        if status not in valid_states:
            logger.warning(f"Invalid WebSocket status 	{status}	 for market 	{market_type}	. Valid states: {valid_states}")
            self.websocket_connection_status.labels(market_type=market_type).state("error")
            return
        self.websocket_connection_status.labels(market_type=market_type).state(status)

    def inc_websocket_message(self, market_type: str, message_type: str):
        self.websocket_messages_received_total.labels(market_type=market_type, message_type=message_type).inc()

    def inc_kline_processed(self, symbol: str, interval: str):
        self.kline_processed_total.labels(symbol=symbol, interval=interval).inc()

    def set_indicator_calculation_duration(self, symbol: str, interval: str, duration_seconds: float):
        self.indicator_calculation_duration_seconds.labels(symbol=symbol, interval=interval).set(duration_seconds)

    def inc_signal_generated(self, symbol: str, strategy: str, direction: str):
        self.signals_generated_total.labels(symbol=symbol, strategy=strategy, direction=direction).inc()

    def inc_order_placed(self, symbol: str, order_type: str, side: str):
        self.orders_placed_total.labels(symbol=symbol, order_type=order_type, side=side).inc()

    def inc_order_failed(self, symbol: str, reason: str = "unknown"):
        self.orders_failed_total.labels(symbol=symbol, reason=reason).inc()

    def inc_order_filled(self, symbol: str, order_type: str, side: str):
        self.orders_filled_total.labels(symbol=symbol, order_type=order_type, side=side).inc()

    def set_active_positions_count(self, contract_type: str, count: int):
        self.active_positions_count.labels(contract_type=contract_type).set(count)
    
    def update_active_positions_gauge(self, positions_usdt_m: int, positions_coin_m: int):
        self.set_active_positions_count(contract_type="USDT_M", count=positions_usdt_m)
        self.set_active_positions_count(contract_type="COIN_M", count=positions_coin_m)

    def set_position_pnl(self, symbol: str, pnl: float):
        self.position_pnl_unrealized.labels(symbol=symbol).set(pnl)

# Example Usage (typically integrated into main_app.py)
async def main_monitor_test():
    logging.basicConfig(level=logging.INFO)
    monitor = PrometheusMonitor(port=8088) # Use a different port for testing
    monitor.start()

    # Simulate some bot activity
    monitor.set_websocket_status(market_type="USDT_M", status="connecting")
    await asyncio.sleep(1)
    monitor.set_websocket_status(market_type="USDT_M", status="connected")
    monitor.inc_websocket_message(market_type="USDT_M", message_type="kline")
    monitor.inc_kline_processed(symbol="BTCUSDT", interval="1m")
    monitor.set_indicator_calculation_duration(symbol="BTCUSDT", interval="1m", duration_seconds=0.05)
    monitor.inc_signal_generated(symbol="BTCUSDT", strategy="V1_SMA", direction="LONG")
    monitor.inc_order_placed(symbol="BTCUSDT", order_type="MARKET", side="BUY")
    monitor.inc_order_filled(symbol="BTCUSDT", order_type="MARKET", side="BUY")
    monitor.set_active_positions_count(contract_type="USDT_M", count=1)
    monitor.set_position_pnl(symbol="BTCUSDT", pnl=10.5)
    monitor.inc_bot_error(module="SignalEngine", error_type="DataMissing")

    try:
        while True:
            # Uptime is updated automatically by the monitor itself
            await asyncio.sleep(10)
            logger.info("Monitor test running... check http://localhost:8088/metrics")
    except KeyboardInterrupt:
        logger.info("Stopping monitor test...")
    finally:
        monitor.stop()

if __name__ == "__main__":
    asyncio.run(main_monitor_test())



================================================
FILE: src/order_manager.py
================================================
import logging
import asyncio
import time
from typing import Optional, Dict, Any, Tuple
import math
from decimal import Decimal, ROUND_DOWN, getcontext

from src.config_loader import ConfigManager
from src.connectors import BinanceRESTClient, convert_symbol_to_api_format
from src.models import TradeSignal, Order, OrderStatus, OrderType, OrderSide, Position, TradeDirection
# from src.position_manager import PositionManager # Will be used later

logger = logging.getLogger(__name__)

class OrderManager:
    def __init__(self, config_manager: ConfigManager, rest_client: BinanceRESTClient):
        self.config_manager = config_manager
        self.rest_client = rest_client
        # self.position_manager = position_manager # To notify about new positions/orders
        self.exchange_info_cache: Dict[str, Any] = {}

    async def _get_exchange_info_for_symbol(self, api_symbol: str) -> Optional[Dict[str, Any]]:
        if api_symbol in self.exchange_info_cache:
            return self.exchange_info_cache[api_symbol]
        
        markets = await self.rest_client.fetch_exchange_info()
        if markets:
            for market_symbol, market_data in markets.items():
                # ccxt market symbols are usually already in API format (e.g., BTCUSDT)
                # We store all of them for potential future use
                self.exchange_info_cache[market_symbol] = market_data 
            
            if api_symbol in self.exchange_info_cache:
                return self.exchange_info_cache[api_symbol]
            else:
                # Try variations if direct match fails (e.g. if input was BTC/USDT vs BTCUSDT)
                # This part might need refinement based on how symbols are consistently handled.
                normalized_api_symbol = api_symbol.replace("/","")
                if normalized_api_symbol in self.exchange_info_cache:
                    return self.exchange_info_cache[normalized_api_symbol]
                logger.warning(f"Exchange info not found for symbol {api_symbol} after fetching markets.")
                return None
        logger.error(f"Failed to fetch exchange info.")
        return None

    def _adjust_quantity_to_precision(self, quantity: float, step_size: float) -> float:
        """Adjusts quantity to the nearest multiple of step_size (floors the value)."""
        if step_size == 0: return quantity # Avoid division by zero if step_size is not set
        
        # Special case for very small step sizes like 0.00001
        if step_size < 0.0001:
            # Convert to string representation for exactness
            step_str = str(step_size)
            precision = len(step_str.split(".")[1]) if "." in step_str else 0
            
            # For very precise step sizes, use decimal module 
            from decimal import Decimal, ROUND_DOWN
            dec_quantity = Decimal(str(quantity))
            dec_step = Decimal(str(step_size))
            
            # Calculate floor division
            steps = dec_quantity / dec_step
            floored_steps = steps.to_integral_exact(rounding=ROUND_DOWN)
            result = floored_steps * dec_step
            
            return float(result)
        
        # For normal step sizes, use regular float math
        return math.floor(quantity / step_size) * step_size

    def _adjust_price_to_precision(self, price: float, tick_size: float) -> float:
        if tick_size == 0: return price
        precision = 0
        if "." in str(tick_size):
            precision = len(str(tick_size).split(".")[1].rstrip("0"))
        else:
            precision = 0
        # For price, usually round to nearest tick_size. Behavior might differ (round, ceil, floor)
        # Let's round for now.
        adjusted_price = round(round(price / tick_size) * tick_size, precision) if precision > 0 else int(round(price / tick_size) * tick_size)
        return adjusted_price

    async def _get_symbol_filters(self, api_symbol: str) -> Tuple[Optional[float], Optional[float], Optional[float]]:
        """ Returns (lot_step_size, price_tick_size, min_notional) """
        market_info = await self._get_exchange_info_for_symbol(api_symbol)
        if not market_info:
            logger.warning(f"Cannot get filters for {api_symbol}, market info not found.")
            return None, None, None

        lot_step_size = None
        price_tick_size = None
        min_notional = None

        try:
            # CCXT structure for precision and limits:
            # market_info["precision"]["amount"] -> quantity precision (step size)
            # market_info["precision"]["price"] -> price precision (tick size)
            # market_info["limits"]["cost"]["min"] -> min notional value
            # market_info["limits"]["amount"]["min"] -> min quantity

            if market_info.get("precision") and market_info["precision"].get("amount") is not None:
                # Handle both string and float formats
                amount_value = market_info["precision"]["amount"]
                lot_step_size = float(amount_value)
            
            if market_info.get("precision") and market_info["precision"].get("price") is not None:
                # Handle both string and float formats
                price_value = market_info["precision"]["price"]
                price_tick_size = float(price_value)

            if market_info.get("limits", {}).get("cost", {}).get("min") is not None:
                # Handle both string and float formats
                min_value = market_info["limits"]["cost"]["min"]
                min_notional = float(min_value)
            elif market_info.get("info", {}).get("filters"):
                # Fallback for direct Binance API structure if ccxt doesn't normalize it fully
                for f in market_info["info"]["filters"]:
                    if f["filterType"] == "LOT_SIZE":
                        lot_step_size = float(f["stepSize"])
                    elif f["filterType"] == "PRICE_FILTER":
                        price_tick_size = float(f["tickSize"])
                    elif f["filterType"] == "MIN_NOTIONAL":
                        min_notional = float(f.get("notional", f.get("minNotional"))) # Binance uses "notional" or "minNotional"
            
            # Log warnings if any filters are missing
            if lot_step_size is None: logger.warning(f"Lot step size not found for {api_symbol}")
            if price_tick_size is None: logger.warning(f"Price tick size not found for {api_symbol}")
            if min_notional is None: logger.warning(f"Min notional not found for {api_symbol}")

        except (KeyError, ValueError, TypeError) as e:
            logger.error(f"Error accessing filter info for {api_symbol}: {e}. Market info: {market_info}")
            return None, None, None
        except Exception as e:
            logger.error(f"Error parsing filters for {api_symbol}: {e}. Market info: {market_info}")
            return None, None, None
            
        return lot_step_size, price_tick_size, min_notional

    async def handle_trade_signal(self, signal: TradeSignal):
        logger.info(f"OrderManager received signal: {signal.symbol} {signal.direction.value} at {signal.entry_price}")
        config = self.config_manager.get_config()
        pair_configs = config.get("pairs", {})
        global_v1_config = config.get("global_settings", {}).get("v1_strategy", {})
        api_symbol = signal.symbol # Already in API format from signal

        pair_details = {}
        for cfg_sym, details in pair_configs.items():
            if convert_symbol_to_api_format(cfg_sym) == api_symbol:
                pair_details = details
                break
        
        if not pair_details:
            logger.error(f"No configuration found for symbol {api_symbol} in OrderManager.")
            return

        # 1. Set Margin Type and Leverage
        margin_mode = pair_details.get("margin_mode", global_v1_config.get("margin_mode", "ISOLATED"))
        leverage = pair_details.get("leverage", global_v1_config.get("default_leverage", 10))

        # These calls might not be needed if already set and not changing per trade.
        # However, good practice to ensure they are as expected.
        # await self.rest_client.set_margin_mode(api_symbol, margin_mode)
        # await self.rest_client.set_leverage(api_symbol, leverage)
        # For now, assume they are pre-set or handle this in a setup phase.
        # logger.info(f"Ensured margin mode {margin_mode} and leverage {leverage}x for {api_symbol}")

        # 2. Calculate Position Size (MVP: Fixed Margin Allocation)
        # TODO: Implement dynamic position sizing later
        fixed_margin_usdt = pair_details.get("margin_usdt", global_v1_config.get("default_margin_usdt"))
        fixed_margin_coin = pair_details.get("margin_coin") # For COIN-M
        entry_price = signal.entry_price
        quantity: Optional[float] = None

        lot_step, price_tick, min_notional_val = await self._get_symbol_filters(api_symbol)
        if lot_step is None or price_tick is None:
            logger.error(f"Could not get precision filters for {api_symbol}. Aborting trade.")
            return

        if signal.contract_type == "USDT_M":
            if fixed_margin_usdt and entry_price > 0:
                quantity_raw = (fixed_margin_usdt * leverage) / entry_price
                quantity = self._adjust_quantity_to_precision(quantity_raw, lot_step)
            else:
                logger.error(f"Invalid fixed_margin_usdt or entry_price for {api_symbol} (USDT-M).")
                return
        elif signal.contract_type == "COIN_M":
            # For COIN-M, quantity is in number of contracts. Value of 1 contract is e.g. 10 USD or 100 USD.
            # Margin is in base currency (e.g. BTC for BTCUSD_PERP).
            # Size = (MarginInBase * Leverage * EntryPrice) / ContractValueInQuote (if contract value is fixed in quote)
            # Or more simply: SizeInContracts = (MarginInBase * Leverage) / (MarginRequiredPerContractInBase)
            # Binance API for COIN-M: quantity is number of contracts.
            # Let's assume `fixed_margin_coin` is the amount of base currency to risk.
            # The actual USD value of this margin fluctuates.
            # Position size in contracts: (Margin_in_Coin * Leverage) / (InitialMarginPerContract_in_Coin)
            # InitialMarginPerContract_in_Coin = (ContractValue_in_USD / EntryPrice_USD) / Leverage (this is circular)
            # Simpler: Quantity_in_Contracts = (Margin_In_Coin * Leverage * EntryPrice_QuotePerBase) / Contract_FaceValue_In_Quote
            # This needs contract size info (e.g. 1 contract = 100 USD for BTCUSD_PERP)
            # For now, let's assume a simpler model if `fixed_margin_coin` is defined as number of contracts to trade directly.
            # This part needs careful review of COIN-M contract specs.
            # A common approach: if contract value is $100, margin is 0.01 BTC, leverage 10x, entry $50k
            # Total exposure in BTC = 0.01 * 10 = 0.1 BTC. Total exposure in USD = 0.1 * 50000 = $5000
            # Number of contracts = $5000 / $100_per_contract = 50 contracts.
            # So, quantity = (fixed_margin_coin * leverage * entry_price) / contract_value_quote
            # This requires `contract_value_quote` from exchange info or config.
            # For MVP, let's assume `fixed_margin_coin` IS the number of contracts if provided, else error.
            # This is a simplification and likely incorrect for general COIN-M. 
            # A better MVP for COIN-M might be to require quantity directly in config for COIN-M pairs.
            if fixed_margin_coin is not None: # Assuming fixed_margin_coin is intended as # of contracts for MVP
                quantity_raw = fixed_margin_coin # This is a placeholder assumption
                logger.warning(f"COIN-M quantity calculation using 'margin_coin' as number of contracts. Review for correctness.")
                quantity = self._adjust_quantity_to_precision(quantity_raw, lot_step)
            else:
                logger.error(f"COIN-M trading requires 'margin_coin' (interpreted as num_contracts for MVP) or a more robust sizing logic. {api_symbol}")
                return
        else:
            logger.error(f"Unknown contract type: {signal.contract_type} for {api_symbol}")
            return

        if quantity is None or quantity <= 0:
            logger.error(f"Calculated quantity is zero or invalid for {api_symbol}: {quantity}")
            return
        
        # Check min notional if applicable
        if min_notional_val and entry_price > 0:
            notional_value = quantity * entry_price
            # For COIN-M, notional value is trickier as it depends on contract multiplier
            # if signal.contract_type == "COIN_M": # Need contract multiplier
            #    pass 
            if signal.contract_type == "USDT_M" and notional_value < min_notional_val:
                logger.warning(f"Order for {api_symbol} notional {notional_value} is less than min_notional {min_notional_val}. Skipping.")
                return

        # 3. Place Entry Order (MARKET)
        order_side = OrderSide.BUY if signal.direction == TradeDirection.LONG else OrderSide.SELL
        entry_order_params = {"newOrderRespType": "RESULT"} # To get full order details
        logger.info(f"Placing entry order for {api_symbol}: {order_side.value} {quantity} units at MARKET price.")
        entry_order_response = await self.rest_client.create_order(
            symbol=api_symbol, 
            order_type=OrderType.MARKET, 
            side=order_side, 
            amount=quantity, 
            params=entry_order_params
        )

        if not entry_order_response or "id" not in entry_order_response or entry_order_response.get("status") == OrderStatus.REJECTED:
            logger.error(f"Failed to place entry order for {api_symbol}. Response: {entry_order_response}")
            return
        
        entry_order_id = entry_order_response["id"]
        logger.info(f"Entry order placed for {api_symbol}. ID: {entry_order_id}, Status: {entry_order_response.get('status')}")

        # Wait for entry order to fill (or partial fill if handling that)
        # For MARKET orders, they usually fill quickly. Polling might be needed for LIMIT.
        # For simplicity, assume MARKET order fills almost instantly for MVP.
        # A robust system would poll order status or use user data stream.
        # Let's assume we get avgFillPrice from the response if available, or use signal.entry_price
        actual_entry_price = float(entry_order_response.get("avgPrice", signal.entry_price)) 
        if actual_entry_price == 0 and entry_order_response.get("status") == OrderStatus.FILLED:
             actual_entry_price = float(entry_order_response.get("fills",[{}])[0].get("price", signal.entry_price))
        if actual_entry_price == 0 : actual_entry_price = signal.entry_price # Fallback

        # 4. Place SL and TP Orders (STOP_MARKET and TAKE_PROFIT_MARKET with reduceOnly)
        sl_tp_side = OrderSide.SELL if signal.direction == TradeDirection.LONG else OrderSide.BUY
        
        # Adjust SL/TP prices to precision
        adjusted_sl_price = self._adjust_price_to_precision(signal.stop_loss_price, price_tick)
        adjusted_tp_price = self._adjust_price_to_precision(signal.take_profit_price, price_tick)

        sl_order_params = {"reduceOnly": "true"}
        logger.info(f"Placing SL order for {api_symbol}: {sl_tp_side.value} {quantity} units, stopPrice {adjusted_sl_price:.{self._get_price_precision(price_tick)}f}")
        sl_order_response = await self.rest_client.create_order(
            symbol=api_symbol, 
            order_type=OrderType.STOP_MARKET, 
            side=sl_tp_side, 
            amount=quantity, 
            params={**sl_order_params, "stopPrice": adjusted_sl_price}
        )

        if not sl_order_response or "id" not in sl_order_response:
            logger.error(f"Failed to place SL order for {api_symbol}. Response: {sl_order_response}. Entry order {entry_order_id} might need manual SL.")
            # Potentially try to close the position if SL cannot be placed
        else:
            logger.info(f"SL order placed for {api_symbol}. ID: {sl_order_response['id']}")

        tp_order_params = {"reduceOnly": "true"}
        logger.info(f"Placing TP order for {api_symbol}: {sl_tp_side.value} {quantity} units, stopPrice {adjusted_tp_price:.{self._get_price_precision(price_tick)}f}")
        tp_order_response = await self.rest_client.create_order(
            symbol=api_symbol, 
            order_type=OrderType.TAKE_PROFIT_MARKET, 
            side=sl_tp_side, 
            amount=quantity, 
            params={**tp_order_params, "stopPrice": adjusted_tp_price}
        )

        if not tp_order_response or "id" not in tp_order_response:
            logger.error(f"Failed to place TP order for {api_symbol}. Response: {tp_order_response}. Entry order {entry_order_id} might need manual TP.")
        else:
            logger.info(f"TP order placed for {api_symbol}. ID: {tp_order_response['id']}")

        # TODO: Notify PositionManager about the new position and associated orders
        # position_data = Position(
        #     symbol=api_symbol,
        #     contract_type=signal.contract_type,
        #     side=signal.direction,
        #     entry_price=actual_entry_price,
        #     quantity=quantity,
        #     leverage=leverage,
        #     margin_type=margin_mode,
        #     entry_order_id=entry_order_id,
        #     sl_order_id=sl_order_response.get("id") if sl_order_response else None,
        #     tp_order_id=tp_order_response.get("id") if tp_order_response else None,
        #     current_sl_price=adjusted_sl_price,
        #     current_tp_price=adjusted_tp_price
        # )
        # await self.position_manager.add_or_update_position(position_data)
        logger.info(f"Trade execution process completed for signal on {api_symbol}.")

    def _get_price_precision(self, tick_size: float) -> int:
        if tick_size == 0: return 8 # Default high precision if tick_size is 0
        if "." in str(tick_size):
            return len(str(tick_size).split(".")[1].rstrip("0"))
        return 0

# Example Usage (for integration testing, not standalone run)
async def main_order_manager_test():
    logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s")
    
    class MockConfigManager:
        def get_config(self):
            return {
                "api": {"binance_api_key": "SIM_KEY", "binance_api_secret": "SIM_SECRET"}, # Simulate real keys for REST client init
                "global_settings": {
                    "v1_strategy": {
                        "default_margin_usdt": 50,
                        "default_leverage": 10,
                        "margin_mode": "ISOLATED"
                    }
                },
                "pairs": {
                    "BTC_USDT": {"enabled": True, "contract_type": "USDT_M", "margin_usdt": 100, "leverage": 20},
                    "ETHUSD_PERP": {"enabled": True, "contract_type": "COIN_M", "margin_coin": 0.1, "leverage": 10} # margin_coin as num_contracts
                }
            }
        def register_callback(self, cb): pass
        def stop_watcher(self): pass

    class MockBinanceRESTClient:
        def __init__(self, cfg):
            logger.info("MockBinanceRESTClient initialized")
            self.exchange_info_data = {
                "BTCUSDT": {"precision": {"amount": "0.00001", "price": "0.01"}, "limits": {"cost": {"min": "10"}}},
                "ETHUSD_PERP": {"precision": {"amount": "1", "price": "0.01"}, "limits": {"cost": {"min": "5"}}} # COIN-M contracts are usually integers
            }
        async def fetch_exchange_info(self): return self.exchange_info_data
        async def create_order(self, symbol, order_type, side, amount, price=None, params={}):
            order_id = f"mock_{order_type.lower()}_{int(time.time()*1000)}"
            logger.info(f"MOCK Create Order: {symbol}, {order_type}, {side}, {amount}, Price: {price}, Params: {params}, ID: {order_id}")
            avg_price = price or (params.get("stopPrice") if order_type != OrderType.MARKET else 50000.0) # Simulate some fill price
            return {"id": order_id, "symbol": symbol, "status": "NEW", "avgPrice": str(avg_price), "type": order_type}
        async def set_leverage(self, symbol, leverage, params={}): logger.info(f"MOCK Set Leverage: {symbol} to {leverage}x"); return True
        async def set_margin_mode(self, symbol, mode, params={}): logger.info(f"MOCK Set Margin Mode: {symbol} to {mode}"); return True
        async def close_exchange(self): pass

    cfg = MockConfigManager()
    rest_client = MockBinanceRESTClient(cfg) # Use mock for testing
    order_manager = OrderManager(cfg, rest_client)

    # Test USDT-M signal
    usdt_signal = TradeSignal(
        symbol="BTCUSDT", config_symbol="BTC_USDT", contract_type="USDT_M",
        direction=TradeDirection.LONG, entry_price=50000.0,
        stop_loss_price=49000.0, take_profit_price=53000.0
    )
    logger.info("--- Testing USDT-M Signal ---")
    await order_manager.handle_trade_signal(usdt_signal)

    await asyncio.sleep(1) # Ensure logs are flushed

    # Test COIN-M signal
    coinm_signal = TradeSignal(
        symbol="ETHUSD_PERP", config_symbol="ETHUSD_PERP", contract_type="COIN_M",
        direction=TradeDirection.SHORT, entry_price=3000.0,
        stop_loss_price=3100.0, take_profit_price=2700.0
    )
    logger.info("--- Testing COIN-M Signal ---")
    await order_manager.handle_trade_signal(coinm_signal)
    
    await rest_client.close_exchange()

if __name__ == "__main__":
    asyncio.run(main_order_manager_test())



================================================
FILE: src/position_manager.py
================================================
import logging
from typing import Dict, Optional, List
from threading import RLock # For thread-safe access to positions dictionary

from src.models import Position, Order, OrderStatus, TradeDirection
from src.config_loader import ConfigManager # For potential config needs

logger = logging.getLogger(__name__)

class PositionManager:
    def __init__(self, config_manager: ConfigManager):
        self.config_manager = config_manager
        # self.positions: Dict[str, Position] = {}  # Key: api_symbol (e.g., BTCUSDT)
        # A symbol can have only one position in Binance Futures (either LONG or SHORT, not both simultaneously unless in Hedge Mode)
        # For non-Hedge mode, a new trade in opposite direction first closes/reduces existing one.
        # Our bot logic (at least for V1) will likely manage one position per symbol at a time.
        self._positions: Dict[str, Position] = {}
        self._lock = RLock()

    async def add_or_update_position(self, position_data: Position):
        """Adds a new position or updates an existing one based on symbol."""
        with self._lock:
            api_symbol = position_data.symbol
            if api_symbol in self._positions:
                # This would typically mean an update, e.g., SL/TP moved, or PnL update
                # For MVP, a new signal might replace an old position after it is closed.
                # For now, let simple replacement happen if a new position is explicitly added.
                logger.info(f"Updating existing position for {api_symbol}.")
            else:
                logger.info(f"Adding new position for {api_symbol}.")
            self._positions[api_symbol] = position_data
            logger.debug(f"Position for {api_symbol} added/updated: {position_data}")

    async def remove_position(self, api_symbol: str):
        """Removes a position, typically after it has been closed."""
        with self._lock:
            if api_symbol in self._positions:
                logger.info(f"Removing position for {api_symbol}.")
                del self._positions[api_symbol]
            else:
                logger.warning(f"Attempted to remove non-existent position for {api_symbol}.")

    def get_position(self, api_symbol: str) -> Optional[Position]:
        """Retrieves the current position for a given symbol."""
        with self._lock:
            return self._positions.get(api_symbol)

    def get_all_positions(self) -> List[Position]:
        """Retrieves all currently tracked positions."""
        with self._lock:
            return list(self._positions.values())
    
    def has_open_position(self, api_symbol: str) -> bool:
        """Checks if there is an active position for the symbol."""
        with self._lock:
            return api_symbol in self._positions

    async def update_position_on_order_update(self, order: Order):
        """
        Updates position based on an order update (e.g., fill, cancellation).
        This is a crucial part that would typically be driven by user data stream.
        For MVP, this might be called by OrderManager after an order is confirmed filled/cancelled.
        """
        with self._lock:
            api_symbol = order.symbol
            position = self.get_position(api_symbol)

            if not position:
                # If an order update comes for a symbol with no tracked position, it might be an old order
                # or an order not initiated by this bot session. For now, we ignore.
                # logger.debug(f"Received order update for {api_symbol} but no active position tracked. Order ID: {order.order_id}")
                return

            # Was this order part of our tracked position?
            is_entry_order = order.order_id == position.entry_order_id
            is_sl_order = order.order_id == position.sl_order_id
            is_tp_order = order.order_id == position.tp_order_id

            if not (is_entry_order or is_sl_order or is_tp_order):
                # logger.debug(f"Order {order.order_id} for {api_symbol} not related to current tracked position.")
                return

            logger.info(f"Processing order update for position {api_symbol}. Order ID: {order.order_id}, Status: {order.status}")

            if order.status == OrderStatus.FILLED:
                if is_entry_order:
                    # Entry order filled. Position is now fully active.
                    # Update entry price if it was a market order and avgFillPrice is available.
                    if order.avg_fill_price and order.avg_fill_price > 0:
                        logger.info(f"Updating entry price for {api_symbol} from {position.entry_price} to {order.avg_fill_price} based on fill.")
                        position.entry_price = order.avg_fill_price
                    # Potentially update quantity if partial fill handling is added
                    position.quantity = order.filled_quantity or position.quantity
                    logger.info(f"Entry order {order.order_id} for {api_symbol} filled. Position active.")
                
                elif is_sl_order:
                    logger.info(f"Stop-loss order {order.order_id} for {api_symbol} FILLED. Position closed.")
                    # Position closed by SL. Remove it.
                    # Before removing, one might want to log PnL, etc.
                    await self.remove_position(api_symbol)
                    # TODO: Cancel the corresponding TP order if it is still open
                    if position.tp_order_id:
                        logger.info(f"Attempting to cancel TP order {position.tp_order_id} for closed position {api_symbol}")
                        # await self.rest_client.cancel_order(position.tp_order_id, api_symbol) # Requires rest_client here

                elif is_tp_order:
                    logger.info(f"Take-profit order {order.order_id} for {api_symbol} FILLED. Position closed.")
                    # Position closed by TP. Remove it.
                    await self.remove_position(api_symbol)
                    # TODO: Cancel the corresponding SL order if it is still open
                    if position.sl_order_id:
                        logger.info(f"Attempting to cancel SL order {position.sl_order_id} for closed position {api_symbol}")
                        # await self.rest_client.cancel_order(position.sl_order_id, api_symbol)
            
            elif order.status == OrderStatus.CANCELED:
                # If an SL or TP order is canceled, we need to handle it.
                # Maybe the bot decided to close the position manually, or an error occurred.
                if is_sl_order:
                    logger.warning(f"SL order {order.order_id} for {api_symbol} was CANCELED. Position might be unprotected.")
                    position.sl_order_id = None # Mark SL as no longer active
                elif is_tp_order:
                    logger.warning(f"TP order {order.order_id} for {api_symbol} was CANCELED.")
                    position.tp_order_id = None
                # If entry order is canceled, the position was never truly opened.
                elif is_entry_order:
                    logger.warning(f"Entry order {order.order_id} for {api_symbol} was CANCELED. Removing tentative position.")
                    await self.remove_position(api_symbol)
            
            elif order.status == OrderStatus.REJECTED:
                logger.error(f"Order {order.order_id} for {api_symbol} was REJECTED.")
                if is_entry_order:
                    await self.remove_position(api_symbol)
                elif is_sl_order:
                    position.sl_order_id = None
                elif is_tp_order:
                    position.tp_order_id = None
                # This state requires careful handling - why was it rejected?

            # Persist the updated position state (if not removed)
            if self.get_position(api_symbol):
                 self._positions[api_symbol] = position # Ensure the modified position object is stored back

    # Placeholder for fetching positions from exchange on startup (reconciliation)
    async def reconcile_positions_with_exchange(self, rest_client: any):
        """
        Fetches open positions from the exchange and updates internal state.
        Useful on startup to sync with any positions already open on Binance.
        `rest_client` is passed here as PositionManager might not always have it directly.
        """
        with self._lock:
            logger.info("Reconciling positions with exchange...")
            try:
                exchange_positions = await rest_client.fetch_positions() # Fetches all open positions
                if exchange_positions is None: # Error occurred during fetch
                    logger.error("Failed to fetch positions from exchange for reconciliation.")
                    return

                current_bot_symbols = set(self._positions.keys())
                exchange_symbols_with_pos = set()

                for pos_data in exchange_positions:
                    api_symbol = pos_data.get("symbol")
                    if not api_symbol: continue
                    exchange_symbols_with_pos.add(api_symbol)

                    # Basic conversion from ccxt position structure to our Position model
                    # This needs to be robust and handle various fields from ccxt
                    qty = float(pos_data.get("contracts", pos_data.get("amount", 0)))
                    if qty == 0: # No actual position, skip
                        if api_symbol in self._positions: # If bot thought it had a position, remove it
                            logger.info(f"Reconciliation: Exchange shows no position for {api_symbol}, removing from bot state.")
                            del self._positions[api_symbol]
                        continue
                    
                    side = TradeDirection.LONG if qty > 0 else TradeDirection.SHORT
                    entry_price = float(pos_data.get("entryPrice", 0))
                    
                    # Create or update bot's internal position state
                    # This is a simplified reconciliation. A full one would also check SL/TP orders.
                    reconciled_pos = Position(
                        symbol=api_symbol,
                        contract_type="USDT_M" if "USDT" in api_symbol else "COIN_M", # Basic assumption
                        side=side,
                        entry_price=entry_price,
                        quantity=abs(qty),
                        margin_type=pos_data.get("marginType"),
                        leverage=int(pos_data.get("leverage",0)),
                        unrealized_pnl=float(pos_data.get("unrealizedPnl",0)),
                        liquidation_price=float(pos_data.get("liquidationPrice",0)),
                        mark_price=float(pos_data.get("markPrice",0)),
                        # SL/TP order IDs are not directly available from fetch_positions, would need separate logic
                    )
                    self._positions[api_symbol] = reconciled_pos
                    logger.info(f"Reconciliation: Synced position for {api_symbol} from exchange: {side.value} {abs(qty)} @ {entry_price}")

                # Remove positions tracked by bot but not on exchange
                for sym_in_bot in current_bot_symbols:
                    if sym_in_bot not in exchange_symbols_with_pos:
                        logger.info(f"Reconciliation: Bot had position for {sym_in_bot}, but not found on exchange. Removing.")
                        del self._positions[sym_in_bot]
                
                logger.info("Position reconciliation completed.")
            except Exception as e:
                logger.error(f"Error during position reconciliation: {e}", exc_info=True)


# Example Usage (for testing purposes)
async def main_position_manager_test():
    logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s")

    class MockConfigManager:
        def get_config(self): return {}
        def register_callback(self, cb): pass

    cfg_manager = MockConfigManager()
    position_manager = PositionManager(config_manager=cfg_manager)

    # Test adding a position
    pos1_data = Position(
        symbol="BTCUSDT", contract_type="USDT_M", side=TradeDirection.LONG, entry_price=50000,
        quantity=0.001, entry_order_id="entry1", sl_order_id="sl1", tp_order_id="tp1"
    )
    await position_manager.add_or_update_position(pos1_data)
    print(f"Position for BTCUSDT: {position_manager.get_position('BTCUSDT')}")
    print(f"All positions: {position_manager.get_all_positions()}")

    # Test updating a position (e.g. SL moved, not fully implemented here but shows add_or_update)
    pos1_updated_data = Position(
        symbol="BTCUSDT", contract_type="USDT_M", side=TradeDirection.LONG, entry_price=50000,
        quantity=0.001, entry_order_id="entry1", sl_order_id="sl1_moved", tp_order_id="tp1"
    )
    await position_manager.add_or_update_position(pos1_updated_data)
    print(f"Updated Position for BTCUSDT: {position_manager.get_position('BTCUSDT')}")

    # Test order update - SL filled
    sl_fill_order = Order(
        order_id="sl1_moved", client_order_id="", symbol="BTCUSDT", type="STOP_MARKET", side="SELL",
        quantity=0.001, status=OrderStatus.FILLED, timestamp=1234567890, avg_fill_price=49000, filled_quantity=0.001
    )
    await position_manager.update_position_on_order_update(sl_fill_order)
    print(f"Position for BTCUSDT after SL fill: {position_manager.get_position('BTCUSDT')}") # Should be None
    assert position_manager.get_position('BTCUSDT') is None

    # Test adding another position
    pos2_data = Position(
        symbol="ETHUSDT", contract_type="USDT_M", side=TradeDirection.SHORT, entry_price=3000,
        quantity=0.05, entry_order_id="entry2", sl_order_id="sl2", tp_order_id="tp2"
    )
    await position_manager.add_or_update_position(pos2_data)
    print(f"All positions: {position_manager.get_all_positions()}")

    # Test removing a position directly
    await position_manager.remove_position("ETHUSDT")
    print(f"All positions after ETHUSDT removal: {position_manager.get_all_positions()}")
    assert position_manager.get_position('ETHUSDT') is None

if __name__ == "__main__":
    import asyncio
    asyncio.run(main_position_manager_test())



================================================
FILE: src/signal_engine copy.py
================================================
import logging
import time
import pandas as pd
from typing import Optional, Dict, Any, Tuple

from src.config_loader import ConfigManager
from src.data_processor import DataProcessor
from src.models import TradeSignal, TradeDirection, Kline
from src.connectors import convert_symbol_to_api_format, convert_symbol_to_ws_format # For consistency

logger = logging.getLogger(__name__)

class SignalEngineV1:
    def __init__(self, config_manager: ConfigManager, data_processor: DataProcessor):
        self.config_manager = config_manager
        self.data_processor = data_processor
        self.last_signal_time: Dict[str, float] = {} # Stores timestamp of the last signal for each pair

    def _get_pair_specific_config(self, config_symbol: str) -> Dict[str, Any]:
        config = self.config_manager.get_config()
        pair_configs = config.get("pairs", {})
        global_v1_config = config.get("global_settings", {}).get("v1_strategy", {})
        
        pair_specific_overrides = {}
        for cfg_sym, details in pair_configs.items():
            if cfg_sym.upper() == config_symbol.upper(): # Match config_symbol (e.g. BTC_USDT)
                pair_specific_overrides = details
                break
        
        return {
            "sma_short_period": pair_specific_overrides.get("sma_short_period", global_v1_config.get("sma_short_period", 21)),
            "sma_long_period": pair_specific_overrides.get("sma_long_period", global_v1_config.get("sma_long_period", 200)),
            "min_signal_interval_minutes": pair_specific_overrides.get("min_signal_interval_minutes", global_v1_config.get("min_signal_interval_minutes", 15)),
            "tp_sl_ratio": pair_specific_overrides.get("tp_sl_ratio", global_v1_config.get("tp_sl_ratio", 3.0)),
            "contract_type": pair_specific_overrides.get("contract_type", "USDT_M") # Default to USDT_M
        }

    def _find_recent_pivot(self, klines_df: pd.DataFrame, lookback: int = 10, direction: TradeDirection = TradeDirection.LONG) -> Optional[float]:
        """Finds the most recent significant pivot low (for LONG) or high (for SHORT)."""
        if klines_df is None or klines_df.empty or len(klines_df) < 3:
            return None

        # Ensure we only look at a recent window of closed candles for pivots
        # The signal candle itself is usually the last one, so we look before it.
        relevant_klines = klines_df[klines_df["is_closed"]].iloc[-lookback-1:-1] # Look at N closed candles before the signal candle
        if len(relevant_klines) < 3:
             relevant_klines = klines_df[klines_df["is_closed"]].iloc[-len(klines_df):-1] # use all available if not enough
             if len(relevant_klines) < 3:
                return None

        if direction == TradeDirection.LONG:
            # Find pivot lows: low[i] < low[i-1] and low[i] < low[i+1]
            # For simplicity, let\"s find the minimum low in the lookback window as a proxy for recent support
            # A more robust pivot detection would use scipy.signal.find_peaks or similar
            min_low = relevant_klines["low"].min()
            return min_low
        else: # TradeDirection.SHORT
            # Find pivot highs: high[i] > high[i-1] and high[i] > high[i+1]
            # For simplicity, let\"s find the maximum high in the lookback window as a proxy for recent resistance
            max_high = relevant_klines["high"].max()
            return max_high

    async def check_signal(self, api_symbol: str, config_symbol: str) -> Optional[TradeSignal]:
        """Checks for a V1 SMA crossover signal for the given API symbol (e.g., BTCUSDT)."""
        pair_config = self._get_pair_specific_config(config_symbol)
        if not pair_config: 
            # logger.debug(f"No configuration found for {config_symbol} in SignalEngineV1")
            return None

        # V1 strategy uses 1-minute timeframe for signals
        signal_interval = "1m"
        df = self.data_processor.get_indicator_dataframe(api_symbol, signal_interval)

        if df is None or df.empty or len(df) < 2:
            # logger.debug(f"Not enough data for {api_symbol} {signal_interval} to generate signal.")
            return None

        # Get the latest two candles for crossover detection
        latest = df.iloc[-1]
        previous = df.iloc[-2]

        sma_short_col = "sma_short"
        sma_long_col = "sma_long"

        if not all(col in latest.index and col in previous.index for col in [sma_short_col, sma_long_col, "close", "is_closed"]):
            # logger.debug(f"SMA data not available for {api_symbol} {signal_interval}.")
            return None
        
        # Ensure latest candle data is present and SMAs are calculated
        if pd.isna(latest[sma_short_col]) or pd.isna(latest[sma_long_col]) or \
           pd.isna(previous[sma_short_col]) or pd.isna(previous[sma_long_col]):
            # logger.debug(f"SMA values are NA for {api_symbol} {signal_interval}. Latest: {latest[sma_short_col]}, {latest[sma_long_col]}. Previous: {previous[sma_short_col]}, {previous[sma_long_col]}")
            return None

        # --- Significance Filter (Time-based) ---
        min_interval_seconds = pair_config["min_signal_interval_minutes"] * 60
        current_time = time.time()
        if api_symbol in self.last_signal_time and (current_time - self.last_signal_time[api_symbol]) < min_interval_seconds:
            # logger.debug(f"Signal for {api_symbol} too soon. Last signal at {self.last_signal_time[api_symbol]}, current: {current_time}")
            return None

        # --- SMA Crossover Detection ---
        # Ensure we are checking on a closed candle or a very recent candle
        # The signal is based on the state at the close of the \"previous\" candle that caused the crossover, 
        # and the \"latest\" candle confirms it.
        # Let\"s assume the signal is valid if the crossover happened on the \"latest\" candle compared to \"previous\".
        
        crossed_up = (previous[sma_short_col] <= previous[sma_long_col] and
                      latest[sma_short_col] > latest[sma_long_col])
        crossed_down = (previous[sma_short_col] >= previous[sma_long_col] and
                        latest[sma_short_col] < latest[sma_long_col])

        signal_direction: Optional[TradeDirection] = None
        if crossed_up:
            signal_direction = TradeDirection.LONG
        elif crossed_down:
            signal_direction = TradeDirection.SHORT
        else:
            return None # No crossover

        # --- SL/TP Calculation ---
        entry_price = latest["close"] # Current close price as entry
        stop_loss_price: Optional[float] = None
        take_profit_price: Optional[float] = None
        tp_sl_ratio = pair_config["tp_sl_ratio"]

        # Use a lookback of N candles for pivot detection, e.g., 20-50 candles for 1m chart
        # The klines for pivot detection should be from the main DataFrame `df`
        pivot_lookback = 30 # Number of 1-minute candles to look back for pivot

        if signal_direction == TradeDirection.LONG:
            pivot_low = self._find_recent_pivot(df, lookback=pivot_lookback, direction=TradeDirection.LONG)
            if pivot_low is not None:
                # Add a small buffer to SL, e.g., a few ticks or a percentage
                # For simplicity, direct use for now. Buffer can be added from config.
                stop_loss_price = pivot_low 
                risk = entry_price - stop_loss_price
                if risk <= 0: # Invalid SL (e.g. pivot_low >= entry_price)
                    logger.warning(f"Invalid SL for LONG {api_symbol}: entry={entry_price}, pivot_low={pivot_low}. Skipping signal.")
                    return None
                take_profit_price = entry_price + (risk * tp_sl_ratio)
            else:
                logger.warning(f"Could not determine pivot low for LONG SL for {api_symbol}. Skipping signal.")
                return None
        else: # TradeDirection.SHORT
            pivot_high = self._find_recent_pivot(df, lookback=pivot_lookback, direction=TradeDirection.SHORT)
            if pivot_high is not None:
                stop_loss_price = pivot_high
                risk = stop_loss_price - entry_price
                if risk <= 0: # Invalid SL (e.g. pivot_high <= entry_price)
                    logger.warning(f"Invalid SL for SHORT {api_symbol}: entry={entry_price}, pivot_high={pivot_high}. Skipping signal.")
                    return None
                take_profit_price = entry_price - (risk * tp_sl_ratio)
            else:
                logger.warning(f"Could not determine pivot high for SHORT SL for {api_symbol}. Skipping signal.")
                return None

        if stop_loss_price is None or take_profit_price is None:
            logger.warning(f"Failed to calculate SL/TP for {api_symbol}. Skipping signal.")
            return None
        
        # Ensure SL and TP are not the same as entry or inverted
        if (signal_direction == TradeDirection.LONG and (stop_loss_price >= entry_price or take_profit_price <= entry_price)) or \
           (signal_direction == TradeDirection.SHORT and (stop_loss_price <= entry_price or take_profit_price >= entry_price)):
            logger.warning(f"Calculated SL/TP invalid for {api_symbol}: E={entry_price}, SL={stop_loss_price}, TP={take_profit_price}. Skipping signal.")
            return None

        self.last_signal_time[api_symbol] = current_time
        logger.info(f"Generated signal for {api_symbol}: {signal_direction.value} at {entry_price}, SL={stop_loss_price}, TP={take_profit_price}")

        # Construct signal kline from the latest data point in the DataFrame
        signal_kline_data = latest.to_dict()
        # Ensure all fields required by Kline model are present, add defaults if necessary
        signal_kline_obj = Kline(
            timestamp=int(latest.name), # timestamp is the index
            open=signal_kline_data.get("open"),
            high=signal_kline_data.get("high"),
            low=signal_kline_data.get("low"),
            close=signal_kline_data.get("close"),
            volume=signal_kline_data.get("volume"),
            is_closed=signal_kline_data.get("is_closed", True), # Assume closed if it triggered signal logic
            symbol=api_symbol,
            interval=signal_interval
        )

        return TradeSignal(
            symbol=api_symbol,
            config_symbol=config_symbol,
            contract_type=pair_config["contract_type"],
            direction=signal_direction,
            entry_price=entry_price,
            stop_loss_price=stop_loss_price,
            take_profit_price=take_profit_price,
            strategy_name="V1_SMA_Crossover",
            signal_kline=signal_kline_obj,
            details={
                "sma_short_at_signal": latest[sma_short_col],
                "sma_long_at_signal": latest[sma_long_col],
                "sma_short_previous": previous[sma_short_col],
                "sma_long_previous": previous[sma_long_col],
                "pivot_used_for_sl": pivot_low if signal_direction == TradeDirection.LONG else pivot_high
            }
        )




================================================
FILE: src/signal_engine.py
================================================
import logging
import time
import pandas as pd
from typing import Optional, Dict, Any, Tuple

from src.config_loader import ConfigManager
from src.data_processor import DataProcessor
from src.models import TradeSignal, TradeDirection, Kline
from src.connectors import convert_symbol_to_api_format, convert_symbol_to_ws_format # For consistency

logger = logging.getLogger(__name__)

class SignalEngineV1:
    def __init__(self, config_manager: ConfigManager, data_processor: DataProcessor):
        self.config_manager = config_manager
        self.data_processor = data_processor
        self.last_signal_time: Dict[str, float] = {} # Stores timestamp of the last signal for each pair

    def _get_pair_specific_config(self, config_symbol: str) -> Dict[str, Any]:
        config = self.config_manager.get_config()
        pair_configs = config.get("pairs", {})
        global_v1_config = config.get("global_settings", {}).get("v1_strategy", {})
        
        pair_specific_overrides = {}
        for cfg_sym, details in pair_configs.items():
            if cfg_sym.upper() == config_symbol.upper(): # Match config_symbol (e.g. BTC_USDT)
                pair_specific_overrides = details
                break
        
        return {
            "sma_short_period": pair_specific_overrides.get("sma_short_period", global_v1_config.get("sma_short_period", 21)),
            "sma_long_period": pair_specific_overrides.get("sma_long_period", global_v1_config.get("sma_long_period", 200)),
            "min_signal_interval_minutes": pair_specific_overrides.get("min_signal_interval_minutes", global_v1_config.get("min_signal_interval_minutes", 15)),
            "tp_sl_ratio": pair_specific_overrides.get("tp_sl_ratio", global_v1_config.get("tp_sl_ratio", 3.0)),
            "contract_type": pair_specific_overrides.get("contract_type", "USDT_M") # Default to USDT_M
        }

    def _find_recent_pivot(self, klines_df: pd.DataFrame, lookback: int = 10, direction: TradeDirection = TradeDirection.LONG) -> Optional[float]:
        """Finds the most recent significant pivot low (for LONG) or high (for SHORT)."""
        logger.debug(f"_find_recent_pivot called with lookback={lookback}, direction={direction.value}")
        
        if klines_df is None or klines_df.empty or len(klines_df) < 3:
            logger.debug(f"Insufficient data for pivot: df exists: {klines_df is not None}, empty: {klines_df.empty if klines_df is not None else True}, len: {len(klines_df) if klines_df is not None else 0}")
            return None

        # Ensure we only look at a recent window of closed candles for pivots
        # The signal candle itself is usually the last one, so we look before it.
        relevant_klines = klines_df[klines_df["is_closed"]].iloc[-lookback-1:-1] # Look at N closed candles before the signal candle
        logger.debug(f"Found {len(relevant_klines)} closed candles in the lookback window")
        
        if len(relevant_klines) < 3:
             relevant_klines = klines_df[klines_df["is_closed"]].iloc[-len(klines_df):-1] # use all available if not enough
             logger.debug(f"Using all available {len(relevant_klines)} closed candles")
             if len(relevant_klines) < 3:
                logger.debug("Still insufficient data for pivot calculation (need at least 3 candles)")
                return None

        if direction == TradeDirection.LONG:
            # Find pivot lows: low[i] < low[i-1] and low[i] < low[i+1]
            # For simplicity, let\"s find the minimum low in the lookback window as a proxy for recent support
            # A more robust pivot detection would use scipy.signal.find_peaks or similar
            min_low = relevant_klines["low"].min()
            logger.debug(f"For LONG direction, found pivot low at {min_low}")
            return min_low
        else: # TradeDirection.SHORT
            # Find pivot highs: high[i] > high[i-1] and high[i] > high[i+1]
            # For simplicity, let\"s find the maximum high in the lookback window as a proxy for recent resistance
            max_high = relevant_klines["high"].max()
            logger.debug(f"For SHORT direction, found pivot high at {max_high}")
            return max_high

    async def check_signal(self, api_symbol: str, config_symbol: str) -> Optional[TradeSignal]:
        """Checks for a V1 SMA crossover signal for the given API symbol (e.g., BTCUSDT)."""
        # DEBUG: Entry to check_signal
        logger.debug(f"Entering check_signal for {api_symbol}, timestamp: {time.time()}")
        
        pair_config = self._get_pair_specific_config(config_symbol)
        if not pair_config: 
            logger.debug(f"No configuration found for {config_symbol} in SignalEngineV1")
            return None

        # V1 strategy uses 1-minute timeframe for signals
        signal_interval = "1m"
        df = self.data_processor.get_indicator_dataframe(api_symbol, signal_interval)

        if df is None or df.empty or len(df) < 2:
            logger.debug(f"Not enough data for {api_symbol} {signal_interval} to generate signal. df exists: {df is not None}, empty: {df.empty if df is not None else True}, len: {len(df) if df is not None else 0}")
            return None

        # Get the latest two candles for crossover detection
        latest = df.iloc[-1]
        previous = df.iloc[-2]

        sma_short_col = "sma_short"
        sma_long_col = "sma_long"

        if not all(col in latest.index and col in previous.index for col in [sma_short_col, sma_long_col, "close", "is_closed"]):
            logger.debug(f"SMA data not available for {api_symbol} {signal_interval}. Columns in latest: {list(latest.index)}")
            return None
        
        # Ensure latest candle data is present and SMAs are calculated
        if pd.isna(latest[sma_short_col]) or pd.isna(latest[sma_long_col]) or \
           pd.isna(previous[sma_short_col]) or pd.isna(previous[sma_long_col]):
            logger.debug(f"SMA values are NA for {api_symbol} {signal_interval}. Latest: {latest[sma_short_col]}, {latest[sma_long_col]}. Previous: {previous[sma_short_col]}, {previous[sma_long_col]}")
            return None

        # DEBUG: Log SMA values for debugging
        logger.debug(f"SMA values for {api_symbol}: Latest short={latest[sma_short_col]}, long={latest[sma_long_col]}. Previous short={previous[sma_short_col]}, long={previous[sma_long_col]}")

        # --- Significance Filter (Time-based) ---
        min_interval_seconds = pair_config["min_signal_interval_minutes"] * 60
        current_time = time.time()
        if api_symbol in self.last_signal_time and (current_time - self.last_signal_time[api_symbol]) < min_interval_seconds:
            logger.debug(f"Signal for {api_symbol} too soon. Last signal at {self.last_signal_time[api_symbol]}, current: {current_time}, min_interval: {min_interval_seconds}")
            return None

        # --- SMA Crossover Detection ---
        # Ensure we are checking on a closed candle or a very recent candle
        # The signal is based on the state at the close of the \"previous\" candle that caused the crossover, 
        # and the \"latest\" candle confirms it.
        # Let\"s assume the signal is valid if the crossover happened on the \"latest\" candle compared to \"previous\".
        
        crossed_up = (previous[sma_short_col] <= previous[sma_long_col] and
                      latest[sma_short_col] > latest[sma_long_col])
        crossed_down = (previous[sma_short_col] >= previous[sma_long_col] and
                        latest[sma_short_col] < latest[sma_long_col])

        # DEBUG: Log crossover detection
        logger.debug(f"Crossover detection for {api_symbol}: crossed_up={crossed_up}, crossed_down={crossed_down}")

        signal_direction: Optional[TradeDirection] = None
        if crossed_up:
            signal_direction = TradeDirection.LONG
            logger.debug(f"LONG signal detected for {api_symbol}")
        elif crossed_down:
            signal_direction = TradeDirection.SHORT
            logger.debug(f"SHORT signal detected for {api_symbol}")
        else:
            logger.debug(f"No crossover detected for {api_symbol}")
            return None # No crossover

        # --- SL/TP Calculation ---
        entry_price = latest["close"] # Current close price as entry
        logger.debug(f"Entry price for {api_symbol}: {entry_price}")
        
        stop_loss_price: Optional[float] = None
        take_profit_price: Optional[float] = None
        tp_sl_ratio = pair_config["tp_sl_ratio"]

        # Standard pivot lookback for production use
        pivot_lookback = 30
        logger.debug(f"Using standard pivot_lookback={pivot_lookback}")

        if signal_direction == TradeDirection.LONG:
            pivot_low = self._find_recent_pivot(df, lookback=pivot_lookback, direction=TradeDirection.LONG)
            logger.debug(f"LONG signal - find_recent_pivot result for {api_symbol}: pivot_low={pivot_low}")
            
            if pivot_low is not None:
                # Add a small buffer to SL, e.g., a few ticks or a percentage
                # For simplicity, direct use for now. Buffer can be added from config.
                stop_loss_price = pivot_low 
                risk = entry_price - stop_loss_price
                logger.debug(f"Calculated risk for LONG {api_symbol}: entry={entry_price}, pivot_low={pivot_low}, risk={risk}")
                
                if risk <= 0: # Invalid SL (e.g. pivot_low >= entry_price)
                    logger.warning(f"Invalid SL for LONG {api_symbol}: entry={entry_price}, pivot_low={pivot_low}, risk={risk}. Skipping signal.")
                    return None
                take_profit_price = entry_price + (risk * tp_sl_ratio)
                logger.debug(f"Calculated TP for LONG {api_symbol}: TP={take_profit_price} (risk={risk} * ratio={tp_sl_ratio})")
            else:
                logger.warning(f"Could not determine pivot low for LONG SL for {api_symbol}. Skipping signal.")
                return None
        else: # TradeDirection.SHORT
            pivot_high = self._find_recent_pivot(df, lookback=pivot_lookback, direction=TradeDirection.SHORT)
            logger.debug(f"SHORT signal - find_recent_pivot result for {api_symbol}: pivot_high={pivot_high}")
            
            if pivot_high is not None:
                stop_loss_price = pivot_high
                risk = stop_loss_price - entry_price
                logger.debug(f"Calculated risk for SHORT {api_symbol}: entry={entry_price}, pivot_high={pivot_high}, risk={risk}")
                
                if risk <= 0: # Invalid SL (e.g. pivot_high <= entry_price)
                    logger.warning(f"Invalid SL for SHORT {api_symbol}: entry={entry_price}, pivot_high={pivot_high}, risk={risk}. Skipping signal.")
                    return None
                take_profit_price = entry_price - (risk * tp_sl_ratio)
                logger.debug(f"Calculated TP for SHORT {api_symbol}: TP={take_profit_price} (risk={risk} * ratio={tp_sl_ratio})")
            else:
                logger.warning(f"Could not determine pivot high for SHORT SL for {api_symbol}. Skipping signal.")
                return None

        if stop_loss_price is None or take_profit_price is None:
            logger.warning(f"Failed to calculate SL/TP for {api_symbol}. Skipping signal.")
            return None
        
        # Ensure SL and TP are not the same as entry or inverted
        if (signal_direction == TradeDirection.LONG and (stop_loss_price >= entry_price or take_profit_price <= entry_price)) or \
           (signal_direction == TradeDirection.SHORT and (stop_loss_price <= entry_price or take_profit_price >= entry_price)):
            logger.warning(f"Calculated SL/TP invalid for {api_symbol}: E={entry_price}, SL={stop_loss_price}, TP={take_profit_price}. Skipping signal.")
            return None

        self.last_signal_time[api_symbol] = current_time
        logger.info(f"Generated signal for {api_symbol}: {signal_direction.value} at {entry_price}, SL={stop_loss_price}, TP={take_profit_price}")

        # Construct signal kline from the latest data point in the DataFrame
        signal_kline_data = latest.to_dict()
        # Ensure all fields required by Kline model are present, add defaults if necessary
        signal_kline_obj = Kline(
            timestamp=int(latest.name), # timestamp is the index
            open=signal_kline_data.get("open"),
            high=signal_kline_data.get("high"),
            low=signal_kline_data.get("low"),
            close=signal_kline_data.get("close"),
            volume=signal_kline_data.get("volume"),
            is_closed=signal_kline_data.get("is_closed", True), # Assume closed if it triggered signal logic
            symbol=api_symbol,
            interval=signal_interval
        )

        logger.debug(f"Successfully created TradeSignal for {api_symbol}: {signal_direction.value} at {entry_price}")
        return TradeSignal(
            symbol=api_symbol,
            config_symbol=config_symbol,
            contract_type=pair_config["contract_type"],
            direction=signal_direction,
            entry_price=entry_price,
            stop_loss_price=stop_loss_price,
            take_profit_price=take_profit_price,
            strategy_name="V1_SMA_Crossover",
            signal_kline=signal_kline_obj,
            details={
                "sma_short_at_signal": latest[sma_short_col],
                "sma_long_at_signal": latest[sma_long_col],
                "sma_short_previous": previous[sma_short_col],
                "sma_long_previous": previous[sma_long_col],
                "pivot_used_for_sl": pivot_low if signal_direction == TradeDirection.LONG else pivot_high
            }
        )




================================================
FILE: src/utils.py
================================================



================================================
FILE: tests/__init__.py
================================================



================================================
FILE: tests/e2e/__init__.py
================================================



================================================
FILE: tests/integration/__init__.py
================================================



================================================
FILE: tests/integration/test_main_flow.py
================================================
import pytest
import asyncio
import pandas as pd
import time
from unittest.mock import AsyncMock, MagicMock, patch
import os
import yaml

# Ensure src is in path for tests if running pytest from root
import sys
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "../../")))

from src.config_loader import ConfigManager
from src.connectors import BinanceRESTClient, BinanceWebSocketConnector, convert_symbol_to_api_format
from src.data_processor import DataProcessor
from src.signal_engine import SignalEngineV1
from src.order_manager import OrderManager
from src.position_manager import PositionManager
from src.models import Kline, TradeSignal, TradeDirection, Order, OrderStatus, Position
from src.main import TradingBot # To test overall orchestration if needed

# --- Test Fixtures --- 
@pytest.fixture(scope="module") # Module scope for heavier setup
def event_loop():
    # Pytest-asyncio provides an event loop by default, but can be explicit if needed
    loop = asyncio.new_event_loop()
    yield loop
    loop.close()

@pytest.fixture
def temp_config_file_for_integration(tmp_path):
    config_dir = tmp_path / "config"
    config_dir.mkdir()
    config_file = config_dir / "config.yaml"
    config_content = """
    api:
      binance_api_key: "INTEGRATION_TEST_KEY" # Use distinct keys for integration tests
      binance_api_secret: "INTEGRATION_TEST_SECRET"
    global_settings:
      v1_strategy:
        sma_short_period: 3
        sma_long_period: 5
        min_signal_interval_minutes: 0 # No wait for testing
        tp_sl_ratio: 1.5
        default_margin_usdt: 20.0
        default_leverage: 5
        indicator_timeframes: ["1m"]
      risk_management:
        dynamic_sizing_enabled: false
    pairs:
      TEST_USDT:
        enabled: true
        contract_type: "USDT_M"
        # margin_usdt: 20 # Uses global
        # leverage: 5   # Uses global
    logging:
      level: "DEBUG"
    monitoring:
      prometheus_port: 8001 # Different port for tests
    """
    with open(config_file, "w") as f:
        f.write(config_content)
    return str(config_file)

@pytest.fixture
def integration_config_manager(temp_config_file_for_integration):
    if hasattr(ConfigManager, "_instance"):
        ConfigManager._instance = None # Reset singleton
    with patch("src.config_loader.DEFAULT_CONFIG_PATH", temp_config_file_for_integration):
        cm = ConfigManager(auto_reload=False)
        yield cm
    if hasattr(ConfigManager, "_instance"):
        ConfigManager._instance = None

@pytest.fixture
def mock_binance_rest_client_integration(integration_config_manager):
    client = BinanceRESTClient(config_manager=integration_config_manager)
    # Mock actual API calls to avoid hitting Binance
    client.exchange = AsyncMock() # Mock the ccxt exchange object itself
    client.exchange.load_markets = AsyncMock(return_value={
        "TESTUSDT": {
            "symbol": "TESTUSDT", "base": "TEST", "quote": "USDT", "type": "future",
            "precision": {"amount": "0.001", "price": "0.01"},
            "limits": {"amount": {"min": "0.001"}, "cost": {"min": "5.0"}}
        }
    })
    
    # Create a proper AsyncMock for create_order so call_count is accessible
    create_order_mock = AsyncMock()
    create_order_mock.side_effect = lambda symbol, order_type, side, amount, price=None, params=None: {
        "id": f"mock_order_{int(time.time()*1000)}",
        "symbol": symbol, 
        "type": order_type, 
        "side": side, 
        "amount": amount, 
        "price": price,
        "status": "NEW", # Simulate NEW, then assume it fills for test flow
        "avgPrice": str(price or params.get("stopPrice") or 100.0), # Mock fill price
        "filled": amount # Assume full fill for market orders
    }
    client.create_order = create_order_mock
    
    client.exchange.set_leverage = AsyncMock(return_value=True)
    client.exchange.set_margin_mode = AsyncMock(return_value=True)
    client.exchange.fetch_balance = AsyncMock(return_value={"USDT": {"free": 1000.0, "total": 1000.0}})
    client.exchange.close = AsyncMock()
    return client

# --- Integration Tests --- 

@pytest.mark.asyncio
async def test_kline_to_signal_to_order_flow(integration_config_manager, mock_binance_rest_client_integration):
    """ Test the flow: Kline -> DataProcessor -> SignalEngine -> OrderManager """
    
    # 1. Setup components
    data_processor = DataProcessor(config_manager=integration_config_manager)
    signal_engine = SignalEngineV1(config_manager=integration_config_manager, data_processor=data_processor)
    order_manager = OrderManager(config_manager=integration_config_manager, rest_client=mock_binance_rest_client_integration)
    # PositionManager could be added if we test its interaction too

    api_symbol = "TESTUSDT"
    config_symbol = "TEST_USDT"
    interval = "1m"

    # 2. Simulate incoming Kline data that should generate a signal
    # Data for a LONG signal (SMA3 crosses above SMA5)
    # SMA3 periods: 3, SMA5 periods: 5
    # Prices: 90, 92, 94 (SMA3=92), 96 (SMA3=94), 98 (SMA3=96)
    #         SMA5 = (90+92+94+96+98)/5 = 94
    # Next candle: close=100. SMA3=(96+98+100)/3 = 98. SMA5=(92+94+96+98+100)/5 = 96.
    # Crossover: Prev SMA3(96) > Prev SMA5(94). Curr SMA3(98) > Curr SMA5(96). This is not a crossover from below.
    # Let's make prev short < long, curr short > long
    # Prices: 90, 92, 90 (SMA3=90.67), 92 (SMA3=91.33), 90 (SMA3=90.67)
    #         SMA5 = (90+92+90+92+90)/5 = 90.8
    # Prev (idx 4, close 90): SMA3=90.67, SMA5=90.8 (short < long)
    # Curr (idx 5, close 98): SMA3=(90+92+98)/3=93.33. SMA5=(92+90+92+90+98)/5=92.4 (short > long) -> BUY
    klines_to_process = [
        Kline(timestamp=1000, open=90, high=91, low=89, close=90, volume=10, is_closed=True, symbol=api_symbol, interval=interval),
        Kline(timestamp=2000, open=90, high=93, low=91, close=92, volume=10, is_closed=True, symbol=api_symbol, interval=interval),
        Kline(timestamp=3000, open=92, high=92, low=89, close=90, volume=10, is_closed=True, symbol=api_symbol, interval=interval),
        Kline(timestamp=4000, open=90, high=93, low=91, close=92, volume=10, is_closed=True, symbol=api_symbol, interval=interval),
        Kline(timestamp=5000, open=92, high=92, low=89, close=90, volume=10, is_closed=True, symbol=api_symbol, interval=interval), # Prev state: SMA3=90.67, SMA5=90.8
        Kline(timestamp=6000, open=90, high=99, low=89, close=98, volume=10, is_closed=True, symbol=api_symbol, interval=interval)  # Curr state: SMA3=93.33, SMA5=92.4 -> BUY
    ]

    for kline in klines_to_process:
        await data_processor.process_kline(kline)
    
    # 3. Check for signal
    # The signal check would typically happen in the main loop or after kline processing
    # For this test, we call it directly.
    signal = await signal_engine.check_signal(api_symbol=api_symbol, config_symbol=config_symbol)
    
    assert signal is not None, "Signal should have been generated"
    assert signal.direction == TradeDirection.LONG
    assert signal.symbol == api_symbol
    assert signal.entry_price == 98.0 # Close of the signal candle
    # SL: min low of lookback. DataProcessor buffer has these klines.
    # Pivots are calculated on `df` inside signal_engine. `df` comes from data_processor.
    # Lows in buffer: 89,91,89,91,89,89. Min low for SL should be 89.
    assert signal.stop_loss_price == 89.0
    # TP: entry + (entry - SL) * tp_sl_ratio = 98 + (98 - 89) * 1.5 = 98 + 9 * 1.5 = 98 + 13.5 = 111.5
    assert signal.take_profit_price == 111.5

    # 4. Handle signal with OrderManager
    # Ensure exchange info is primed for the mock client
    await order_manager._get_exchange_info_for_symbol(api_symbol) 
    
    await order_manager.handle_trade_signal(signal)

    # 5. Verify orders were placed (mocked)
    # Expected quantity: (20 USDT margin * 5x leverage) / 98 entry = 1.0204...
    # Adjusted by step 0.001: floor(1.0204... / 0.001)*0.001 = 1.020
    expected_quantity = 1.020

    assert mock_binance_rest_client_integration.create_order.call_count == 3
    calls = mock_binance_rest_client_integration.create_order.call_args_list
    
    # Entry order
    assert calls[0][1]["symbol"] == api_symbol
    assert calls[0][1]["order_type"] == "MARKET"
    assert calls[0][1]["side"] == "BUY"
    assert calls[0][1]["amount"] == expected_quantity
    
    # SL order (price adjusted to 0.01 tick)
    assert calls[1][1]["params"]["stopPrice"] == 89.00
    assert calls[1][1]["amount"] == expected_quantity

    # TP order (price adjusted to 0.01 tick)
    assert calls[2][1]["params"]["stopPrice"] == 111.50
    assert calls[2][1]["amount"] == expected_quantity

@pytest.mark.asyncio
async def test_full_bot_cycle_with_mock_dependencies(temp_config_file_for_integration):
    """ Test a simplified integration between components without using TradingBot """
    
    # Reset ConfigManager singleton
    if hasattr(ConfigManager, "_instance"):
        ConfigManager._instance = None
    
    with patch("src.config_loader.DEFAULT_CONFIG_PATH", temp_config_file_for_integration):
        # Create a real config manager using the temp file
        config_manager = ConfigManager(auto_reload=False)
        
        # Setup components
        data_processor = DataProcessor(config_manager=config_manager)
        signal_engine = SignalEngineV1(config_manager=config_manager, data_processor=data_processor)
        
        # Setup REST client mock
        rest_client = AsyncMock()
        rest_client.fetch_exchange_info.return_value = {
            "TESTUSDT": {
                "symbol": "TESTUSDT", "precision": {"amount": "0.001", "price": "0.01"},
                "limits": {"cost": {"min": "5.0"}}
            }
        }
        
        # Mock create_order with an AsyncMock that we can track
        rest_client.create_order = AsyncMock(return_value={
            "id": "test_order_id",
            "status": "NEW"
        })
        
        # Create OrderManager with our mock
        order_manager = OrderManager(config_manager=config_manager, rest_client=rest_client)
        
        # Test data
        api_symbol = "TESTUSDT"
        config_symbol = "TEST_USDT"
        interval = "1m"
        
        # Create klines that will trigger a buy signal
        klines_to_process = [
            Kline(timestamp=1000, open=90, high=91, low=89, close=90, volume=10, is_closed=True, symbol=api_symbol, interval=interval),
            Kline(timestamp=2000, open=90, high=93, low=91, close=92, volume=10, is_closed=True, symbol=api_symbol, interval=interval),
            Kline(timestamp=3000, open=92, high=92, low=89, close=90, volume=10, is_closed=True, symbol=api_symbol, interval=interval),
            Kline(timestamp=4000, open=90, high=93, low=91, close=92, volume=10, is_closed=True, symbol=api_symbol, interval=interval),
            Kline(timestamp=5000, open=92, high=92, low=89, close=90, volume=10, is_closed=True, symbol=api_symbol, interval=interval),
            Kline(timestamp=6000, open=90, high=99, low=89, close=98, volume=10, is_closed=True, symbol=api_symbol, interval=interval)
        ]
        
        # Process klines
        for kline in klines_to_process:
            await data_processor.process_kline(kline)
        
        # Get signal
        signal = await signal_engine.check_signal(api_symbol=api_symbol, config_symbol=config_symbol)
        
        # Verify signal
        assert signal is not None, "Signal should have been generated"
        assert signal.direction == TradeDirection.LONG
        assert signal.symbol == api_symbol
        
        # Handle signal with OrderManager
        await order_manager.handle_trade_signal(signal)
        
        # Verify orders were placed
        assert rest_client.create_order.call_count == 3, "Should have created entry, SL, and TP orders"
        
        # Verify that config contains our test pair
        config = config_manager.get_config()
        assert "TEST_USDT" in config.get("pairs", {}), "Test pair should be in config"

    if hasattr(ConfigManager, "_instance"):
        ConfigManager._instance = None # Cleanup singleton




================================================
FILE: tests/unit/__init__.py
================================================



================================================
FILE: tests/unit/test_config_loader.py
================================================
import pytest
import os
import yaml
import time
import asyncio
from unittest.mock import patch, mock_open

from src.config_loader import ConfigManager, DEFAULT_CONFIG_PATH, EXAMPLE_CONFIG_PATH

@pytest.fixture
def temp_config_files(tmp_path):
    config_dir = tmp_path / "config"
    config_dir.mkdir()
    default_config_file = config_dir / "config.yaml"
    example_config_file = config_dir / "config.yaml.example"

    example_content = {
        "api": {"key": "example_key", "secret": "example_secret"},
        "logging": {"level": "INFO"}
    }
    with open(example_config_file, "w") as f:
        yaml.dump(example_content, f)
    
    # Initially, no default config.yaml, so it should be copied from example
    return str(default_config_file), str(example_config_file)

@pytest.fixture
def cleanup_singleton():
    # Reset the singleton instance before and after each test
    if hasattr(ConfigManager, "_instance"):
        ConfigManager._instance = None
    if hasattr(ConfigManager, "_initialized"):
        # This is a bit of a hack; ideally, the singleton is designed to be reset or re-initialized for tests.
        # For this specific implementation, clearing _instance is the main thing.
        # If __init__ has instance checks, we might need to delattr(ConfigManager, "_initialized") too.
        pass 
    yield
    if hasattr(ConfigManager, "_instance"):
        ConfigManager._instance = None

@pytest.mark.asyncio
async def test_config_manager_singleton(cleanup_singleton):
    cm1 = ConfigManager(config_file_path="dummy_path1.yaml", auto_reload=False)
    cm2 = ConfigManager(config_file_path="dummy_path2.yaml", auto_reload=False)
    assert cm1 is cm2
    # Even if params are different after first init, it should return the same instance
    # and not re-initialize with new params. This is typical singleton behavior.
    # The current ConfigManager init logic ensures it only initializes fully once.
    assert cm1.config_file_path == "dummy_path1.yaml" # Should retain path from first call

@pytest.mark.asyncio
async def test_config_load_from_example_if_default_missing(temp_config_files, cleanup_singleton):
    default_cfg_path, example_cfg_path = temp_config_files
    
    # Ensure default_cfg_path does not exist initially for this part of the test
    if os.path.exists(default_cfg_path):
        os.remove(default_cfg_path)

    # Mock the global paths to use temp_config_files
    with patch("src.config_loader.DEFAULT_CONFIG_PATH", default_cfg_path), \
         patch("src.config_loader.EXAMPLE_CONFIG_PATH", example_cfg_path):
        
        cm = ConfigManager(auto_reload=False) # Should trigger copy from example
        assert os.path.exists(default_cfg_path) # Default should have been created
        config_data = cm.get_config()
        assert config_data["api"]["key"] == "example_key"
        assert config_data["logging"]["level"] == "INFO"

@pytest.mark.asyncio
async def test_config_load_existing_default(temp_config_files, cleanup_singleton):
    default_cfg_path, example_cfg_path = temp_config_files

    # Create a specific default config.yaml
    default_content = {
        "api": {"key": "default_key", "secret": "default_secret"},
        "logging": {"level": "DEBUG"}
    }
    with open(default_cfg_path, "w") as f:
        yaml.dump(default_content, f)

    with patch("src.config_loader.DEFAULT_CONFIG_PATH", default_cfg_path), \
         patch("src.config_loader.EXAMPLE_CONFIG_PATH", example_cfg_path):
        cm = ConfigManager(auto_reload=False)
        config_data = cm.get_config()
        assert config_data["api"]["key"] == "default_key"
        assert config_data["logging"]["level"] == "DEBUG"

@pytest.mark.asyncio
async def test_get_specific_config(temp_config_files, cleanup_singleton):
    default_cfg_path, example_cfg_path = temp_config_files
    # Let it load from example
    if os.path.exists(default_cfg_path):
        os.remove(default_cfg_path)

    with patch("src.config_loader.DEFAULT_CONFIG_PATH", default_cfg_path), \
         patch("src.config_loader.EXAMPLE_CONFIG_PATH", example_cfg_path):
        cm = ConfigManager(auto_reload=False)
        assert cm.get_specific_config("api.key") == "example_key"
        assert cm.get_specific_config("logging.level") == "INFO"
        assert cm.get_specific_config("non.existent.path", "default_val") == "default_val"
        assert cm.get_specific_config("api.non_existent_key") is None

@pytest.mark.asyncio
async def test_config_hot_reload(temp_config_files, cleanup_singleton):
    default_cfg_path, example_cfg_path = temp_config_files
    # Start with example content
    if os.path.exists(default_cfg_path):
        os.remove(default_cfg_path)

    callback_triggered = False
    new_conf_in_callback = None

    def my_callback(new_config):
        nonlocal callback_triggered, new_conf_in_callback
        callback_triggered = True
        new_conf_in_callback = new_config

    with patch("src.config_loader.DEFAULT_CONFIG_PATH", default_cfg_path), \
         patch("src.config_loader.EXAMPLE_CONFIG_PATH", example_cfg_path):
        
        cm = ConfigManager(auto_reload=True) # Enable auto_reload
        cm.register_callback(my_callback)
        
        initial_config = cm.get_config()
        assert initial_config["logging"]["level"] == "INFO"

        # Modify the config file
        modified_content = {
            "api": {"key": "modified_key", "secret": "modified_secret"},
            "logging": {"level": "DEBUG_MODIFIED"}
        }
        # Wait a moment to ensure the watcher is established before writing
        await asyncio.sleep(0.2) 
        with open(default_cfg_path, "w") as f:
            yaml.dump(modified_content, f)
        
        # Give watchdog time to detect and process the change
        await asyncio.sleep(1.0) # Increased sleep for reliability in CI/slower systems

        assert callback_triggered is True
        assert new_conf_in_callback is not None
        assert new_conf_in_callback["logging"]["level"] == "DEBUG_MODIFIED"
        
        current_config_from_cm = cm.get_config()
        assert current_config_from_cm["logging"]["level"] == "DEBUG_MODIFIED"
        assert cm.get_specific_config("api.key") == "modified_key"

        cm.stop_watcher() # Clean up watcher thread

@pytest.mark.asyncio
async def test_config_load_failure_empty_file(temp_config_files, cleanup_singleton):
    default_cfg_path, example_cfg_path = temp_config_files
    # Create an empty config.yaml
    with open(default_cfg_path, "w") as f:
        f.write("")

    with patch("src.config_loader.DEFAULT_CONFIG_PATH", default_cfg_path), \
         patch("src.config_loader.EXAMPLE_CONFIG_PATH", example_cfg_path):
        cm = ConfigManager(auto_reload=False)
        # Should log a warning, and config_data should be empty or fallback
        # The current implementation falls back to empty dict if load fails post-initialization
        assert cm.get_config() == {} 

@pytest.mark.asyncio
async def test_config_load_failure_invalid_yaml(temp_config_files, cleanup_singleton):
    default_cfg_path, example_cfg_path = temp_config_files
    # Create an invalid YAML config.yaml
    with open(default_cfg_path, "w") as f:
        f.write("api: key: -: invalid_yaml_structure")

    # Pre-populate with valid example data first so there is an "old" config
    example_data = {"api": {"key": "example_key"}}
    with open(example_cfg_path, "w") as f:
        yaml.dump(example_data, f)
    if os.path.exists(default_cfg_path):
        os.remove(default_cfg_path)

    with patch("src.config_loader.DEFAULT_CONFIG_PATH", default_cfg_path), \
         patch("src.config_loader.EXAMPLE_CONFIG_PATH", example_cfg_path):
        
        cm_initial = ConfigManager(auto_reload=False) # Loads from example
        initial_key = cm_initial.get_specific_config("api.key")
        assert initial_key == "example_key"

        # Now, simulate the invalid file being loaded (e.g., by a hot reload attempt or direct load)
        with open(default_cfg_path, "w") as f:
            f.write("api: key: -: invalid_yaml_structure")
        
        cm_initial.load_config() # Manually trigger a load of the bad file

        # Config should remain the old valid one due to parsing error
        assert cm_initial.get_specific_config("api.key") == initial_key




================================================
FILE: tests/unit/test_connectors.py
================================================
import pytest
import asyncio
import json
import websockets
from unittest.mock import AsyncMock, patch, MagicMock

from src.config_loader import ConfigManager
from src.connectors import BinanceRESTClient, BinanceWebSocketConnector, convert_symbol_to_ws_format, convert_symbol_to_api_format
from src.models import Kline

@pytest.fixture
def mock_config_manager_for_connectors(tmp_path):
    # Create a dummy config file for tests
    config_dir = tmp_path / "config"
    config_dir.mkdir()
    config_file = config_dir / "config.yaml"
    config_content = """
    api:
      binance_api_key: "TEST_KEY"
      binance_api_secret: "TEST_SECRET"
    global_settings:
      v1_strategy:
        indicator_timeframes: ["1m", "5m"]
    pairs:
      BTC_USDT:
        enabled: true
        contract_type: "USDT_M"
      ETH_USDT:
        enabled: true
        contract_type: "USDT_M"
        indicator_timeframes: ["1m"]
      BTCUSD_PERP:
        enabled: true
        contract_type: "COIN_M"
        indicator_timeframes: ["1m"]
    logging:
      level: "DEBUG"
    """
    with open(config_file, "w") as f:
        f.write(config_content)
    
    # Patch ConfigManager to use this temp config file
    # and ensure singleton is reset for these tests
    if hasattr(ConfigManager, "_instance"):
        ConfigManager._instance = None

    with patch("src.config_loader.DEFAULT_CONFIG_PATH", str(config_file)):
        cm = ConfigManager(auto_reload=False)
        yield cm
    
    # Cleanup singleton after test
    if hasattr(ConfigManager, "_instance"):
        ConfigManager._instance = None

# --- Test Symbol Conversion --- 
def test_convert_symbol_to_ws_format():
    assert convert_symbol_to_ws_format("BTC_USDT") == "btcusdt"
    assert convert_symbol_to_ws_format("ETH_BTC") == "ethbtc"
    assert convert_symbol_to_ws_format("BTCUSD_PERP") == "btcusd_perp"
    assert convert_symbol_to_ws_format("btcusdt") == "btcusdt" # Already formatted

def test_convert_symbol_to_api_format():
    assert convert_symbol_to_api_format("BTC_USDT") == "BTCUSDT"
    assert convert_symbol_to_api_format("ETH_BTC") == "ETHBTC"
    assert convert_symbol_to_api_format("BTCUSD_PERP") == "BTCUSD_PERP"
    assert convert_symbol_to_api_format("btcusdt") == "BTCUSDT"

# --- Test BinanceRESTClient --- 
@pytest.mark.asyncio
async def test_rest_client_initialization(mock_config_manager_for_connectors):
    rest_client = BinanceRESTClient(config_manager=mock_config_manager_for_connectors)
    assert rest_client.exchange is not None # Should initialize ccxt exchange
    await rest_client.close_exchange()

@pytest.mark.asyncio
async def test_rest_client_initialization_no_api_keys(tmp_path):
    config_dir = tmp_path / "config"
    config_dir.mkdir()
    config_file = config_dir / "config.yaml"
    config_content = """
    api:
      binance_api_key: "YOUR_BINANCE_API_KEY"
      binance_api_secret: "YOUR_BINANCE_API_SECRET"
    """
    with open(config_file, "w") as f:
        f.write(config_content)
    if hasattr(ConfigManager, "_instance"):
        ConfigManager._instance = None
    with patch("src.config_loader.DEFAULT_CONFIG_PATH", str(config_file)):
        cm = ConfigManager(auto_reload=False)
        rest_client = BinanceRESTClient(config_manager=cm)
        assert rest_client.exchange is None # Should be None if keys are placeholders
        # Test a call, should simulate or return default
        order = await rest_client.create_order("BTCUSDT", "MARKET", "BUY", 1.0)
        # The order ID format includes a timestamp which we can't predict exactly,
        # so we just check if it starts with "simulated_order"
        assert order["id"].startswith("simulated_order")
        await rest_client.close_exchange()
    if hasattr(ConfigManager, "_instance"):
        ConfigManager._instance = None

@pytest.mark.asyncio
async def test_rest_client_fetch_balance(mock_config_manager_for_connectors):
    rest_client = BinanceRESTClient(config_manager=mock_config_manager_for_connectors)
    with patch.object(rest_client.exchange, "fetch_balance", new_callable=AsyncMock) as mock_fetch:
        mock_fetch.return_value = {"USDT": {"free": 1000, "total": 1000}}
        balance = await rest_client.fetch_balance()
        assert balance["USDT"]["free"] == 1000
        mock_fetch.assert_called_once()
    await rest_client.close_exchange()

@pytest.mark.asyncio
async def test_rest_client_create_order(mock_config_manager_for_connectors):
    rest_client = BinanceRESTClient(config_manager=mock_config_manager_for_connectors)
    with patch.object(rest_client.exchange, "create_order", new_callable=AsyncMock) as mock_create:
        mock_create.return_value = {"id": "123", "symbol": "BTCUSDT", "status": "NEW"}
        order = await rest_client.create_order("BTC_USDT", "MARKET", "BUY", 0.01)
        assert order["id"] == "123"
        mock_create.assert_called_once_with("BTCUSDT", "MARKET", "BUY", 0.01, None, {})
    await rest_client.close_exchange()

# --- Test BinanceWebSocketConnector --- 
@pytest.fixture
def mock_kline_callback():
    return AsyncMock()

@pytest.mark.asyncio
async def test_ws_connector_get_active_pairs_and_intervals(mock_config_manager_for_connectors, mock_kline_callback):
    ws_connector = BinanceWebSocketConnector(config_manager=mock_config_manager_for_connectors, kline_callback=mock_kline_callback)
    active_streams = ws_connector._get_active_pairs_and_intervals()
    assert "btcusdt@kline_1m" in active_streams["USDT_M"]
    assert "btcusdt@kline_5m" in active_streams["USDT_M"]
    assert "ethusdt@kline_1m" in active_streams["USDT_M"]
    assert "btcusd_perp@kline_1m" in active_streams["COIN_M"]
    assert "ethusdt@kline_5m" not in active_streams["USDT_M"] # Overridden to 1m only

@pytest.mark.asyncio
async def test_ws_connector_subscribe_unsubscribe(mock_kline_callback):
    # This test requires a more involved setup with a mock WebSocket server
    # or deeper patching of the `websockets.connect` call.
    # For simplicity, we focus on the logic of forming subscription messages.
    
    # Mock config that enables only one stream for easier assertion
    class MinimalMockConfigManager:
        def get_config(self):
            return {
                "global_settings": {"v1_strategy": {"indicator_timeframes": ["1m"]}},
                "pairs": {"BTC_USDT": {"enabled": True, "contract_type": "USDT_M"}}
            }
        def register_callback(self, cb): pass
        def unregister_callback(self, cb): pass
        def stop_watcher(self): pass

    ws_connector = BinanceWebSocketConnector(config_manager=MinimalMockConfigManager(), kline_callback=mock_kline_callback)
    
    mock_ws_connection = AsyncMock(spec=websockets.WebSocketClientProtocol)
    mock_ws_connection.open = True # Simulate open connection

    streams_to_sub = ["btcusdt@kline_1m"]
    await ws_connector._subscribe(mock_ws_connection, streams_to_sub)
    call_args = json.loads(mock_ws_connection.send.call_args[0][0])
    assert call_args["method"] == "SUBSCRIBE"
    assert call_args["params"] == streams_to_sub

    await ws_connector._unsubscribe(mock_ws_connection, streams_to_sub)
    call_args_unsub = json.loads(mock_ws_connection.send.call_args[0][0])
    assert call_args_unsub["method"] == "UNSUBSCRIBE"
    assert call_args_unsub["params"] == streams_to_sub

@pytest.mark.asyncio
async def test_ws_connector_process_kline_message(mock_config_manager_for_connectors, mock_kline_callback):
    ws_connector = BinanceWebSocketConnector(config_manager=mock_config_manager_for_connectors, kline_callback=mock_kline_callback)
    
    # Reset the mock to ensure it's clean
    mock_kline_callback.reset_mock()
    
    # This is the correct message format that Binance sends, with a stream and data key
    kline_msg_str = {
        "stream": "btcusdt@kline_1m",
        "data": {
            "e": "kline",
            "E": 123456789,
            "s": "BTCUSDT",
            "k": {
                "t": 123400000,
                "T": 123459999,
                "s": "BTCUSDT",
                "i": "1m",
                "o": "0.0010",
                "c": "0.0020",
                "h": "0.0025",
                "l": "0.0015",
                "v": "1000",
                "n": 100,
                "x": False, # Is kline closed?
                "q": "1.0000",
                "V": "500",
                "Q": "0.500",
                "B": "123456"
            }
        }
    }
    
    # Convert to JSON string and process
    await ws_connector._process_message(json.dumps(kline_msg_str), "USDT_M")
    
    # Need to wait a tiny bit for the async call to complete
    await asyncio.sleep(0.01)
    
    # Assert the callback was called
    mock_kline_callback.assert_called_once()
    
    # If assertion passes, check values
    called_kline_arg = mock_kline_callback.call_args[0][0]
    assert isinstance(called_kline_arg, Kline)
    assert called_kline_arg.symbol == "BTCUSDT"
    assert called_kline_arg.interval == "1m"
    assert called_kline_arg.close == 0.0020
    assert called_kline_arg.is_closed is False

@pytest.mark.asyncio
async def test_ws_connector_start_stop_and_config_update_flow(mock_config_manager_for_connectors, mock_kline_callback):
    ws_connector = BinanceWebSocketConnector(config_manager=mock_config_manager_for_connectors, kline_callback=mock_kline_callback)
    
    # Patch the actual connection handler to prevent real WS connections during this unit test
    with patch.object(ws_connector, "_handle_connection", new_callable=AsyncMock) as mock_handler:
        await ws_connector.start()
        assert ws_connector._is_running
        # _handle_config_update should have been called, leading to _handle_connection calls
        # Check if tasks for USDT_M and COIN_M were created (based on config)
        await asyncio.sleep(0.1) # Allow tasks to be scheduled
        assert mock_handler.call_count >= 1 # Should be called for USDT_M and COIN_M if enabled
        
        # Simulate a config update that disables a pair
        new_config_data = mock_config_manager_for_connectors.get_config()
        new_config_data["pairs"]["BTC_USDT"]["enabled"] = False
        
        # Mock the _unsubscribe and _subscribe methods on an active connection if one existed
        # For this test, we mainly check if _handle_config_update is called and updates subscriptions
        mock_ws_conn_usdm = AsyncMock(spec=websockets.WebSocketClientProtocol)
        mock_ws_conn_usdm.open = True
        ws_connector._ws_connections["USDT_M"] = mock_ws_conn_usdm
        ws_connector._active_subscriptions["USDT_M"] = ["btcusdt@kline_1m", "btcusdt@kline_5m"]

        await ws_connector._handle_config_update(new_config_data) # Manually trigger for test control
        
        # Check if btcusdt streams were unsubscribed
        # This requires inspecting calls to _unsubscribe or checking _active_subscriptions
        assert "btcusdt@kline_1m" not in ws_connector._active_subscriptions["USDT_M"]
        assert "btcusdt@kline_5m" not in ws_connector._active_subscriptions["USDT_M"]
        # And that ethusdt@kline_1m is still there
        assert "ethusdt@kline_1m" in ws_connector._active_subscriptions["USDT_M"]

        await ws_connector.stop()
        assert not ws_connector._is_running
        mock_handler.reset_mock() # Reset for next potential calls if any




================================================
FILE: tests/unit/test_data_processor.py
================================================
import pytest
import asyncio
import pandas as pd
import numpy as np
from unittest.mock import MagicMock, patch
from collections import deque

from src.config_loader import ConfigManager
from src.data_processor import DataProcessor, MAX_KLINE_BUFFER_LENGTH
from src.models import Kline

@pytest.fixture
def mock_config_manager_for_dp():
    """Fixture that creates a mock ConfigManager for DataProcessor testing."""
    mock_cm = MagicMock(spec=ConfigManager)
    
    # Create a mock config with different enabled pairs, timeframes, and SMA periods
    mock_config = {
        "global_settings": {
            "v1_strategy": {
                "sma_short_period": 21,
                "sma_long_period": 200,
                "indicator_timeframes": ["1m", "5m", "15m"]
            }
        },
        "pairs": {
            "BTC_USDT": {
                "enabled": True,
                "contract_type": "USDT_M",
                "indicator_timeframes": ["1m", "5m"]  # Override global
            },
            "ETH_USDT": {
                "enabled": True,
                "contract_type": "USDT_M"
                # Uses global timeframes: ["1m", "5m", "15m"]
            },
            "SOL_USDT": {
                "enabled": False  # This pair should not have buffers initialized initially
            },
            "XRP_USDT": {
                "enabled": True,
                "indicator_timeframes": ["1m"]  # Just 1m timeframe
            }
        }
    }
    
    # Set up the return value for get_config method
    mock_cm.get_config.return_value = mock_config
    
    return mock_cm

@pytest.fixture
def data_processor(mock_config_manager_for_dp):
    """Fixture that initializes DataProcessor with a mock ConfigManager."""
    dp = DataProcessor(config_manager=mock_config_manager_for_dp)
    return dp

# Test Initialization
@pytest.mark.asyncio
async def test_initialization_buffers_creation(data_processor, mock_config_manager_for_dp):
    """Test that buffers are created correctly based on enabled pairs and timeframes."""
    # Check active pairs timeframes dictionary
    assert "BTCUSDT" in data_processor._active_pairs_timeframes
    assert "ETHUSDT" in data_processor._active_pairs_timeframes
    assert "XRPUSDT" in data_processor._active_pairs_timeframes
    assert "SOLUSDT" not in data_processor._active_pairs_timeframes  # Disabled in config
    
    # Check specific timeframes for each pair
    assert set(data_processor._active_pairs_timeframes["BTCUSDT"]) == {"1m", "5m"}  # Overridden from global
    assert set(data_processor._active_pairs_timeframes["ETHUSDT"]) == {"1m", "5m", "15m"}  # From global
    assert set(data_processor._active_pairs_timeframes["XRPUSDT"]) == {"1m"}  # Specific config
    
    # Check kline buffer creation for all active pairs/timeframes
    for symbol in ["BTCUSDT", "ETHUSDT", "XRPUSDT"]:
        for tf in data_processor._active_pairs_timeframes[symbol]:
            assert tf in data_processor.kline_buffers[symbol]
            assert isinstance(data_processor.kline_buffers[symbol][tf], deque)
            assert data_processor.kline_buffers[symbol][tf].maxlen == MAX_KLINE_BUFFER_LENGTH
    
    # Check that disabled pairs don't have buffers or have empty ones
    if "SOLUSDT" in data_processor.kline_buffers:
        assert not data_processor.kline_buffers["SOLUSDT"]  # Should be empty

@pytest.mark.asyncio
async def test_initialization_empty_pairs_config(mock_config_manager_for_dp):
    """Test initialization with empty pairs configuration."""
    # Set empty pairs config
    empty_config = {
        "global_settings": {
            "v1_strategy": {
                "sma_short_period": 21,
                "sma_long_period": 200,
                "indicator_timeframes": ["1m", "5m"]
            }
        },
        "pairs": {}  # Empty pairs
    }
    mock_config_manager_for_dp.get_config.return_value = empty_config
    
    # Initialize DataProcessor with empty config
    dp = DataProcessor(config_manager=mock_config_manager_for_dp)
    
    # Check that active pairs, kline_buffers and indicator_data are empty
    assert not dp._active_pairs_timeframes
    assert not dp.kline_buffers  # Check defaultdict doesn't have any pairs
    assert not dp.indicator_data

# Test Kline Processing
@pytest.mark.asyncio
async def test_process_closed_kline(data_processor):
    """Test processing a single closed Kline for an active pair/timeframe."""
    # Create a sample closed kline
    kline_closed = Kline(
        timestamp=1000,
        open=10.0,
        high=12.0,
        low=9.0,
        close=11.0,
        volume=100.0,
        is_closed=True,
        symbol="BTCUSDT",
        interval="1m"
    )
    
    # Process the kline
    await data_processor.process_kline(kline_closed)
    
    # Check that kline was added to the buffer
    assert len(data_processor.kline_buffers["BTCUSDT"]["1m"]) == 1
    assert data_processor.kline_buffers["BTCUSDT"]["1m"][0] == kline_closed
    
    # Check that indicator data was updated (should exist even if values are NA)
    indicator_df = data_processor.get_indicator_dataframe("BTCUSDT", "1m")
    assert indicator_df is not None
    assert not indicator_df.empty
    assert kline_closed.timestamp in indicator_df.index
    assert "sma_short" in indicator_df.columns
    assert "sma_long" in indicator_df.columns

@pytest.mark.asyncio
async def test_process_unclosed_kline(data_processor):
    """Test processing a single unclosed Kline for an active pair/timeframe."""
    # Create a sample unclosed kline
    kline_unclosed = Kline(
        timestamp=1000,
        open=10.0,
        high=12.0,
        low=9.0,
        close=11.0,
        volume=100.0,
        is_closed=False,
        symbol="BTCUSDT",
        interval="1m"
    )
    
    # Process the kline
    await data_processor.process_kline(kline_unclosed)
    
    # Check that kline was added to the buffer
    assert len(data_processor.kline_buffers["BTCUSDT"]["1m"]) == 1
    assert data_processor.kline_buffers["BTCUSDT"]["1m"][0] == kline_unclosed
    
    # Check if indicator data exists (should be empty since only unclosed kline was processed)
    indicator_df = data_processor.get_indicator_dataframe("BTCUSDT", "1m")
    if indicator_df is not None and not indicator_df.empty:
        # Implementation may or may not update indicators for unclosed candles
        # Just check the structure exists
        assert kline_unclosed.timestamp in indicator_df.index
        assert "sma_short" in indicator_df.columns
        assert "sma_long" in indicator_df.columns

@pytest.mark.asyncio
async def test_update_unclosed_kline(data_processor):
    """Test updating the last unclosed Kline."""
    # Create initial unclosed kline
    kline_unclosed_t1 = Kline(
        timestamp=1000,
        open=10.0,
        high=11.0,
        low=9.0,
        close=10.5,
        volume=50.0,
        is_closed=False,
        symbol="BTCUSDT",
        interval="1m"
    )
    
    # Process the initial kline
    await data_processor.process_kline(kline_unclosed_t1)
    assert len(data_processor.kline_buffers["BTCUSDT"]["1m"]) == 1
    
    # Create an updated version of the same kline (same timestamp, different data)
    kline_unclosed_t1_update = Kline(
        timestamp=1000,
        open=10.0,
        high=12.0,  # Higher high
        low=8.5,    # Lower low
        close=11.0, # Different close
        volume=75.0, # More volume
        is_closed=False,
        symbol="BTCUSDT",
        interval="1m"
    )
    
    # Process the updated kline
    await data_processor.process_kline(kline_unclosed_t1_update)
    
    # Check that the deque contains only one element (the updated kline)
    assert len(data_processor.kline_buffers["BTCUSDT"]["1m"]) == 1
    assert data_processor.kline_buffers["BTCUSDT"]["1m"][0] == kline_unclosed_t1_update
    assert data_processor.kline_buffers["BTCUSDT"]["1m"][0].high == 12.0
    assert data_processor.kline_buffers["BTCUSDT"]["1m"][0].close == 11.0

@pytest.mark.asyncio
async def test_replace_unclosed_with_closed_kline(data_processor):
    """Test replacing the last unclosed Kline with its closed version."""
    # Create initial unclosed kline
    kline_unclosed_t1 = Kline(
        timestamp=1000,
        open=10.0,
        high=11.0,
        low=9.0,
        close=10.5,
        volume=50.0,
        is_closed=False,
        symbol="BTCUSDT",
        interval="1m"
    )
    
    # Process the unclosed kline
    await data_processor.process_kline(kline_unclosed_t1)
    assert len(data_processor.kline_buffers["BTCUSDT"]["1m"]) == 1
    assert not data_processor.kline_buffers["BTCUSDT"]["1m"][0].is_closed
    
    # Create closed version of the same kline
    kline_closed_t1 = Kline(
        timestamp=1000,
        open=10.0,
        high=11.5,
        low=9.0,
        close=11.0,
        volume=100.0,
        is_closed=True,  # Now closed
        symbol="BTCUSDT",
        interval="1m"
    )
    
    # Process the closed kline
    await data_processor.process_kline(kline_closed_t1)
    
    # Check that the deque contains one element (the closed kline)
    assert len(data_processor.kline_buffers["BTCUSDT"]["1m"]) == 1
    assert data_processor.kline_buffers["BTCUSDT"]["1m"][0] == kline_closed_t1
    assert data_processor.kline_buffers["BTCUSDT"]["1m"][0].is_closed is True
    
    # Check that indicator data was updated
    indicator_df = data_processor.get_indicator_dataframe("BTCUSDT", "1m")
    assert indicator_df is not None
    assert not indicator_df.empty
    assert kline_closed_t1.timestamp in indicator_df.index

@pytest.mark.asyncio
async def test_process_kline_inactive_pair(data_processor):
    """Test processing a Kline for an inactive pair/timeframe."""
    # Create a kline for an inactive pair
    kline_inactive = Kline(
        timestamp=1000,
        open=10.0,
        high=12.0,
        low=9.0,
        close=11.0,
        volume=100.0,
        is_closed=True,
        symbol="SOLUSDT",  # Disabled in config
        interval="1m"
    )
    
    # Process the kline
    await data_processor.process_kline(kline_inactive)
    
    # Check that kline was not processed (no buffer should exist)
    if "SOLUSDT" in data_processor.kline_buffers:
        assert not data_processor.kline_buffers["SOLUSDT"]["1m"]
    
    # Check that indicator data was not created
    indicator_df = data_processor.get_indicator_dataframe("SOLUSDT", "1m")
    if indicator_df is not None:
        assert indicator_df.empty

@pytest.mark.asyncio
async def test_buffer_limit_enforcement(data_processor):
    """Test that buffer size is limited to MAX_KLINE_BUFFER_LENGTH."""
    # Generate klines with sequential timestamps
    symbol = "BTCUSDT"
    interval = "1m"
    num_klines = MAX_KLINE_BUFFER_LENGTH + 5  # More than the max buffer length
    
    for i in range(num_klines):
        kline = Kline(
            timestamp=1000 + i,
            open=10.0,
            high=12.0,
            low=9.0,
            close=11.0,
            volume=100.0,
            is_closed=True,
            symbol=symbol,
            interval=interval
        )
        await data_processor.process_kline(kline)
    
    # Check that buffer size is limited to MAX_KLINE_BUFFER_LENGTH
    assert len(data_processor.kline_buffers[symbol][interval]) == MAX_KLINE_BUFFER_LENGTH
    
    # Check that oldest klines were discarded
    # First timestamp should be the earliest retained timestamp
    first_timestamp = data_processor.kline_buffers[symbol][interval][0].timestamp
    assert first_timestamp == 1000 + (num_klines - MAX_KLINE_BUFFER_LENGTH)

# Test Indicator Calculation
@pytest.mark.asyncio
async def test_insufficient_data_for_sma(data_processor, mock_config_manager_for_dp):
    """Test case where there's insufficient data for SMA calculation."""
    # Set shorter SMA periods for easier testing
    mock_config = mock_config_manager_for_dp.get_config()
    mock_config["global_settings"]["v1_strategy"]["sma_short_period"] = 3
    mock_config["global_settings"]["v1_strategy"]["sma_long_period"] = 5
    mock_config_manager_for_dp.get_config.return_value = mock_config
    
    # Initialize with new config
    dp = DataProcessor(config_manager=mock_config_manager_for_dp)
    
    symbol = "BTCUSDT"
    interval = "1m"
    
    # Process 2 klines (less than sma_short_period of 3)
    for i in range(2):
        kline = Kline(
            timestamp=1000 + i * 60000,  # 1-minute intervals
            open=100.0,
            high=110.0,
            low=90.0,
            close=100.0 + i,  # Different close prices
            volume=100.0,
            is_closed=True,
            symbol=symbol,
            interval=interval
        )
        await dp.process_kline(kline)
    
    # Check indicator dataframe
    df = dp.get_indicator_dataframe(symbol, interval)
    assert df is not None
    assert not df.empty
    assert "sma_short" in df.columns
    assert "sma_long" in df.columns
    
    # Check that SMA values are NaN due to insufficient data
    latest_row = df.iloc[-1]
    assert pd.isna(latest_row["sma_short"])
    assert pd.isna(latest_row["sma_long"])

@pytest.mark.asyncio
async def test_correct_sma_short_calculation(data_processor, mock_config_manager_for_dp):
    """Test correct calculation of short-period SMA."""
    # Set shorter SMA periods for easier testing
    mock_config = mock_config_manager_for_dp.get_config()
    mock_config["global_settings"]["v1_strategy"]["sma_short_period"] = 3
    mock_config["global_settings"]["v1_strategy"]["sma_long_period"] = 5
    mock_config_manager_for_dp.get_config.return_value = mock_config
    
    # Initialize with new config
    dp = DataProcessor(config_manager=mock_config_manager_for_dp)
    
    symbol = "BTCUSDT"
    interval = "1m"
    close_prices = [100.0, 110.0, 120.0, 130.0]
    
    # Process exactly sma_short_period + 1 klines
    for i, close in enumerate(close_prices):
        kline = Kline(
            timestamp=1000 + i * 60000,
            open=close,
            high=close + 10,
            low=close - 10,
            close=close,
            volume=100.0,
            is_closed=True,
            symbol=symbol,
            interval=interval
        )
        await dp.process_kline(kline)
    
    # Check indicator dataframe
    df = dp.get_indicator_dataframe(symbol, interval)
    assert df is not None
    assert len(df) == len(close_prices)
    
    # Calculate expected SMA values
    expected_sma3 = sum(close_prices[-3:]) / 3  # Average of last 3 values
    
    # Check SMA values
    latest_row = df.iloc[-1]
    assert latest_row["sma_short"] == pytest.approx(expected_sma3)
    assert pd.isna(latest_row["sma_long"])  # Not enough data for long SMA

@pytest.mark.asyncio
async def test_correct_sma_long_calculation(data_processor, mock_config_manager_for_dp):
    """Test correct calculation of long-period SMA."""
    # Set shorter SMA periods for easier testing
    mock_config = mock_config_manager_for_dp.get_config()
    mock_config["global_settings"]["v1_strategy"]["sma_short_period"] = 3
    mock_config["global_settings"]["v1_strategy"]["sma_long_period"] = 5
    mock_config_manager_for_dp.get_config.return_value = mock_config
    
    # Initialize with new config
    dp = DataProcessor(config_manager=mock_config_manager_for_dp)
    
    symbol = "BTCUSDT"
    interval = "1m"
    close_prices = [100.0, 110.0, 120.0, 130.0, 140.0, 150.0]
    
    # Process exactly sma_long_period + 1 klines
    for i, close in enumerate(close_prices):
        kline = Kline(
            timestamp=1000 + i * 60000,
            open=close,
            high=close + 10,
            low=close - 10,
            close=close,
            volume=100.0,
            is_closed=True,
            symbol=symbol,
            interval=interval
        )
        await dp.process_kline(kline)
    
    # Check indicator dataframe
    df = dp.get_indicator_dataframe(symbol, interval)
    assert df is not None
    assert len(df) == len(close_prices)
    
    # Calculate expected SMA values
    expected_sma3 = sum(close_prices[-3:]) / 3  # Average of last 3 values
    expected_sma5 = sum(close_prices[-5:]) / 5  # Average of last 5 values
    
    # Check SMA values
    latest_row = df.iloc[-1]
    assert latest_row["sma_short"] == pytest.approx(expected_sma3)
    assert latest_row["sma_long"] == pytest.approx(expected_sma5)

@pytest.mark.asyncio
async def test_sma_calculation_with_duplicate_timestamps(data_processor, mock_config_manager_for_dp):
    """Test that SMA calculation correctly handles duplicate timestamps."""
    # Set shorter SMA periods for easier testing
    mock_config = mock_config_manager_for_dp.get_config()
    mock_config["global_settings"]["v1_strategy"]["sma_short_period"] = 3
    mock_config["global_settings"]["v1_strategy"]["sma_long_period"] = 5
    mock_config_manager_for_dp.get_config.return_value = mock_config
    
    # Initialize with new config
    dp = DataProcessor(config_manager=mock_config_manager_for_dp)
    
    symbol = "BTCUSDT"
    interval = "1m"
    
    # Process klines with some duplicate timestamps
    klines_data = [
        # Original klines
        (1000, 100.0, False),
        (2000, 110.0, False),
        (3000, 120.0, False),
        (4000, 130.0, False),
        (5000, 140.0, False),
        # Updates with same timestamps but different values (should replace)
        (3000, 125.0, True),  # Update and close kline at t=3000
        (5000, 145.0, True),  # Update and close kline at t=5000
    ]
    
    for timestamp, close, is_closed in klines_data:
        kline = Kline(
            timestamp=timestamp,
            open=close - 10,
            high=close + 10,
            low=close - 20,
            close=close,
            volume=100.0,
            is_closed=is_closed,
            symbol=symbol,
            interval=interval
        )
        await dp.process_kline(kline)
    
    # Check indicator dataframe
    df = dp.get_indicator_dataframe(symbol, interval)
    assert df is not None
    
    # Check no duplicate timestamps in DataFrame
    assert len(df.index) == len(set(df.index))
    
    # Check that the updated values are used in the DataFrame
    assert df.loc[3000, "close"] == 125.0
    assert df.loc[5000, "close"] == 145.0
    
    # Calculate expected SMA values (using last values after updates)
    expected_values = [100.0, 110.0, 125.0, 130.0, 145.0]
    expected_sma3 = sum(expected_values[-3:]) / 3
    expected_sma5 = sum(expected_values) / 5
    
    # Check SMA calculations
    latest_row = df.iloc[-1]  # Should be the row for timestamp 5000
    assert latest_row["sma_short"] == pytest.approx(expected_sma3)
    assert latest_row["sma_long"] == pytest.approx(expected_sma5)

# Test Getter Methods
@pytest.mark.asyncio
async def test_getters_return_correct_data(data_processor, mock_config_manager_for_dp):
    """Test that getter methods return correct data after processing."""
    # Set shorter SMA periods for easier testing
    mock_config = mock_config_manager_for_dp.get_config()
    mock_config["global_settings"]["v1_strategy"]["sma_short_period"] = 3
    mock_config["global_settings"]["v1_strategy"]["sma_long_period"] = 5
    mock_config_manager_for_dp.get_config.return_value = mock_config
    
    # Initialize with new config
    dp = DataProcessor(config_manager=mock_config_manager_for_dp)
    
    symbol = "BTCUSDT"
    interval = "1m"
    
    # Process several klines
    klines = []
    for i in range(6):  # 6 klines
        kline = Kline(
            timestamp=1000 + i * 60000,
            open=100.0 + i,
            high=110.0 + i,
            low=90.0 + i,
            close=105.0 + i,
            volume=100.0 + i * 10,
            is_closed=True,
            symbol=symbol,
            interval=interval
        )
        klines.append(kline)
        await dp.process_kline(kline)
    
    # Test get_latest_kline
    latest_kline = dp.get_latest_kline(symbol, interval)
    assert latest_kline is not None
    assert latest_kline == klines[-1]
    
    # Test get_indicator_dataframe
    df = dp.get_indicator_dataframe(symbol, interval)
    assert df is not None
    assert not df.empty
    assert len(df) == len(klines)
    
    # Test get_latest_indicators
    latest_indicators = dp.get_latest_indicators(symbol, interval)
    assert latest_indicators is not None
    assert latest_indicators["timestamp"] == klines[-1].timestamp
    assert latest_indicators["close"] == klines[-1].close
    assert not pd.isna(latest_indicators["sma_short"])
    assert not pd.isna(latest_indicators["sma_long"])

@pytest.mark.asyncio
async def test_getters_return_none_for_nonexistent_data(data_processor):
    """Test that getters return None or empty DataFrame for non-existent symbol/timeframe."""
    # Test with non-existent symbol
    assert data_processor.get_latest_kline("NONEXISTENT", "1m") is None
    df = data_processor.get_indicator_dataframe("NONEXISTENT", "1m")
    if df is not None:
        assert df.empty
    assert data_processor.get_latest_indicators("NONEXISTENT", "1m") is None
    
    # Test with valid symbol but non-existent timeframe
    assert data_processor.get_latest_kline("BTCUSDT", "NONEXISTENT") is None
    df = data_processor.get_indicator_dataframe("BTCUSDT", "NONEXISTENT")
    if df is not None:
        assert df.empty
    assert data_processor.get_latest_indicators("BTCUSDT", "NONEXISTENT") is None

# Test Configuration Hot-Reload
@pytest.mark.asyncio
async def test_adding_new_active_pair_via_config_update(data_processor, mock_config_manager_for_dp):
    """Test that config update adds a new active pair correctly."""
    # Check initial state
    assert "SOLUSDT" not in data_processor._active_pairs_timeframes  # Initially disabled
    
    # Create new config with SOLUSDT enabled
    new_config = mock_config_manager_for_dp.get_config().copy()
    new_config["pairs"]["SOL_USDT"]["enabled"] = True
    new_config["pairs"]["SOL_USDT"]["indicator_timeframes"] = ["1m", "15m"]
    
    # Trigger config update
    data_processor._handle_config_update(new_config)
    
    # Check that SOLUSDT was added to active pairs
    assert "SOLUSDT" in data_processor._active_pairs_timeframes
    assert set(data_processor._active_pairs_timeframes["SOLUSDT"]) == {"1m", "15m"}
    
    # Check that buffers were created
    assert "SOLUSDT" in data_processor.kline_buffers
    assert "1m" in data_processor.kline_buffers["SOLUSDT"]
    assert "15m" in data_processor.kline_buffers["SOLUSDT"]
    assert isinstance(data_processor.kline_buffers["SOLUSDT"]["1m"], deque)
    assert isinstance(data_processor.kline_buffers["SOLUSDT"]["15m"], deque)
    assert data_processor.kline_buffers["SOLUSDT"]["1m"].maxlen == MAX_KLINE_BUFFER_LENGTH

@pytest.mark.asyncio
async def test_disabling_existing_pair_via_config_update(data_processor, mock_config_manager_for_dp):
    """Test that config update correctly disables an active pair."""
    # Check initial state
    assert "BTCUSDT" in data_processor._active_pairs_timeframes  # Initially enabled
    
    # Create new config with BTCUSDT disabled
    new_config = mock_config_manager_for_dp.get_config().copy()
    new_config["pairs"]["BTC_USDT"]["enabled"] = False
    
    # Trigger config update
    data_processor._handle_config_update(new_config)
    
    # Check that BTCUSDT was removed from active pairs
    assert "BTCUSDT" not in data_processor._active_pairs_timeframes
    
    # Note: The current implementation might not remove old buffers, just stop processing for them
    # So we won't assert on the removal of buffers, just on the active pairs list

@pytest.mark.asyncio
async def test_changing_timeframes_via_config_update(data_processor, mock_config_manager_for_dp):
    """Test that config update correctly changes timeframes for an active pair."""
    # Check initial state for ETHUSDT
    assert "ETHUSDT" in data_processor._active_pairs_timeframes
    assert set(data_processor._active_pairs_timeframes["ETHUSDT"]) == {"1m", "5m", "15m"}
    
    # Create new config with different timeframes for ETHUSDT
    new_config = mock_config_manager_for_dp.get_config().copy()
    new_config["pairs"]["ETH_USDT"]["indicator_timeframes"] = ["5m", "30m"]  # Changed timeframes
    
    # Trigger config update
    data_processor._handle_config_update(new_config)
    
    # Check that timeframes were updated
    assert "ETHUSDT" in data_processor._active_pairs_timeframes
    assert set(data_processor._active_pairs_timeframes["ETHUSDT"]) == {"5m", "30m"}
    
    # Check that new buffer for 30m timeframe was created
    assert "30m" in data_processor.kline_buffers["ETHUSDT"]
    assert isinstance(data_processor.kline_buffers["ETHUSDT"]["30m"], deque)




================================================
FILE: tests/unit/test_models.py
================================================
import pytest
import time
from pydantic import ValidationError

from src.models import Kline, PairConfig, TradeSignal, TradeDirection, Order, OrderStatus, OrderType, OrderSide, Position

def test_kline_creation():
    ts = int(time.time() * 1000)
    kline = Kline(
        timestamp=ts, open=100, high=110, low=90, close=105, volume=1000,
        is_closed=True, symbol="BTCUSDT", interval="1m"
    )
    assert kline.timestamp == ts
    assert kline.close == 105
    assert kline.symbol == "BTCUSDT"
    assert kline.is_closed is True

def test_pair_config_creation():
    pc = PairConfig(symbol="BTC_USDT", enabled=True, leverage=20, contract_type="USDT_M")
    assert pc.symbol == "BTC_USDT"
    assert pc.leverage == 20
    assert pc.contract_type == "USDT_M"

    with pytest.raises(ValidationError):
        PairConfig(symbol="BTCUSDT", enabled=True) # Invalid symbol format for config
    
    pc_coinm = PairConfig(symbol="BTCUSD_PERP", enabled=True, contract_type="COIN_M")
    assert pc_coinm.symbol == "BTCUSD_PERP"
    assert pc_coinm.contract_type == "COIN_M"

def test_trade_signal_creation():
    ts = int(time.time() * 1000)
    signal = TradeSignal(
        timestamp=ts, symbol="ETHUSDT", config_symbol="ETH_USDT", contract_type="USDT_M",
        direction=TradeDirection.SHORT, entry_price=2000, stop_loss_price=2100, take_profit_price=1800,
        strategy_name="TestStrategy"
    )
    assert signal.symbol == "ETHUSDT"
    assert signal.direction == TradeDirection.SHORT
    assert signal.take_profit_price == 1800

def test_order_creation():
    ts = int(time.time() * 1000)
    order = Order(
        order_id="ord123", symbol="LINKUSDT", type=OrderType.LIMIT, side=OrderSide.BUY,
        quantity=100, price=15.0, status=OrderStatus.NEW, timestamp=ts
    )
    assert order.order_id == "ord123"
    assert order.type == OrderType.LIMIT
    assert order.status == OrderStatus.NEW

    market_order = Order(
        order_id="ord124", symbol="ADAUSDT", type=OrderType.MARKET, side=OrderSide.SELL,
        quantity=1000, status=OrderStatus.FILLED, timestamp=ts, avg_fill_price=0.45, filled_quantity=1000
    )
    assert market_order.type == OrderType.MARKET
    assert market_order.avg_fill_price == 0.45

def test_position_creation():
    ts = int(time.time() * 1000)
    position = Position(
        symbol="SOLUSDT", contract_type="USDT_M", side=TradeDirection.LONG, entry_price=40.0,
        quantity=10, leverage=10, margin_type="ISOLATED", entry_timestamp=ts,
        entry_order_id="entry_sol_1", sl_order_id="sl_sol_1", tp_order_id="tp_sol_1",
        current_sl_price=38.0, current_tp_price=45.0
    )
    assert position.symbol == "SOLUSDT"
    assert position.side == TradeDirection.LONG
    assert position.current_sl_price == 38.0

# Test enums
def test_trade_direction_values():
    assert TradeDirection.LONG.value == "BUY"
    assert TradeDirection.SHORT.value == "SELL"

def test_order_status_values():
    assert OrderStatus.NEW.value == "NEW"
    assert OrderStatus.FILLED.value == "FILLED"
    # ... add more checks if needed

def test_order_type_values():
    assert OrderType.MARKET.value == "MARKET"
    assert OrderType.LIMIT.value == "LIMIT"
    # ... add more checks if needed

def test_order_side_values():
    assert OrderSide.BUY.value == "BUY"
    assert OrderSide.SELL.value == "SELL"

# Test validation if any complex validators were added
# Example: Kline timestamp must be positive
@pytest.mark.parametrize("invalid_ts", [-100, 0])
def test_kline_invalid_timestamp(invalid_ts):
    # Assuming Pydantic models implicitly validate types, but explicit validators can be tested.
    # If Kline had a validator for timestamp > 0:
    # with pytest.raises(ValidationError):
    #     Kline(timestamp=invalid_ts, open=1, high=2, low=0, close=1, volume=10, is_closed=True)
    pass # No explicit validator for this in current model, Pydantic handles type (int)

@pytest.mark.parametrize(
    "symbol_input, expected_output, should_raise",
    [
        ("BTC_USDT", "BTC_USDT", False),
        ("ETH_USD", "ETH_USD", False),
        ("BTCUSD_PERP", "BTCUSD_PERP", False),
        ("BTCUSDT", "BTCUSDT", True), # Fails because _ is missing for USDT_M style
        ("btcusd_perp", "btcusd_perp", False), # Passes as it ends with PERP
    ]
)
def test_pair_config_symbol_validation(symbol_input, expected_output, should_raise):
    if should_raise:
        with pytest.raises(ValidationError):
            PairConfig(symbol=symbol_input, enabled=True)
    else:
        pc = PairConfig(symbol=symbol_input, enabled=True)
        assert pc.symbol == expected_output




================================================
FILE: tests/unit/test_monitoring.py
================================================
import pytest
import asyncio
import time
from unittest.mock import patch, MagicMock
from prometheus_client import REGISTRY

from src.monitoring import PrometheusMonitor

@pytest.fixture
def monitor():
    """Fixture that provides a PrometheusMonitor instance for testing"""
    # Use a high port number to avoid conflicts with any running services
    test_port = 9999
    monitor = PrometheusMonitor(port=test_port)
    yield monitor
    
    # Clean up after test
    monitor._server_started = False
    
    # Clear Prometheus registry to avoid interference between tests
    collectors = list(REGISTRY._collector_to_names.keys())
    for collector in collectors:
        REGISTRY.unregister(collector)


class TestPrometheusMonitor:
    """Tests for the PrometheusMonitor class"""

    def test_initialization(self, monitor):
        """Test that the monitor initializes with the correct metric types"""
        # Check counters
        assert hasattr(monitor, "bot_errors_total")
        assert hasattr(monitor, "websocket_messages_received_total")
        assert hasattr(monitor, "kline_processed_total")
        assert hasattr(monitor, "signals_generated_total")
        assert hasattr(monitor, "orders_placed_total")
        assert hasattr(monitor, "orders_failed_total")
        assert hasattr(monitor, "orders_filled_total")
        
        # Check gauges
        assert hasattr(monitor, "bot_uptime_seconds")
        assert hasattr(monitor, "indicator_calculation_duration_seconds")
        assert hasattr(monitor, "active_positions_count")
        assert hasattr(monitor, "position_pnl_unrealized")
        
        # Check enum
        assert hasattr(monitor, "websocket_connection_status")
        
        # Check info
        assert hasattr(monitor, "bot_info")
        
        # Verify internal state
        assert monitor._server_started is False
        assert isinstance(monitor.port, int)

    @patch('src.monitoring.start_http_server')
    def test_start_method(self, mock_start_http_server, monitor):
        """Test that the start method correctly initializes the HTTP server and metrics"""
        # Test normal start
        monitor.start()
        
        # Verify HTTP server was started with correct port
        mock_start_http_server.assert_called_once_with(monitor.port)
        
        # Verify server started flag is set
        assert monitor._server_started is True
        
        # Check bot_info metric was set
        # For Info metrics, we can only verify it exists as get_sample_value
        # doesn't work the same way for this type
        assert hasattr(monitor, "bot_info")
        
        # Test starting again (should log warning and do nothing)
        monitor.start()
        # Mock should still have been called only once
        mock_start_http_server.assert_called_once()

    @patch('src.monitoring.start_http_server')
    def test_start_method_error_handling(self, mock_start_http_server, monitor):
        """Test error handling when starting the HTTP server fails"""
        # Configure mock to raise an exception
        mock_start_http_server.side_effect = OSError("Port in use")
        
        # Call start method
        monitor.start()
        
        # Verify server started flag remains False
        assert monitor._server_started is False
        
        # Test with a different exception type
        mock_start_http_server.side_effect = Exception("Unknown error")
        
        # Call start method
        monitor.start()
        
        # Verify server started flag remains False
        assert monitor._server_started is False

    def test_stop_method(self, monitor):
        """Test the stop method"""
        # Set the server as started
        monitor._server_started = True
        
        # Call stop method
        monitor.stop()
        
        # Verify server started flag is reset
        assert monitor._server_started is False

    @pytest.mark.asyncio
    @patch('src.monitoring.asyncio.create_task')
    @patch('src.monitoring.start_http_server')
    async def test_uptime_task_creation(self, mock_start_http_server, mock_create_task, monitor):
        """Test that the uptime update task is created correctly"""
        # Start the monitor
        monitor.start()
        
        # Verify create_task was called with the _update_uptime_periodically coroutine
        mock_create_task.assert_called_once()
        
        # The first argument to the first call should be a coroutine
        call_args = mock_create_task.call_args[0][0]
        assert asyncio.iscoroutine(call_args)

    @pytest.mark.asyncio
    async def test_update_uptime_directly(self, monitor):
        """Test the _update_uptime_periodically method directly by calling it once"""
        # Set server as started
        monitor._server_started = True
        
        # Record the start time
        monitor.start_time = time.time() - 10  # pretend we started 10 seconds ago
        
        # Call the method once (manually)
        monitor.bot_uptime_seconds.set(time.time() - monitor.start_time)
        
        # Verify uptime is approximately 10 seconds (with some tolerance)
        uptime = REGISTRY.get_sample_value('trading_bot_uptime_seconds')
        assert uptime is not None
        assert 9.5 <= uptime <= 10.5  # Allow for small timing differences

    def test_inc_bot_error(self, monitor):
        """Test the inc_bot_error method"""
        # Call the method with different labels
        monitor.inc_bot_error(module="TestModule", error_type="TestError")
        monitor.inc_bot_error(module="TestModule", error_type="AnotherError")
        monitor.inc_bot_error(module="AnotherModule", error_type="TestError")
        # Call again with the same labels
        monitor.inc_bot_error(module="TestModule", error_type="TestError")
        
        # Verify counters are incremented correctly
        assert REGISTRY.get_sample_value('trading_bot_errors_total', 
                                       {'module': 'TestModule', 'error_type': 'TestError'}) == 2
        assert REGISTRY.get_sample_value('trading_bot_errors_total', 
                                       {'module': 'TestModule', 'error_type': 'AnotherError'}) == 1
        assert REGISTRY.get_sample_value('trading_bot_errors_total', 
                                       {'module': 'AnotherModule', 'error_type': 'TestError'}) == 1

    def test_set_websocket_status(self, monitor):
        """Test the set_websocket_status method with valid and invalid states"""
        # Test valid states
        monitor.set_websocket_status(market_type="USDT_M", status="connected")
        
        # Check connected=1, others=0
        assert REGISTRY.get_sample_value('trading_bot_websocket_connection_status', 
                                      {'market_type': 'USDT_M', 'trading_bot_websocket_connection_status': 'connected'}) == 1
        assert REGISTRY.get_sample_value('trading_bot_websocket_connection_status', 
                                      {'market_type': 'USDT_M', 'trading_bot_websocket_connection_status': 'disconnected'}) == 0
        
        # Change status
        monitor.set_websocket_status(market_type="USDT_M", status="disconnected")
        
        # Check disconnected=1, others=0
        assert REGISTRY.get_sample_value('trading_bot_websocket_connection_status', 
                                      {'market_type': 'USDT_M', 'trading_bot_websocket_connection_status': 'disconnected'}) == 1
        assert REGISTRY.get_sample_value('trading_bot_websocket_connection_status', 
                                      {'market_type': 'USDT_M', 'trading_bot_websocket_connection_status': 'connected'}) == 0
        
        # Test invalid state
        monitor.set_websocket_status(market_type="USDT_M", status="invalid_state")
        
        # Should set to "error" state
        assert REGISTRY.get_sample_value('trading_bot_websocket_connection_status', 
                                      {'market_type': 'USDT_M', 'trading_bot_websocket_connection_status': 'error'}) == 1
        assert REGISTRY.get_sample_value('trading_bot_websocket_connection_status', 
                                      {'market_type': 'USDT_M', 'trading_bot_websocket_connection_status': 'disconnected'}) == 0

    def test_inc_websocket_message(self, monitor):
        """Test the inc_websocket_message method"""
        # Call the method with different labels
        monitor.inc_websocket_message(market_type="USDT_M", message_type="kline")
        monitor.inc_websocket_message(market_type="USDT_M", message_type="kline")
        monitor.inc_websocket_message(market_type="COIN_M", message_type="depthUpdate")
        
        # Verify counters are incremented correctly
        assert REGISTRY.get_sample_value('trading_bot_websocket_messages_received_total', 
                                       {'market_type': 'USDT_M', 'message_type': 'kline'}) == 2
        assert REGISTRY.get_sample_value('trading_bot_websocket_messages_received_total', 
                                       {'market_type': 'COIN_M', 'message_type': 'depthUpdate'}) == 1

    def test_inc_kline_processed(self, monitor):
        """Test the inc_kline_processed method"""
        # Call the method with different labels
        monitor.inc_kline_processed(symbol="BTCUSDT", interval="1m")
        monitor.inc_kline_processed(symbol="BTCUSDT", interval="1m")
        monitor.inc_kline_processed(symbol="ETHUSDT", interval="5m")
        
        # Verify counters are incremented correctly
        assert REGISTRY.get_sample_value('trading_bot_klines_processed_total', 
                                       {'symbol': 'BTCUSDT', 'interval': '1m'}) == 2
        assert REGISTRY.get_sample_value('trading_bot_klines_processed_total', 
                                       {'symbol': 'ETHUSDT', 'interval': '5m'}) == 1

    def test_set_indicator_calculation_duration(self, monitor):
        """Test the set_indicator_calculation_duration method"""
        # Call the method with different labels and values
        monitor.set_indicator_calculation_duration(symbol="BTCUSDT", interval="1m", duration_seconds=0.123)
        monitor.set_indicator_calculation_duration(symbol="ETHUSDT", interval="5m", duration_seconds=0.456)
        
        # Update value for first label set
        monitor.set_indicator_calculation_duration(symbol="BTCUSDT", interval="1m", duration_seconds=0.789)
        
        # Verify gauge values reflect the last set value
        assert REGISTRY.get_sample_value('trading_bot_indicator_calculation_duration_seconds', 
                                       {'symbol': 'BTCUSDT', 'interval': '1m'}) == 0.789
        assert REGISTRY.get_sample_value('trading_bot_indicator_calculation_duration_seconds', 
                                       {'symbol': 'ETHUSDT', 'interval': '5m'}) == 0.456

    def test_inc_signal_generated(self, monitor):
        """Test the inc_signal_generated method"""
        # Call the method with different labels
        monitor.inc_signal_generated(symbol="BTCUSDT", strategy="V1_SMA", direction="LONG")
        monitor.inc_signal_generated(symbol="BTCUSDT", strategy="V1_SMA", direction="LONG")
        monitor.inc_signal_generated(symbol="ETHUSDT", strategy="V1_SMA", direction="SHORT")
        
        # Verify counters are incremented correctly
        assert REGISTRY.get_sample_value('trading_bot_signals_generated_total', 
                                       {'symbol': 'BTCUSDT', 'strategy': 'V1_SMA', 'direction': 'LONG'}) == 2
        assert REGISTRY.get_sample_value('trading_bot_signals_generated_total', 
                                       {'symbol': 'ETHUSDT', 'strategy': 'V1_SMA', 'direction': 'SHORT'}) == 1

    def test_inc_order_placed(self, monitor):
        """Test the inc_order_placed method"""
        # Call the method with different labels
        monitor.inc_order_placed(symbol="BTCUSDT", order_type="MARKET", side="BUY")
        monitor.inc_order_placed(symbol="BTCUSDT", order_type="MARKET", side="BUY")
        monitor.inc_order_placed(symbol="ETHUSDT", order_type="LIMIT", side="SELL")
        
        # Verify counters are incremented correctly
        assert REGISTRY.get_sample_value('trading_bot_orders_placed_total', 
                                       {'symbol': 'BTCUSDT', 'order_type': 'MARKET', 'side': 'BUY'}) == 2
        assert REGISTRY.get_sample_value('trading_bot_orders_placed_total', 
                                       {'symbol': 'ETHUSDT', 'order_type': 'LIMIT', 'side': 'SELL'}) == 1

    def test_inc_order_failed(self, monitor):
        """Test the inc_order_failed method"""
        # Call the method with different labels
        monitor.inc_order_failed(symbol="BTCUSDT", reason="INSUFFICIENT_BALANCE")
        monitor.inc_order_failed(symbol="BTCUSDT", reason="INSUFFICIENT_BALANCE")
        monitor.inc_order_failed(symbol="ETHUSDT", reason="PRICE_FILTER")
        
        # Verify counters are incremented correctly
        assert REGISTRY.get_sample_value('trading_bot_orders_failed_total', 
                                       {'symbol': 'BTCUSDT', 'reason': 'INSUFFICIENT_BALANCE'}) == 2
        assert REGISTRY.get_sample_value('trading_bot_orders_failed_total', 
                                       {'symbol': 'ETHUSDT', 'reason': 'PRICE_FILTER'}) == 1

    def test_inc_order_filled(self, monitor):
        """Test the inc_order_filled method"""
        # Call the method with different labels
        monitor.inc_order_filled(symbol="BTCUSDT", order_type="MARKET", side="BUY")
        monitor.inc_order_filled(symbol="BTCUSDT", order_type="MARKET", side="BUY")
        monitor.inc_order_filled(symbol="ETHUSDT", order_type="LIMIT", side="SELL")
        
        # Verify counters are incremented correctly
        assert REGISTRY.get_sample_value('trading_bot_orders_filled_total', 
                                       {'symbol': 'BTCUSDT', 'order_type': 'MARKET', 'side': 'BUY'}) == 2
        assert REGISTRY.get_sample_value('trading_bot_orders_filled_total', 
                                       {'symbol': 'ETHUSDT', 'order_type': 'LIMIT', 'side': 'SELL'}) == 1

    def test_set_active_positions_count(self, monitor):
        """Test the set_active_positions_count method"""
        # Call the method with different labels and values
        monitor.set_active_positions_count(contract_type="USDT_M", count=5)
        monitor.set_active_positions_count(contract_type="COIN_M", count=3)
        
        # Update value for first label set
        monitor.set_active_positions_count(contract_type="USDT_M", count=7)
        
        # Verify gauge values reflect the last set value
        assert REGISTRY.get_sample_value('trading_bot_active_positions_count', 
                                       {'contract_type': 'USDT_M'}) == 7
        assert REGISTRY.get_sample_value('trading_bot_active_positions_count', 
                                       {'contract_type': 'COIN_M'}) == 3

    def test_update_active_positions_gauge(self, monitor):
        """Test the update_active_positions_gauge method"""
        # Call the method
        monitor.update_active_positions_gauge(positions_usdt_m=5, positions_coin_m=3)
        
        # Verify both gauges are set correctly
        assert REGISTRY.get_sample_value('trading_bot_active_positions_count', 
                                       {'contract_type': 'USDT_M'}) == 5
        assert REGISTRY.get_sample_value('trading_bot_active_positions_count', 
                                       {'contract_type': 'COIN_M'}) == 3
        
        # Update with new values
        monitor.update_active_positions_gauge(positions_usdt_m=7, positions_coin_m=2)
        
        # Verify both gauges reflect the updated values
        assert REGISTRY.get_sample_value('trading_bot_active_positions_count', 
                                       {'contract_type': 'USDT_M'}) == 7
        assert REGISTRY.get_sample_value('trading_bot_active_positions_count', 
                                       {'contract_type': 'COIN_M'}) == 2

    def test_set_position_pnl(self, monitor):
        """Test the set_position_pnl method"""
        # Call the method with different labels and values
        monitor.set_position_pnl(symbol="BTCUSDT", pnl=10.5)
        monitor.set_position_pnl(symbol="ETHUSDT", pnl=-5.25)
        
        # Update value for first label
        monitor.set_position_pnl(symbol="BTCUSDT", pnl=15.75)
        
        # Verify gauge values reflect the last set value
        assert REGISTRY.get_sample_value('trading_bot_position_pnl_unrealized', 
                                       {'symbol': 'BTCUSDT'}) == 15.75
        assert REGISTRY.get_sample_value('trading_bot_position_pnl_unrealized', 
                                       {'symbol': 'ETHUSDT'}) == -5.25 


================================================
FILE: tests/unit/test_order_manager.py
================================================
import pytest
import asyncio
from unittest.mock import AsyncMock, MagicMock, patch
from math import isclose

from src.config_loader import ConfigManager
from src.connectors import BinanceRESTClient
from src.order_manager import OrderManager
from src.models import TradeSignal, TradeDirection, OrderType, OrderSide, Position, OrderStatus

@pytest.fixture
def mock_config_manager_for_om():
    cm = MagicMock(spec=ConfigManager)
    cm.get_config.return_value = {
        "api": {"binance_api_key": "TEST_KEY", "binance_api_secret": "TEST_SECRET"},
        "global_settings": {
            "v1_strategy": {
                "default_margin_usdt": 50.0,
                "default_leverage": 10,
                "margin_mode": "ISOLATED"
            }
        },
        "pairs": {
            "BTC_USDT": {
                "enabled": True, 
                "contract_type": "USDT_M", 
                "margin_usdt": 100.0, # Override global
                "leverage": 20 # Override global
            },
            "ETHUSD_PERP": {
                "enabled": True, 
                "contract_type": "COIN_M", 
                "margin_coin": 0.1, # Interpreted as num_contracts for MVP test
                "leverage": 5
            }
        }
    }
    return cm

@pytest.fixture
def mock_rest_client_for_om():
    rest_client = AsyncMock(spec=BinanceRESTClient)
    # Mock exchange info for precision and limits
    rest_client.fetch_exchange_info.return_value = {
        "BTCUSDT": {
            "symbol": "BTCUSDT",
            "precision": {"amount": "0.00001", "price": "0.01"},
            "limits": {"cost": {"min": "5.0"}, "amount": {"min": "0.00001"}}
        },
        "ETHUSD_PERP": {
            "symbol": "ETHUSD_PERP",
            "precision": {"amount": "0.001", "price": "0.01"}, # COIN-M contracts might be integers or decimals
            "limits": {"cost": {"min": "5.0"}, "amount": {"min": "0.001"}}
        }
    }
    
    # Properly mock create_order to return a dictionary directly
    async def mock_create_order(symbol, order_type, side, amount, price=None, params={}):
        return {
            "id": f"mock_order_{symbol}_{int(asyncio.get_event_loop().time()*1000)}",
            "symbol": symbol,
            "status": "NEW", 
            "avgPrice": str(price or params.get("stopPrice") or (50000.0 if "BTC" in symbol else 3000.0)),
            "type": order_type
        }
    
    rest_client.create_order.side_effect = mock_create_order
    return rest_client

@pytest.fixture
def order_manager(mock_config_manager_for_om, mock_rest_client_for_om):
    om = OrderManager(config_manager=mock_config_manager_for_om, rest_client=mock_rest_client_for_om)
    # Prime the cache for exchange info to avoid repeated calls in tests unless specifically testing cache miss
    async def prime_cache():
        # Make sure the exchange_info_cache is properly set with the values we expect
        om.exchange_info_cache = {
            "BTCUSDT": {
                "symbol": "BTCUSDT",
                "precision": {"amount": "0.00001", "price": "0.01"},
                "limits": {"cost": {"min": "5.0"}, "amount": {"min": "0.00001"}}
            },
            "ETHUSD_PERP": {
                "symbol": "ETHUSD_PERP",
                "precision": {"amount": "0.001", "price": "0.01"},
                "limits": {"cost": {"min": "5.0"}, "amount": {"min": "0.001"}}
            }
        }
    asyncio.run(prime_cache())
    return om

# Tests for Precision and Filter Logic
@pytest.mark.asyncio
async def test_om_adjust_quantity_to_precision(order_manager):
    """Test quantity adjustment to precision based on step size."""
    # Use almost equal for floating point comparisons
    
    result = order_manager._adjust_quantity_to_precision(0.123456, 0.001)
    assert isclose(result, 0.123, rel_tol=1e-10), f"Expected 0.123, got {result}"
    
    result = order_manager._adjust_quantity_to_precision(0.123, 0.0001)
    assert isclose(result, 0.123, rel_tol=1e-10), f"Expected 0.123, got {result}"
    
    result = order_manager._adjust_quantity_to_precision(123.456, 1.0)
    assert isclose(result, 123.0, rel_tol=1e-10), f"Expected 123.0, got {result}"
    
    # Expected to be 0.99999 (multiple of 0.00001)
    result = order_manager._adjust_quantity_to_precision(0.99999, 0.00001)
    assert isclose(result, 0.99999, rel_tol=1e-10), f"Expected 0.99999, got {result}"
    
    # Floor behavior - 0.000005 is less than 0.00001
    result = order_manager._adjust_quantity_to_precision(0.000005, 0.00001)
    assert isclose(result, 0.0, rel_tol=1e-10), f"Expected 0.0, got {result}"
    
    # Test with zero step size (should return original value)
    result = order_manager._adjust_quantity_to_precision(123.456, 0)
    assert isclose(result, 123.456, rel_tol=1e-10), f"Expected 123.456, got {result}"

@pytest.mark.asyncio
async def test_om_adjust_price_to_precision(order_manager):
    """Test price adjustment to precision based on tick size."""
    assert order_manager._adjust_price_to_precision(123.456, 0.01) == 123.46 # Rounds
    assert order_manager._adjust_price_to_precision(123.454, 0.01) == 123.45
    assert order_manager._adjust_price_to_precision(123.5, 1.0) == 124.0
    assert order_manager._adjust_price_to_precision(50000.557, 0.01) == 50000.56
    # Test with zero tick size (should return original value)
    assert order_manager._adjust_price_to_precision(123.456, 0) == 123.456

@pytest.mark.asyncio
async def test_om_get_symbol_filters(order_manager, mock_rest_client_for_om):
    """Test retrieving correct symbol filters from exchange info."""
    # Test for BTCUSDT
    lot_step, price_tick, min_notional = await order_manager._get_symbol_filters("BTCUSDT")
    assert lot_step == 0.00001
    assert price_tick == 0.01
    assert min_notional == 5.0
    
    # Test for ETHUSD_PERP
    lot_step, price_tick, min_notional = await order_manager._get_symbol_filters("ETHUSD_PERP")
    assert lot_step == 0.001
    assert price_tick == 0.01
    assert min_notional == 5.0
    
    # Verify cache is used (fetch_exchange_info should not be called again)
    mock_rest_client_for_om.fetch_exchange_info.reset_mock()
    await order_manager._get_symbol_filters("BTCUSDT")
    mock_rest_client_for_om.fetch_exchange_info.assert_not_called()

@pytest.mark.asyncio
async def test_om_get_symbol_filters_with_missing_data(order_manager, mock_rest_client_for_om):
    """Test handling missing filter data gracefully."""
    # Clear the cache to force a new fetch
    order_manager.exchange_info_cache = {}
    
    # Mock the response with missing data
    mock_rest_client_for_om.fetch_exchange_info.return_value = {
        "BTCUSDT": {
            "symbol": "BTCUSDT",
            # Missing precision and limits data
        }
    }
    
    lot_step, price_tick, min_notional = await order_manager._get_symbol_filters("BTCUSDT")
    assert lot_step is None
    assert price_tick is None
    assert min_notional is None

@pytest.mark.asyncio
async def test_om_get_symbol_filters_fetch_failure(order_manager, mock_rest_client_for_om):
    """Test handling exchange info fetch failure."""
    # Clear the cache to force a new fetch
    order_manager.exchange_info_cache = {}
    
    # Mock fetch_exchange_info to return None (failure)
    mock_rest_client_for_om.fetch_exchange_info.return_value = None
    
    lot_step, price_tick, min_notional = await order_manager._get_symbol_filters("BTCUSDT")
    assert lot_step is None
    assert price_tick is None
    assert min_notional is None

# Tests for Position Sizing
@pytest.mark.asyncio
async def test_om_quantity_calculation_usdt_m(order_manager, mock_rest_client_for_om):
    """Test correct quantity calculation for USDT-M pair."""
    mock_rest_client_for_om.create_order.reset_mock()
    
    signal = TradeSignal(
        symbol="BTCUSDT", config_symbol="BTC_USDT", contract_type="USDT_M",
        direction=TradeDirection.LONG, entry_price=50000.0,
        stop_loss_price=49000.0, take_profit_price=53000.0
    )
    
    await order_manager.handle_trade_signal(signal)
    
    # Expected quantity: (100 USDT margin * 20x leverage) / 50000 entry = 0.04 BTC
    expected_quantity = 0.04
    
    assert mock_rest_client_for_om.create_order.call_count == 3
    entry_call = mock_rest_client_for_om.create_order.call_args_list[0]
    assert entry_call[1]["amount"] == expected_quantity

@pytest.mark.asyncio
async def test_om_quantity_calculation_coin_m(order_manager, mock_rest_client_for_om):
    """Test correct quantity calculation for COIN-M pair (MVP: margin_coin = number of contracts)."""
    mock_rest_client_for_om.create_order.reset_mock()
    
    signal = TradeSignal(
        symbol="ETHUSD_PERP", config_symbol="ETHUSD_PERP", contract_type="COIN_M",
        direction=TradeDirection.LONG, entry_price=3000.0,
        stop_loss_price=2900.0, take_profit_price=3300.0
    )
    
    await order_manager.handle_trade_signal(signal)
    
    # For COIN-M in MVP, margin_coin (0.1) is used directly as the quantity
    expected_quantity = 0.1
    
    assert mock_rest_client_for_om.create_order.call_count == 3
    entry_call = mock_rest_client_for_om.create_order.call_args_list[0]
    assert entry_call[1]["amount"] == expected_quantity

@pytest.mark.asyncio
async def test_om_missing_margin_configuration(order_manager, mock_rest_client_for_om):
    """Test handling missing margin configuration."""
    mock_rest_client_for_om.create_order.reset_mock()
    
    # Create a new config with missing margin settings for BTC_USDT
    config = order_manager.config_manager.get_config.return_value.copy()
    config["pairs"]["BTC_USDT"].pop("margin_usdt")  # Remove margin_usdt
    config["global_settings"]["v1_strategy"].pop("default_margin_usdt")  # Remove default margin
    order_manager.config_manager.get_config.return_value = config
    
    signal = TradeSignal(
        symbol="BTCUSDT", config_symbol="BTC_USDT", contract_type="USDT_M",
        direction=TradeDirection.LONG, entry_price=50000.0,
        stop_loss_price=49000.0, take_profit_price=53000.0
    )
    
    await order_manager.handle_trade_signal(signal)
    
    # No orders should be placed due to missing margin configuration
    assert mock_rest_client_for_om.create_order.call_count == 0

@pytest.mark.asyncio
async def test_om_zero_entry_price(order_manager, mock_rest_client_for_om):
    """Test handling zero or invalid entry price."""
    mock_rest_client_for_om.create_order.reset_mock()
    
    signal = TradeSignal(
        symbol="BTCUSDT", config_symbol="BTC_USDT", contract_type="USDT_M",
        direction=TradeDirection.LONG, entry_price=0.0,  # Zero entry price
        stop_loss_price=0.0, take_profit_price=0.0
    )
    
    await order_manager.handle_trade_signal(signal)
    
    # No orders should be placed due to invalid entry price
    assert mock_rest_client_for_om.create_order.call_count == 0

# Tests for Order Placement Logic
@pytest.mark.asyncio
async def test_om_handle_trade_signal_usdt_m_long(order_manager, mock_rest_client_for_om):
    """Test correct order parameters for USDT-M LONG trade."""
    mock_rest_client_for_om.create_order.reset_mock()
    
    signal = TradeSignal(
        symbol="BTCUSDT", config_symbol="BTC_USDT", contract_type="USDT_M",
        direction=TradeDirection.LONG, entry_price=50000.0,
        stop_loss_price=49000.0, take_profit_price=53000.0
    )
    
    await order_manager.handle_trade_signal(signal)
    
    # Expected quantity: (100 USDT margin * 20x leverage) / 50000 entry = 0.04 BTC
    expected_quantity = 0.04
    
    # Check create_order calls
    assert mock_rest_client_for_om.create_order.call_count == 3
    
    # Check entry order parameters
    entry_call = mock_rest_client_for_om.create_order.call_args_list[0]
    assert entry_call[1]["symbol"] == "BTCUSDT"
    assert entry_call[1]["order_type"] == OrderType.MARKET
    assert entry_call[1]["side"] == OrderSide.BUY
    assert entry_call[1]["amount"] == expected_quantity
    
    # Check SL order parameters
    sl_call = mock_rest_client_for_om.create_order.call_args_list[1]
    assert sl_call[1]["symbol"] == "BTCUSDT"
    assert sl_call[1]["order_type"] == OrderType.STOP_MARKET
    assert sl_call[1]["side"] == OrderSide.SELL
    assert sl_call[1]["amount"] == expected_quantity
    assert sl_call[1]["params"]["stopPrice"] == 49000.00  # Adjusted to 0.01 tick
    assert sl_call[1]["params"]["reduceOnly"] == "true"
    
    # Check TP order parameters
    tp_call = mock_rest_client_for_om.create_order.call_args_list[2]
    assert tp_call[1]["symbol"] == "BTCUSDT"
    assert tp_call[1]["order_type"] == OrderType.TAKE_PROFIT_MARKET
    assert tp_call[1]["side"] == OrderSide.SELL
    assert tp_call[1]["amount"] == expected_quantity
    assert tp_call[1]["params"]["stopPrice"] == 53000.00  # Adjusted to 0.01 tick
    assert tp_call[1]["params"]["reduceOnly"] == "true"

@pytest.mark.asyncio
async def test_om_handle_trade_signal_usdt_m_short(order_manager, mock_rest_client_for_om):
    """Test correct order parameters for USDT-M SHORT trade."""
    mock_rest_client_for_om.create_order.reset_mock()
    
    signal = TradeSignal(
        symbol="BTCUSDT", config_symbol="BTC_USDT", contract_type="USDT_M",
        direction=TradeDirection.SHORT, entry_price=50000.0,
        stop_loss_price=51000.0, take_profit_price=47000.0
    )
    
    await order_manager.handle_trade_signal(signal)
    
    # Expected quantity: (100 USDT margin * 20x leverage) / 50000 entry = 0.04 BTC
    expected_quantity = 0.04
    
    # Check create_order calls
    assert mock_rest_client_for_om.create_order.call_count == 3
    
    # Check entry order parameters
    entry_call = mock_rest_client_for_om.create_order.call_args_list[0]
    assert entry_call[1]["symbol"] == "BTCUSDT"
    assert entry_call[1]["order_type"] == OrderType.MARKET
    assert entry_call[1]["side"] == OrderSide.SELL
    assert entry_call[1]["amount"] == expected_quantity
    
    # Check SL order parameters
    sl_call = mock_rest_client_for_om.create_order.call_args_list[1]
    assert sl_call[1]["symbol"] == "BTCUSDT"
    assert sl_call[1]["order_type"] == OrderType.STOP_MARKET
    assert sl_call[1]["side"] == OrderSide.BUY
    assert sl_call[1]["amount"] == expected_quantity
    assert sl_call[1]["params"]["stopPrice"] == 51000.00  # Adjusted to 0.01 tick
    assert sl_call[1]["params"]["reduceOnly"] == "true"
    
    # Check TP order parameters
    tp_call = mock_rest_client_for_om.create_order.call_args_list[2]
    assert tp_call[1]["symbol"] == "BTCUSDT"
    assert tp_call[1]["order_type"] == OrderType.TAKE_PROFIT_MARKET
    assert tp_call[1]["side"] == OrderSide.BUY
    assert tp_call[1]["amount"] == expected_quantity
    assert tp_call[1]["params"]["stopPrice"] == 47000.00  # Adjusted to 0.01 tick
    assert tp_call[1]["params"]["reduceOnly"] == "true"

@pytest.mark.asyncio
async def test_om_handle_trade_signal_coin_m_short(order_manager, mock_rest_client_for_om):
    """Test correct order parameters for COIN-M SHORT trade."""
    mock_rest_client_for_om.create_order.reset_mock()
    
    signal = TradeSignal(
        symbol="ETHUSD_PERP", config_symbol="ETHUSD_PERP", contract_type="COIN_M",
        direction=TradeDirection.SHORT, entry_price=3000.0,
        stop_loss_price=3100.0, take_profit_price=2700.0
    )
    
    await order_manager.handle_trade_signal(signal)
    
    # Expected quantity for COIN-M (margin_coin=0.1 is used as num_contracts for MVP test)
    expected_quantity = 0.1
    
    assert mock_rest_client_for_om.create_order.call_count == 3
    
    # Check entry order parameters
    entry_call = mock_rest_client_for_om.create_order.call_args_list[0]
    assert entry_call[1]["symbol"] == "ETHUSD_PERP"
    assert entry_call[1]["order_type"] == OrderType.MARKET
    assert entry_call[1]["side"] == OrderSide.SELL
    assert entry_call[1]["amount"] == expected_quantity
    
    # Check SL order parameters
    sl_call = mock_rest_client_for_om.create_order.call_args_list[1]
    assert sl_call[1]["symbol"] == "ETHUSD_PERP"
    assert sl_call[1]["order_type"] == OrderType.STOP_MARKET
    assert sl_call[1]["side"] == OrderSide.BUY
    assert sl_call[1]["amount"] == expected_quantity
    assert sl_call[1]["params"]["stopPrice"] == 3100.00
    assert sl_call[1]["params"]["reduceOnly"] == "true"
    
    # Check TP order parameters
    tp_call = mock_rest_client_for_om.create_order.call_args_list[2]
    assert tp_call[1]["symbol"] == "ETHUSD_PERP"
    assert tp_call[1]["order_type"] == OrderType.TAKE_PROFIT_MARKET
    assert tp_call[1]["side"] == OrderSide.BUY
    assert tp_call[1]["amount"] == expected_quantity
    assert tp_call[1]["params"]["stopPrice"] == 2700.00
    assert tp_call[1]["params"]["reduceOnly"] == "true"

@pytest.mark.asyncio
async def test_om_min_notional_check_usdt_m(order_manager, mock_rest_client_for_om):
    """Test minimum notional value check for USDT-M."""
    mock_rest_client_for_om.create_order.reset_mock()
    
    # Test case that passes min notional check
    signal_high_notional = TradeSignal(
        symbol="BTCUSDT", config_symbol="BTC_USDT", contract_type="USDT_M",
        direction=TradeDirection.LONG, entry_price=1.0,
        stop_loss_price=0.9, take_profit_price=1.3
    )
    await order_manager.handle_trade_signal(signal_high_notional)
    assert mock_rest_client_for_om.create_order.call_count == 3  # Orders should be placed
    mock_rest_client_for_om.create_order.reset_mock()
    
    # Test case that fails min notional check by modifying config
    # Set margin_usdt and leverage so that margin_usdt * leverage < min_notional
    order_manager.config_manager.get_config.return_value["pairs"]["BTC_USDT"]["margin_usdt"] = 0.1
    order_manager.config_manager.get_config.return_value["pairs"]["BTC_USDT"]["leverage"] = 10
    # Now notional is 0.1 * 10 = 1.0 USDT. Min notional is 5.0. Should fail.
    
    signal_low_notional = TradeSignal(
        symbol="BTCUSDT", config_symbol="BTC_USDT", contract_type="USDT_M",
        direction=TradeDirection.LONG, entry_price=50000.0,
        stop_loss_price=49000.0, take_profit_price=53000.0
    )
    await order_manager.handle_trade_signal(signal_low_notional)
    
    # No orders should be placed due to min notional check failure
    assert mock_rest_client_for_om.create_order.call_count == 0
    
    # Reset config for other tests
    order_manager.config_manager.get_config.return_value["pairs"]["BTC_USDT"]["margin_usdt"] = 100.0
    order_manager.config_manager.get_config.return_value["pairs"]["BTC_USDT"]["leverage"] = 20

@pytest.mark.asyncio
async def test_om_handle_trade_signal_zero_quantity(order_manager, mock_rest_client_for_om):
    """Test handling zero calculated quantity."""
    mock_rest_client_for_om.create_order.reset_mock()
    
    # Mock _get_symbol_filters to return a larger step_size that will cause quantity to be floored to zero
    with patch.object(order_manager, '_get_symbol_filters', new_callable=AsyncMock) as mock_filters:
        mock_filters.return_value = (0.001, 0.01, 5.0)  # Lot_step = 0.001
        
        signal = TradeSignal(
            symbol="BTCUSDT", config_symbol="BTC_USDT", contract_type="USDT_M",
            direction=TradeDirection.LONG, entry_price=10000000.0,  # Very high price
            stop_loss_price=9000000.0, take_profit_price=13000000.0
        )
        
        # Expected raw quantity: (100 * 20) / 10000000 = 0.0002
        # Adjusted with step 0.001: floor(0.0002 / 0.001) * 0.001 = 0.0
        await order_manager.handle_trade_signal(signal)
        
        # No orders should be placed due to zero quantity
        assert mock_rest_client_for_om.create_order.call_count == 0

# Tests for Error Handling
@pytest.mark.asyncio
async def test_om_exchange_info_fetch_failure(order_manager, mock_rest_client_for_om):
    """Test handling failure to fetch exchange info."""
    mock_rest_client_for_om.create_order.reset_mock()
    
    # Clear the cache to force a new fetch
    order_manager.exchange_info_cache = {}
    
    # Mock exchange_info fetch to return None (failure)
    mock_rest_client_for_om.fetch_exchange_info.return_value = None
    
    signal = TradeSignal(
        symbol="BTCUSDT", config_symbol="BTC_USDT", contract_type="USDT_M",
        direction=TradeDirection.LONG, entry_price=50000.0,
        stop_loss_price=49000.0, take_profit_price=53000.0
    )
    
    await order_manager.handle_trade_signal(signal)
    
    # No orders should be placed due to exchange info fetch failure
    assert mock_rest_client_for_om.create_order.call_count == 0

@pytest.mark.asyncio
async def test_om_entry_order_placement_failure(order_manager, mock_rest_client_for_om):
    """Test handling entry order placement failure."""
    mock_rest_client_for_om.create_order.reset_mock()
    
    # Mock the first call to create_order (entry order) to return None (failure)
    mock_rest_client_for_om.create_order.side_effect = [
        None,  # Entry order fails
        {"id": "mock_sl_order_id"},  # SL order (shouldn't be called)
        {"id": "mock_tp_order_id"}   # TP order (shouldn't be called)
    ]
    
    signal = TradeSignal(
        symbol="BTCUSDT", config_symbol="BTC_USDT", contract_type="USDT_M",
        direction=TradeDirection.LONG, entry_price=50000.0,
        stop_loss_price=49000.0, take_profit_price=53000.0
    )
    
    await order_manager.handle_trade_signal(signal)
    
    # Only entry order should be attempted, and it fails
    assert mock_rest_client_for_om.create_order.call_count == 1

@pytest.mark.asyncio
async def test_om_entry_order_rejected(order_manager, mock_rest_client_for_om):
    """Test handling entry order rejection."""
    mock_rest_client_for_om.create_order.reset_mock()
    
    # Mock the first call to create_order (entry order) to return a rejected status
    mock_rest_client_for_om.create_order.side_effect = [
        {"id": "mock_entry_order_id", "status": OrderStatus.REJECTED},  # Entry order rejected
        {"id": "mock_sl_order_id"},  # SL order (shouldn't be called)
        {"id": "mock_tp_order_id"}   # TP order (shouldn't be called)
    ]
    
    signal = TradeSignal(
        symbol="BTCUSDT", config_symbol="BTC_USDT", contract_type="USDT_M",
        direction=TradeDirection.LONG, entry_price=50000.0,
        stop_loss_price=49000.0, take_profit_price=53000.0
    )
    
    await order_manager.handle_trade_signal(signal)
    
    # Only entry order should be attempted, but SL/TP are not placed due to rejected entry
    assert mock_rest_client_for_om.create_order.call_count == 1

@pytest.mark.asyncio
async def test_om_sl_order_placement_failure(order_manager, mock_rest_client_for_om):
    """Test handling SL order placement failure."""
    mock_rest_client_for_om.create_order.reset_mock()
    
    # Mock create_order to succeed for entry but fail for SL
    mock_rest_client_for_om.create_order.side_effect = [
        {"id": "mock_entry_order_id", "status": "NEW"},  # Entry order succeeds
        None,  # SL order fails
        {"id": "mock_tp_order_id"}   # TP order should still be attempted
    ]
    
    signal = TradeSignal(
        symbol="BTCUSDT", config_symbol="BTC_USDT", contract_type="USDT_M",
        direction=TradeDirection.LONG, entry_price=50000.0,
        stop_loss_price=49000.0, take_profit_price=53000.0
    )
    
    await order_manager.handle_trade_signal(signal)
    
    # Entry order succeeds, SL fails, but TP is still attempted
    assert mock_rest_client_for_om.create_order.call_count == 3

@pytest.mark.asyncio
async def test_om_tp_order_placement_failure(order_manager, mock_rest_client_for_om):
    """Test handling TP order placement failure."""
    mock_rest_client_for_om.create_order.reset_mock()
    
    # Mock create_order to succeed for entry and SL but fail for TP
    mock_rest_client_for_om.create_order.side_effect = [
        {"id": "mock_entry_order_id", "status": "NEW"},  # Entry order succeeds
        {"id": "mock_sl_order_id"},   # SL order succeeds
        None  # TP order fails
    ]
    
    signal = TradeSignal(
        symbol="BTCUSDT", config_symbol="BTC_USDT", contract_type="USDT_M",
        direction=TradeDirection.LONG, entry_price=50000.0,
        stop_loss_price=49000.0, take_profit_price=53000.0
    )
    
    await order_manager.handle_trade_signal(signal)
    
    # All three orders should be attempted, but TP fails
    assert mock_rest_client_for_om.create_order.call_count == 3

@pytest.mark.asyncio
async def test_om_unknown_contract_type(order_manager, mock_rest_client_for_om):
    """Test handling unknown contract type."""
    mock_rest_client_for_om.create_order.reset_mock()
    
    # Use a valid contract type but modify handle_trade_signal behavior
    signal = TradeSignal(
        symbol="BTCUSDT", config_symbol="BTC_USDT", contract_type="USDT_M",
        direction=TradeDirection.LONG, entry_price=50000.0,
        stop_loss_price=49000.0, take_profit_price=53000.0
    )
    
    # Patch the signal's contract_type attribute after creation to simulate an unknown type
    # This avoids the Pydantic validation error
    with patch.object(signal, 'contract_type', "UNKNOWN_TYPE"):
        await order_manager.handle_trade_signal(signal)
    
    # No orders should be placed due to unknown contract type
    assert mock_rest_client_for_om.create_order.call_count == 0




================================================
FILE: tests/unit/test_position_manager.py
================================================
import pytest
import asyncio
from unittest.mock import AsyncMock, MagicMock, patch
from threading import RLock

from src.config_loader import ConfigManager
from src.position_manager import PositionManager
from src.models import Position, Order, OrderStatus, TradeDirection, OrderType, OrderSide

@pytest.fixture
def mock_config_manager_for_pm():
    cm = MagicMock(spec=ConfigManager)
    cm.get_config.return_value = {}  # Empty config is fine for PositionManager tests
    return cm

@pytest.fixture
def position_manager(mock_config_manager_for_pm):
    return PositionManager(config_manager=mock_config_manager_for_pm)

@pytest.mark.asyncio
async def test_pm_empty_state(position_manager):
    """Test that a new PositionManager returns correct values when empty."""
    # Verify getters return correct values when empty
    assert position_manager.get_position("BTCUSDT") is None
    assert position_manager.get_all_positions() == []
    assert position_manager.has_open_position("BTCUSDT") is False
    assert position_manager.has_open_position("ETHUSDT") is False

@pytest.mark.asyncio
async def test_pm_add_get_position(position_manager):
    # Test adding a position
    pos_data = Position(
        symbol="BTCUSDT", contract_type="USDT_M", side=TradeDirection.LONG,
        entry_price=50000.0, quantity=0.01, entry_order_id="entry1",
        sl_order_id="sl1", tp_order_id="tp1"
    )
    await position_manager.add_or_update_position(pos_data)
    
    # Test retrieving the position
    retrieved_pos = position_manager.get_position("BTCUSDT")
    assert retrieved_pos is not None
    assert retrieved_pos.symbol == "BTCUSDT"
    assert retrieved_pos.entry_price == 50000.0
    assert retrieved_pos.quantity == 0.01
    assert retrieved_pos.sl_order_id == "sl1"
    
    # Test has_open_position
    assert position_manager.has_open_position("BTCUSDT") is True
    assert position_manager.has_open_position("ETHUSDT") is False
    
    # Test get_all_positions
    all_positions = position_manager.get_all_positions()
    assert len(all_positions) == 1
    assert all_positions[0].symbol == "BTCUSDT"

@pytest.mark.asyncio
async def test_pm_update_position(position_manager):
    # Add initial position
    pos_data = Position(
        symbol="ETHUSDT", contract_type="USDT_M", side=TradeDirection.SHORT,
        entry_price=3000.0, quantity=0.1, entry_order_id="entry2",
        sl_order_id="sl2", tp_order_id="tp2"
    )
    await position_manager.add_or_update_position(pos_data)
    
    # Update the position
    updated_pos_data = Position(
        symbol="ETHUSDT", contract_type="USDT_M", side=TradeDirection.SHORT,
        entry_price=3000.0, quantity=0.1, entry_order_id="entry2",
        sl_order_id="sl2_new", tp_order_id="tp2", # Changed SL order ID
        current_sl_price=3100.0, # Added SL price
        unrealized_pnl=-50.0 # Added PnL
    )
    await position_manager.add_or_update_position(updated_pos_data)
    
    # Verify the update
    retrieved_pos = position_manager.get_position("ETHUSDT")
    assert retrieved_pos.sl_order_id == "sl2_new"
    assert retrieved_pos.current_sl_price == 3100.0
    assert retrieved_pos.unrealized_pnl == -50.0

@pytest.mark.asyncio
async def test_pm_remove_position(position_manager):
    # Add a position
    pos_data = Position(
        symbol="SOLUSDT", contract_type="USDT_M", side=TradeDirection.LONG,
        entry_price=100.0, quantity=1.0, entry_order_id="entry3",
        sl_order_id="sl3", tp_order_id="tp3"
    )
    await position_manager.add_or_update_position(pos_data)
    assert position_manager.has_open_position("SOLUSDT") is True
    
    # Remove the position
    await position_manager.remove_position("SOLUSDT")
    assert position_manager.has_open_position("SOLUSDT") is False
    assert position_manager.get_position("SOLUSDT") is None
    
    # Test removing a non-existent position (should not raise error)
    await position_manager.remove_position("NONEXISTENT")

@pytest.mark.asyncio
async def test_pm_update_position_on_entry_order_fill(position_manager):
    # Add a position
    pos_data = Position(
        symbol="BTCUSDT", contract_type="USDT_M", side=TradeDirection.LONG,
        entry_price=50000.0, quantity=0.01, entry_order_id="entry1",
        sl_order_id="sl1", tp_order_id="tp1"
    )
    await position_manager.add_or_update_position(pos_data)
    
    # Simulate entry order fill with different fill price
    entry_order_fill = Order(
        order_id="entry1", symbol="BTCUSDT", type=OrderType.MARKET, side=OrderSide.BUY,
        quantity=0.01, status=OrderStatus.FILLED, timestamp=1234567890,
        avg_fill_price=50100.0, filled_quantity=0.01
    )
    await position_manager.update_position_on_order_update(entry_order_fill)
    
    # Verify entry price was updated
    updated_pos = position_manager.get_position("BTCUSDT")
    assert updated_pos.entry_price == 50100.0

@pytest.mark.asyncio
async def test_pm_update_position_on_sl_order_fill(position_manager):
    # Add a position
    pos_data = Position(
        symbol="BTCUSDT", contract_type="USDT_M", side=TradeDirection.LONG,
        entry_price=50000.0, quantity=0.01, entry_order_id="entry1",
        sl_order_id="sl1", tp_order_id="tp1"
    )
    await position_manager.add_or_update_position(pos_data)
    
    # Simulate SL order fill
    sl_order_fill = Order(
        order_id="sl1", symbol="BTCUSDT", type=OrderType.STOP_MARKET, side=OrderSide.SELL,
        quantity=0.01, status=OrderStatus.FILLED, timestamp=1234567890,
        avg_fill_price=49000.0, filled_quantity=0.01
    )
    await position_manager.update_position_on_order_update(sl_order_fill)
    
    # Verify position was removed
    assert position_manager.has_open_position("BTCUSDT") is False

@pytest.mark.asyncio
async def test_pm_update_position_on_tp_order_fill(position_manager):
    # Add a position
    pos_data = Position(
        symbol="BTCUSDT", contract_type="USDT_M", side=TradeDirection.LONG,
        entry_price=50000.0, quantity=0.01, entry_order_id="entry1",
        sl_order_id="sl1", tp_order_id="tp1"
    )
    await position_manager.add_or_update_position(pos_data)
    
    # Simulate TP order fill
    tp_order_fill = Order(
        order_id="tp1", symbol="BTCUSDT", type=OrderType.TAKE_PROFIT_MARKET, side=OrderSide.SELL,
        quantity=0.01, status=OrderStatus.FILLED, timestamp=1234567890,
        avg_fill_price=52000.0, filled_quantity=0.01
    )
    await position_manager.update_position_on_order_update(tp_order_fill)
    
    # Verify position was removed
    assert position_manager.has_open_position("BTCUSDT") is False

@pytest.mark.asyncio
async def test_pm_update_position_on_order_cancel(position_manager):
    # Add a position
    pos_data = Position(
        symbol="BTCUSDT", contract_type="USDT_M", side=TradeDirection.LONG,
        entry_price=50000.0, quantity=0.01, entry_order_id="entry1",
        sl_order_id="sl1", tp_order_id="tp1"
    )
    await position_manager.add_or_update_position(pos_data)
    
    # Simulate SL order cancellation
    sl_order_cancel = Order(
        order_id="sl1", symbol="BTCUSDT", type=OrderType.STOP_MARKET, side=OrderSide.SELL,
        quantity=0.01, status=OrderStatus.CANCELED, timestamp=1234567890
    )
    await position_manager.update_position_on_order_update(sl_order_cancel)
    
    # Verify SL order ID was cleared
    updated_pos = position_manager.get_position("BTCUSDT")
    assert updated_pos.sl_order_id is None
    assert updated_pos.tp_order_id == "tp1"  # TP order should still be there

@pytest.mark.asyncio
async def test_pm_update_position_on_entry_order_cancel(position_manager):
    # Add a position
    pos_data = Position(
        symbol="BTCUSDT", contract_type="USDT_M", side=TradeDirection.LONG,
        entry_price=50000.0, quantity=0.01, entry_order_id="entry1",
        sl_order_id="sl1", tp_order_id="tp1"
    )
    await position_manager.add_or_update_position(pos_data)
    
    # Simulate entry order cancellation
    entry_order_cancel = Order(
        order_id="entry1", symbol="BTCUSDT", type=OrderType.MARKET, side=OrderSide.BUY,
        quantity=0.01, status=OrderStatus.CANCELED, timestamp=1234567890
    )
    await position_manager.update_position_on_order_update(entry_order_cancel)
    
    # Verify position was removed
    assert position_manager.has_open_position("BTCUSDT") is False

@pytest.mark.asyncio
async def test_pm_update_position_on_order_reject(position_manager):
    # Add a position
    pos_data = Position(
        symbol="BTCUSDT", contract_type="USDT_M", side=TradeDirection.LONG,
        entry_price=50000.0, quantity=0.01, entry_order_id="entry1",
        sl_order_id="sl1", tp_order_id="tp1"
    )
    await position_manager.add_or_update_position(pos_data)
    
    # Simulate TP order rejection
    tp_order_reject = Order(
        order_id="tp1", symbol="BTCUSDT", type=OrderType.TAKE_PROFIT_MARKET, side=OrderSide.SELL,
        quantity=0.01, status=OrderStatus.REJECTED, timestamp=1234567890
    )
    await position_manager.update_position_on_order_update(tp_order_reject)
    
    # Verify TP order ID was cleared
    updated_pos = position_manager.get_position("BTCUSDT")
    assert updated_pos.tp_order_id is None
    assert updated_pos.sl_order_id == "sl1"  # SL order should still be there

@pytest.mark.asyncio
async def test_pm_update_position_on_unrelated_order(position_manager):
    """Test that unrelated order updates don't affect positions."""
    # Add a position
    pos_data = Position(
        symbol="BTCUSDT", contract_type="USDT_M", side=TradeDirection.LONG,
        entry_price=50000.0, quantity=0.01, entry_order_id="entry1",
        sl_order_id="sl1", tp_order_id="tp1"
    )
    await position_manager.add_or_update_position(pos_data)
    
    # Create a snapshot of the position before the update
    original_pos = position_manager.get_position("BTCUSDT")
    
    # Simulate an order update with an unrelated order ID
    unrelated_order = Order(
        order_id="unrelated123", symbol="BTCUSDT", type=OrderType.MARKET, side=OrderSide.BUY,
        quantity=0.01, status=OrderStatus.FILLED, timestamp=1234567890
    )
    await position_manager.update_position_on_order_update(unrelated_order)
    
    # Verify position state remains unchanged
    updated_pos = position_manager.get_position("BTCUSDT")
    assert updated_pos.entry_order_id == original_pos.entry_order_id
    assert updated_pos.sl_order_id == original_pos.sl_order_id
    assert updated_pos.tp_order_id == original_pos.tp_order_id
    assert updated_pos.entry_price == original_pos.entry_price

@pytest.mark.asyncio
async def test_pm_update_position_on_order_for_nonexistent_position(position_manager):
    """Test handling order updates for symbols with no tracked position."""
    # Ensure no position exists
    assert position_manager.has_open_position("XYZUSDT") is False
    
    # Simulate an order update for a symbol with no position
    order = Order(
        order_id="xyz123", symbol="XYZUSDT", type=OrderType.MARKET, side=OrderSide.BUY,
        quantity=0.01, status=OrderStatus.FILLED, timestamp=1234567890
    )
    # This should not raise an error
    await position_manager.update_position_on_order_update(order)
    
    # Verify no position was created
    assert position_manager.has_open_position("XYZUSDT") is False

@pytest.mark.asyncio
async def test_pm_reconcile_positions_with_exchange(position_manager):
    # Mock REST client
    mock_rest_client = AsyncMock()
    mock_rest_client.fetch_positions.return_value = [
        {
            "symbol": "BTCUSDT",
            "contracts": 0.01,
            "entryPrice": 50000.0,
            "marginType": "ISOLATED",
            "leverage": 20,
            "unrealizedPnl": 100.0,
            "liquidationPrice": 45000.0,
            "markPrice": 51000.0
        },
        {
            "symbol": "ETHUSDT",
            "contracts": -0.1,  # Negative for SHORT
            "entryPrice": 3000.0,
            "marginType": "ISOLATED",
            "leverage": 10,
            "unrealizedPnl": -50.0,
            "liquidationPrice": 3300.0,
            "markPrice": 3050.0
        }
    ]
    
    # Add a position that doesn't exist on exchange
    pos_data = Position(
        symbol="SOLUSDT", contract_type="USDT_M", side=TradeDirection.LONG,
        entry_price=100.0, quantity=1.0, entry_order_id="entry3",
        sl_order_id="sl3", tp_order_id="tp3"
    )
    await position_manager.add_or_update_position(pos_data)
    
    # Reconcile
    await position_manager.reconcile_positions_with_exchange(mock_rest_client)
    
    # Verify positions from exchange were added
    btc_pos = position_manager.get_position("BTCUSDT")
    assert btc_pos is not None
    assert btc_pos.side == TradeDirection.LONG
    assert btc_pos.entry_price == 50000.0
    assert btc_pos.quantity == 0.01
    assert btc_pos.unrealized_pnl == 100.0
    
    eth_pos = position_manager.get_position("ETHUSDT")
    assert eth_pos is not None
    assert eth_pos.side == TradeDirection.SHORT
    assert eth_pos.entry_price == 3000.0
    assert eth_pos.quantity == 0.1
    assert eth_pos.unrealized_pnl == -50.0
    
    # Verify position not on exchange was removed
    assert position_manager.has_open_position("SOLUSDT") is False

@pytest.mark.asyncio
async def test_pm_reconcile_positions_with_zero_quantity(position_manager):
    """Test reconciling with an exchange position that has zero quantity."""
    # Mock REST client with a zero-quantity position
    mock_rest_client = AsyncMock()
    mock_rest_client.fetch_positions.return_value = [
        {
            "symbol": "BTCUSDT",
            "contracts": 0,  # Zero quantity position
            "entryPrice": 50000.0,
            "marginType": "ISOLATED",
            "leverage": 20
        }
    ]
    
    # Add a position for BTCUSDT in manager
    pos_data = Position(
        symbol="BTCUSDT", contract_type="USDT_M", side=TradeDirection.LONG,
        entry_price=50000.0, quantity=0.01, entry_order_id="entry1"
    )
    await position_manager.add_or_update_position(pos_data)
    assert position_manager.has_open_position("BTCUSDT") is True
    
    # Reconcile
    await position_manager.reconcile_positions_with_exchange(mock_rest_client)
    
    # Verify position was removed (because exchange shows zero quantity)
    assert position_manager.has_open_position("BTCUSDT") is False

@pytest.mark.asyncio
async def test_pm_reconcile_positions_with_exchange_error(position_manager):
    """Test reconciliation when fetch_positions returns None or raises an exception."""
    # Add a position that should remain untouched if fetch_positions fails
    pos_data = Position(
        symbol="BTCUSDT", contract_type="USDT_M", side=TradeDirection.LONG,
        entry_price=50000.0, quantity=0.01, entry_order_id="entry1"
    )
    await position_manager.add_or_update_position(pos_data)
    
    # Case 1: fetch_positions returns None
    mock_rest_client1 = AsyncMock()
    mock_rest_client1.fetch_positions.return_value = None
    
    # Reconcile - should not modify positions
    await position_manager.reconcile_positions_with_exchange(mock_rest_client1)
    assert position_manager.has_open_position("BTCUSDT") is True
    
    # Case 2: fetch_positions raises an exception
    mock_rest_client2 = AsyncMock()
    mock_rest_client2.fetch_positions.side_effect = Exception("API Error")
    
    # Reconcile - should not modify positions
    await position_manager.reconcile_positions_with_exchange(mock_rest_client2)
    assert position_manager.has_open_position("BTCUSDT") is True

@pytest.mark.asyncio
async def test_pm_thread_safety(position_manager):
    # This test is more conceptual than practical in a unit test environment
    # In a real multi-threaded environment, we'd need to test with actual threads
    
    # Verify the lock exists and has acquire/release methods like a lock should
    assert hasattr(position_manager, "_lock")
    assert hasattr(position_manager._lock, "acquire")
    assert hasattr(position_manager._lock, "release")
    
    # Test that methods use the lock (we can't directly test this without mocking the lock)
    # But we can verify the methods work correctly
    pos_data = Position(
        symbol="BTCUSDT", contract_type="USDT_M", side=TradeDirection.LONG,
        entry_price=50000.0, quantity=0.01, entry_order_id="entry1",
        sl_order_id="sl1", tp_order_id="tp1"
    )
    await position_manager.add_or_update_position(pos_data)
    assert position_manager.get_position("BTCUSDT") is not None
    
    # Create a few async tasks that modify and read the position state
    # to simulate concurrent operations
    async def update_task():
        await position_manager.add_or_update_position(pos_data)
        return True
        
    async def get_task():
        # Wrap the synchronous call in an async function
        return position_manager.get_position("BTCUSDT")
        
    async def list_task():
        # Wrap the synchronous call in an async function
        return position_manager.get_all_positions()
    
    # Run tasks concurrently
    results = await asyncio.gather(
        update_task(),
        get_task(),
        list_task()
    )
    
    # Verify results
    assert results[0] is True  # update_task completed
    assert results[1] is not None  # get_task returned position
    assert len(results[2]) == 1  # list_task returned list with one position



================================================
FILE: tests/unit/test_signal_engine.py
================================================
import pytest
import asyncio
import pandas as pd
import time
from unittest.mock import MagicMock, AsyncMock, patch

from src.config_loader import ConfigManager
from src.data_processor import DataProcessor
from src.signal_engine import SignalEngineV1
from src.models import TradeSignal, TradeDirection, Kline

@pytest.fixture
def mock_config_manager_for_se():
    cm = MagicMock(spec=ConfigManager)
    cm.get_config.return_value = {
        "global_settings": {
            "v1_strategy": {
                "sma_short_period": 3,
                "sma_long_period": 5,
                "min_signal_interval_minutes": 15,
                "tp_sl_ratio": 2.0
            }
        },
        "pairs": {
            "BTC_USDT": {"enabled": True, "contract_type": "USDT_M"},
            "ETH_USDT": {
                "enabled": True, 
                "contract_type": "USDT_M",
                "min_signal_interval_minutes": 0  # For testing without wait
            },
            "SOL_USDT": {
                "enabled": True,
                "contract_type": "USDT_M",
                "tp_sl_ratio": 3.5  # Custom R:R ratio for testing
            }
        }
    }
    return cm

@pytest.fixture
def mock_data_processor_for_se():
    dp = MagicMock(spec=DataProcessor)
    return dp

@pytest.fixture
def signal_engine_v1(mock_config_manager_for_se, mock_data_processor_for_se):
    return SignalEngineV1(config_manager=mock_config_manager_for_se, data_processor=mock_data_processor_for_se)

# Helper to create a DataFrame for mock_data_processor
def create_mock_df(sma_short_prev, sma_long_prev, sma_short_curr, sma_long_curr, close_curr=100, low_lookback=[90,91,89], high_lookback=[110,109,111]):
    # Ensure lookback arrays are long enough for pivot logic (default pivot_lookback=30)
    # Create enough past data for pivot calculation
    total_rows = 32  # Total number of rows in the DataFrame (31 for past data + 1 for current)
    pivot_data_rows = 30  # Number of rows needed for pivot calculation (excluding the last 2 rows)
    
    # Ensure low_lookback and high_lookback are lists
    if not isinstance(low_lookback, list):
        low_lookback = [low_lookback]
    if not isinstance(high_lookback, list):
        high_lookback = [high_lookback]
    
    # Repeat the lookback arrays to make them at least pivot_data_rows long
    past_lows = (low_lookback * (pivot_data_rows // len(low_lookback) + 1))[:pivot_data_rows]
    past_highs = (high_lookback * (pivot_data_rows // len(high_lookback) + 1))[:pivot_data_rows]
    
    # Create data arrays of consistent length
    timestamps = list(range(1000, 1000 + total_rows * 1000, 1000))  # timestamps from 1000 to 32000, step 1000
    
    # Build arrays for all columns, ensuring they're all the same length
    opens = [close_curr - 1] * pivot_data_rows + [close_curr - 1, close_curr - 0.5]
    highs = past_highs + [max(high_lookback), close_curr + 2]
    lows = past_lows + [min(low_lookback), close_curr - 2]
    closes = [close_curr - 1] * pivot_data_rows + [close_curr - 1, close_curr]
    volumes = [100] * total_rows
    is_closed = [True] * total_rows
    
    # SMA values - past values, previous, and current
    sma_shorts = [sma_short_prev - 1] * pivot_data_rows + [sma_short_prev, sma_short_curr]
    sma_longs = [sma_long_prev - 1] * pivot_data_rows + [sma_long_prev, sma_long_curr]
    
    # Validate all arrays have the same length
    assert len(timestamps) == total_rows
    assert len(opens) == total_rows
    assert len(highs) == total_rows
    assert len(lows) == total_rows
    assert len(closes) == total_rows
    assert len(volumes) == total_rows
    assert len(is_closed) == total_rows
    assert len(sma_shorts) == total_rows
    assert len(sma_longs) == total_rows
    
    data = {
        "timestamp": timestamps,
        "open": opens,
        "high": highs,
        "low": lows,
        "close": closes,
        "volume": volumes,
        "is_closed": is_closed,
        "sma_short": sma_shorts,
        "sma_long": sma_longs,
    }
    
    df = pd.DataFrame(data)
    df.set_index("timestamp", inplace=True)
    return df

# Helper to create a shorter DataFrame with specific values
def create_limited_df(rows=5, with_na=False):
    """Creates a small DataFrame with limited rows - useful for testing insufficient data scenarios"""
    data = {
        "timestamp": list(range(1000, 1000 + rows * 1000, 1000)),
        "open": [99] * rows,
        "high": [101] * rows,
        "low": [98] * rows,
        "close": [100] * rows,
        "volume": [100] * rows,
        "is_closed": [True] * rows,
        "sma_short": [99] * rows,
        "sma_long": [100] * rows
    }
    
    # Set some values to NA if requested
    if with_na:
        data["sma_short"][-1] = pd.NA
    
    df = pd.DataFrame(data)
    df.set_index("timestamp", inplace=True)
    return df

# 1. Test Signal Generation Logic
@pytest.mark.asyncio
async def test_se_no_signal_if_not_enough_data(signal_engine_v1, mock_data_processor_for_se):
    # Test with empty DataFrame
    mock_data_processor_for_se.get_indicator_dataframe.return_value = pd.DataFrame()  # Empty DF
    signal = await signal_engine_v1.check_signal("BTCUSDT", "BTC_USDT")
    assert signal is None

    # Test with None DataFrame
    mock_data_processor_for_se.get_indicator_dataframe.return_value = None
    signal = await signal_engine_v1.check_signal("BTCUSDT", "BTC_USDT")
    assert signal is None

    # Test with only one row
    mock_data_processor_for_se.get_indicator_dataframe.return_value = create_mock_df(10,20,11,19)[:1]  # Only one row
    signal = await signal_engine_v1.check_signal("BTCUSDT", "BTC_USDT")
    assert signal is None

@pytest.mark.asyncio
async def test_se_no_signal_if_sma_na(signal_engine_v1, mock_data_processor_for_se):
    # Test with NA in latest SMA short
    df_with_na = create_mock_df(10, 20, 11, 19)
    df_with_na.loc[df_with_na.index[-1], "sma_short"] = pd.NA
    mock_data_processor_for_se.get_indicator_dataframe.return_value = df_with_na
    signal = await signal_engine_v1.check_signal("BTCUSDT", "BTC_USDT")
    assert signal is None

    # Test with NA in latest SMA long
    df_with_na = create_mock_df(10, 20, 11, 19)
    df_with_na.loc[df_with_na.index[-1], "sma_long"] = pd.NA
    mock_data_processor_for_se.get_indicator_dataframe.return_value = df_with_na
    signal = await signal_engine_v1.check_signal("BTCUSDT", "BTC_USDT")
    assert signal is None

    # Test with NA in previous SMA short
    df_with_na = create_mock_df(10, 20, 11, 19)
    df_with_na.loc[df_with_na.index[-2], "sma_short"] = pd.NA
    mock_data_processor_for_se.get_indicator_dataframe.return_value = df_with_na
    signal = await signal_engine_v1.check_signal("BTCUSDT", "BTC_USDT")
    assert signal is None

    # Test with NA in previous SMA long
    df_with_na = create_mock_df(10, 20, 11, 19)
    df_with_na.loc[df_with_na.index[-2], "sma_long"] = pd.NA
    mock_data_processor_for_se.get_indicator_dataframe.return_value = df_with_na
    signal = await signal_engine_v1.check_signal("BTCUSDT", "BTC_USDT")
    assert signal is None

@pytest.mark.asyncio
async def test_se_no_signal_if_no_crossover(signal_engine_v1, mock_data_processor_for_se):
    # Test when short > long, and still short > long (no crossover)
    mock_df = create_mock_df(sma_short_prev=101, sma_long_prev=100, sma_short_curr=102, sma_long_curr=99)
    mock_data_processor_for_se.get_indicator_dataframe.return_value = mock_df
    signal = await signal_engine_v1.check_signal("ETHUSDT", "ETH_USDT")
    assert signal is None

    # Test when short < long, and still short < long (no crossover)
    mock_df = create_mock_df(sma_short_prev=99, sma_long_prev=100, sma_short_curr=98, sma_long_curr=101)
    mock_data_processor_for_se.get_indicator_dataframe.return_value = mock_df
    signal = await signal_engine_v1.check_signal("ETHUSDT", "ETH_USDT")
    assert signal is None

    # Test when short = long, and still short = long (no crossover)
    mock_df = create_mock_df(sma_short_prev=100, sma_long_prev=100, sma_short_curr=100, sma_long_curr=100)
    mock_data_processor_for_se.get_indicator_dataframe.return_value = mock_df
    signal = await signal_engine_v1.check_signal("ETHUSDT", "ETH_USDT")
    assert signal is None

@pytest.mark.asyncio
async def test_se_long_signal_sma_crossover(signal_engine_v1, mock_data_processor_for_se):
    # prev: short <= long, curr: short > long
    mock_df = create_mock_df(sma_short_prev=99, sma_long_prev=100, sma_short_curr=101, sma_long_curr=100, close_curr=100.5, low_lookback=[90,88,89])
    mock_data_processor_for_se.get_indicator_dataframe.return_value = mock_df
    
    signal = await signal_engine_v1.check_signal("ETHUSDT", "ETH_USDT")  # ETH_USDT has min_interval 0
    assert signal is not None
    assert signal.direction == TradeDirection.LONG
    assert signal.symbol == "ETHUSDT"
    assert signal.config_symbol == "ETH_USDT"
    assert signal.contract_type == "USDT_M"
    assert signal.entry_price == 100.5  # latest close
    assert signal.stop_loss_price == 88  # min of low_lookback
    # Risk = 100.5 - 88 = 12.5. TP = 100.5 + (12.5 * 2.0) = 100.5 + 25 = 125.5
    assert signal.take_profit_price == 125.5
    assert signal.strategy_name == "V1_SMA_Crossover"
    assert signal.signal_kline is not None
    assert signal.signal_kline.close == 100.5
    assert signal.signal_kline.timestamp == mock_df.index[-1]
    assert signal.details is not None
    assert signal.details["sma_short_at_signal"] == 101
    assert signal.details["sma_long_at_signal"] == 100
    assert signal.details["sma_short_previous"] == 99
    assert signal.details["sma_long_previous"] == 100
    assert signal.details["pivot_used_for_sl"] == 88

@pytest.mark.asyncio
async def test_se_short_signal_sma_crossover(signal_engine_v1, mock_data_processor_for_se):
    # prev: short >= long, curr: short < long
    mock_df = create_mock_df(sma_short_prev=101, sma_long_prev=100, sma_short_curr=99, sma_long_curr=100, close_curr=99.5, high_lookback=[110,112,111])
    mock_data_processor_for_se.get_indicator_dataframe.return_value = mock_df

    signal = await signal_engine_v1.check_signal("ETHUSDT", "ETH_USDT")
    assert signal is not None
    assert signal.direction == TradeDirection.SHORT
    assert signal.symbol == "ETHUSDT"
    assert signal.config_symbol == "ETH_USDT"
    assert signal.entry_price == 99.5
    assert signal.stop_loss_price == 112  # max of high_lookback
    # Risk = 112 - 99.5 = 12.5. TP = 99.5 - (12.5 * 2.0) = 99.5 - 25 = 74.5
    assert signal.take_profit_price == 74.5
    assert signal.signal_kline is not None
    assert signal.signal_kline.close == 99.5
    assert signal.details is not None
    assert signal.details["sma_short_at_signal"] == 99
    assert signal.details["sma_long_at_signal"] == 100
    assert signal.details["sma_short_previous"] == 101
    assert signal.details["sma_long_previous"] == 100
    assert signal.details["pivot_used_for_sl"] == 112

# 2. Test SL/TP Calculation
@pytest.mark.asyncio
async def test_se_sl_tp_calculation_long(signal_engine_v1, mock_data_processor_for_se):
    # Test a more complex case with specific pivot lows
    low_lookback = [90, 88, 89, 85, 87]  # The pivot low should be 85
    mock_df = create_mock_df(
        sma_short_prev=99, sma_long_prev=100, 
        sma_short_curr=101, sma_long_curr=100, 
        close_curr=100.5, 
        low_lookback=low_lookback
    )
    mock_data_processor_for_se.get_indicator_dataframe.return_value = mock_df
    
    signal = await signal_engine_v1.check_signal("ETHUSDT", "ETH_USDT")
    assert signal is not None
    assert signal.direction == TradeDirection.LONG
    assert signal.stop_loss_price == 85  # min of low_lookback
    # Risk = 100.5 - 85 = 15.5. TP = 100.5 + (15.5 * 2.0) = 100.5 + 31 = 131.5
    assert signal.take_profit_price == 131.5

@pytest.mark.asyncio
async def test_se_sl_tp_calculation_short(signal_engine_v1, mock_data_processor_for_se):
    # Test a more complex case with specific pivot highs
    high_lookback = [110, 112, 115, 111, 113]  # The pivot high should be 115
    mock_df = create_mock_df(
        sma_short_prev=101, sma_long_prev=100, 
        sma_short_curr=99, sma_long_curr=100, 
        close_curr=99.5, 
        high_lookback=high_lookback
    )
    mock_data_processor_for_se.get_indicator_dataframe.return_value = mock_df
    
    signal = await signal_engine_v1.check_signal("ETHUSDT", "ETH_USDT")
    assert signal is not None
    assert signal.direction == TradeDirection.SHORT
    assert signal.stop_loss_price == 115  # max of high_lookback
    # Risk = 115 - 99.5 = 15.5. TP = 99.5 - (15.5 * 2.0) = 99.5 - 31 = 68.5
    assert signal.take_profit_price == 68.5

@pytest.mark.asyncio
async def test_se_custom_tp_sl_ratio(signal_engine_v1, mock_data_processor_for_se):
    # Test TP calculation with a custom R:R ratio for SOL_USDT (3.5)
    mock_df = create_mock_df(
        sma_short_prev=99, sma_long_prev=100, 
        sma_short_curr=101, sma_long_curr=100, 
        close_curr=100.5, 
        low_lookback=[90, 88, 89]
    )
    mock_data_processor_for_se.get_indicator_dataframe.return_value = mock_df
    
    signal = await signal_engine_v1.check_signal("SOLUSDT", "SOL_USDT")
    assert signal is not None
    assert signal.direction == TradeDirection.LONG
    assert signal.stop_loss_price == 88
    # Risk = 100.5 - 88 = 12.5. TP = 100.5 + (12.5 * 3.5) = 100.5 + 43.75 = 144.25
    assert signal.take_profit_price == 144.25

@pytest.mark.asyncio
async def test_se_no_signal_if_insufficient_pivot_data(signal_engine_v1, mock_data_processor_for_se):
    # Create a DataFrame that's too small for proper pivot calculation (< 3 rows)
    small_df = create_limited_df(rows=2)
    mock_data_processor_for_se.get_indicator_dataframe.return_value = small_df
    
    signal = await signal_engine_v1.check_signal("ETHUSDT", "ETH_USDT")
    assert signal is None

@pytest.mark.asyncio
async def test_se_sl_tp_calculation_invalid_risk(signal_engine_v1, mock_data_processor_for_se):
    # SL is worse than entry for LONG (pivot low > entry price)
    mock_df_bad_sl_long = create_mock_df(
        sma_short_prev=99, sma_long_prev=100, 
        sma_short_curr=101, sma_long_curr=100, 
        close_curr=90, 
        low_lookback=[95, 96, 97]  # min low is 95, which is > entry price 90
    )
    mock_data_processor_for_se.get_indicator_dataframe.return_value = mock_df_bad_sl_long
    signal = await signal_engine_v1.check_signal("ETHUSDT", "ETH_USDT")
    assert signal is None

    # SL is worse than entry for SHORT (pivot high < entry price)
    mock_df_bad_sl_short = create_mock_df(
        sma_short_prev=101, sma_long_prev=100, 
        sma_short_curr=99, sma_long_curr=100, 
        close_curr=110, 
        high_lookback=[105, 106, 104]  # max high is 106, which is < entry price 110
    )
    mock_data_processor_for_se.get_indicator_dataframe.return_value = mock_df_bad_sl_short
    signal = await signal_engine_v1.check_signal("ETHUSDT", "ETH_USDT")
    assert signal is None

@pytest.mark.asyncio
async def test_se_long_signal_signal_kline_content(signal_engine_v1, mock_data_processor_for_se):
    # Test that signal_kline contains the correct data from the last DataFrame row
    mock_df = create_mock_df(
        sma_short_prev=99, sma_long_prev=100, 
        sma_short_curr=101, sma_long_curr=100, 
        close_curr=100.5
    )
    mock_data_processor_for_se.get_indicator_dataframe.return_value = mock_df
    
    signal = await signal_engine_v1.check_signal("ETHUSDT", "ETH_USDT")
    assert signal is not None
    assert signal.signal_kline is not None
    assert signal.signal_kline.timestamp == mock_df.index[-1]
    assert signal.signal_kline.open == mock_df.iloc[-1]["open"]
    assert signal.signal_kline.high == mock_df.iloc[-1]["high"]
    assert signal.signal_kline.low == mock_df.iloc[-1]["low"]
    assert signal.signal_kline.close == mock_df.iloc[-1]["close"]
    assert signal.signal_kline.volume == mock_df.iloc[-1]["volume"]
    assert signal.signal_kline.is_closed == mock_df.iloc[-1]["is_closed"]
    assert signal.signal_kline.symbol == "ETHUSDT"
    assert signal.signal_kline.interval == "1m"  # The default interval used by SignalEngineV1

# 3. Test Filters
@pytest.mark.asyncio
async def test_se_signal_interval_filter(signal_engine_v1, mock_data_processor_for_se):
    # BTC_USDT has min_interval_minutes = 15
    mock_df = create_mock_df(
        sma_short_prev=99, sma_long_prev=100, 
        sma_short_curr=101, sma_long_curr=100, 
        close_curr=100.5
    )
    mock_data_processor_for_se.get_indicator_dataframe.return_value = mock_df

    # First signal should pass
    signal1 = await signal_engine_v1.check_signal("BTCUSDT", "BTC_USDT")
    assert signal1 is not None
    assert signal_engine_v1.last_signal_time["BTCUSDT"] > 0

    # Second signal immediately after should be filtered
    signal2 = await signal_engine_v1.check_signal("BTCUSDT", "BTC_USDT")
    assert signal2 is None

    # Simulate time passing (less than interval)
    signal_engine_v1.last_signal_time["BTCUSDT"] = time.time() - (10 * 60)  # 10 minutes ago
    signal3 = await signal_engine_v1.check_signal("BTCUSDT", "BTC_USDT")
    assert signal3 is None 

    # Simulate time passing (more than interval)
    signal_engine_v1.last_signal_time["BTCUSDT"] = time.time() - (20 * 60)  # 20 minutes ago
    signal4 = await signal_engine_v1.check_signal("BTCUSDT", "BTC_USDT")
    assert signal4 is not None

@pytest.mark.asyncio
async def test_se_signal_interval_is_pair_specific(signal_engine_v1, mock_data_processor_for_se):
    # Setup: BTC_USDT has interval=15, ETH_USDT has interval=0
    mock_df = create_mock_df(
        sma_short_prev=99, sma_long_prev=100, 
        sma_short_curr=101, sma_long_curr=100, 
        close_curr=100.5
    )
    mock_data_processor_for_se.get_indicator_dataframe.return_value = mock_df
    
    # Generate signals for both pairs
    btc_signal = await signal_engine_v1.check_signal("BTCUSDT", "BTC_USDT")
    eth_signal = await signal_engine_v1.check_signal("ETHUSDT", "ETH_USDT")
    
    # Both should work the first time
    assert btc_signal is not None
    assert eth_signal is not None
    
    # Try immediate second signals
    btc_signal2 = await signal_engine_v1.check_signal("BTCUSDT", "BTC_USDT")
    eth_signal2 = await signal_engine_v1.check_signal("ETHUSDT", "ETH_USDT")
    
    # BTC should be filtered, ETH should still generate (interval=0)
    assert btc_signal2 is None
    assert eth_signal2 is not None

# 4. Test Helper Methods
@pytest.mark.asyncio
async def test_se_get_pair_specific_config(signal_engine_v1):
    # Test getting config for BTC_USDT (uses global values)
    btc_config = signal_engine_v1._get_pair_specific_config("BTC_USDT")
    assert btc_config["sma_short_period"] == 3
    assert btc_config["sma_long_period"] == 5
    assert btc_config["min_signal_interval_minutes"] == 15
    assert btc_config["tp_sl_ratio"] == 2.0
    assert btc_config["contract_type"] == "USDT_M"
    
    # Test getting config for ETH_USDT (has custom min_signal_interval_minutes)
    eth_config = signal_engine_v1._get_pair_specific_config("ETH_USDT")
    assert eth_config["sma_short_period"] == 3
    assert eth_config["sma_long_period"] == 5
    assert eth_config["min_signal_interval_minutes"] == 0  # Overridden
    assert eth_config["tp_sl_ratio"] == 2.0
    assert eth_config["contract_type"] == "USDT_M"
    
    # Test getting config for SOL_USDT (has custom tp_sl_ratio)
    sol_config = signal_engine_v1._get_pair_specific_config("SOL_USDT")
    assert sol_config["sma_short_period"] == 3
    assert sol_config["sma_long_period"] == 5
    assert sol_config["min_signal_interval_minutes"] == 15
    assert sol_config["tp_sl_ratio"] == 3.5  # Overridden
    assert sol_config["contract_type"] == "USDT_M"
    
    # Test getting config for unknown pair (should use global values)
    unknown_config = signal_engine_v1._get_pair_specific_config("XRP_USDT")
    assert unknown_config["sma_short_period"] == 3
    assert unknown_config["sma_long_period"] == 5
    assert unknown_config["min_signal_interval_minutes"] == 15
    assert unknown_config["tp_sl_ratio"] == 2.0
    assert unknown_config["contract_type"] == "USDT_M"

@pytest.mark.asyncio
async def test_se_find_recent_pivot_logic(signal_engine_v1):
    # Test _find_recent_pivot directly (it's a protected method, but crucial)
    data = {
        "timestamp": range(10), 
        "low": [10, 8, 9, 7, 10, 6, 8, 9, 7, 11],
        "high": [20, 22, 21, 23, 20, 24, 22, 21, 23, 19],
        "is_closed": [True]*10
    }
    df = pd.DataFrame(data).set_index("timestamp")
    
    # Test for LONG direction with different lookbacks
    # For lookback=5, it should look at indices 4,5,6,7,8 (lows: 10, 6, 8, 9, 7). Min is 6.
    pivot_l_5 = signal_engine_v1._find_recent_pivot(df, lookback=5, direction=TradeDirection.LONG)
    assert pivot_l_5 == 6
    
    # For lookback=3, it should look at indices 6,7,8 (lows: 8, 9, 7). Min is 7.
    pivot_l_3 = signal_engine_v1._find_recent_pivot(df, lookback=3, direction=TradeDirection.LONG)
    assert pivot_l_3 == 7
    
    # Test for SHORT direction with different lookbacks
    # For lookback=5, it should look at indices 4,5,6,7,8 (highs: 20, 24, 22, 21, 23). Max is 24.
    pivot_h_5 = signal_engine_v1._find_recent_pivot(df, lookback=5, direction=TradeDirection.SHORT)
    assert pivot_h_5 == 24
    
    # For lookback=3, it should look at indices 6,7,8 (highs: 22, 21, 23). Max is 23.
    pivot_h_3 = signal_engine_v1._find_recent_pivot(df, lookback=3, direction=TradeDirection.SHORT)
    assert pivot_h_3 == 23
    
    # Test with insufficient data
    assert signal_engine_v1._find_recent_pivot(df[:2], lookback=5, direction=TradeDirection.LONG) is None
    
    # Test with exactly 3 rows
    # According to the implementation in SignalEngineV1._find_recent_pivot,
    # we need at least 3 rows, but they must be closed candles *before* the signal candle
    # When we pass a 3-row DataFrame, there are actually only 2 rows considered for pivot calculation
    # (the signal candle itself is excluded with iloc[-lookback-1:-1])
    three_row_df = df[:3]
    pivot_l_min = signal_engine_v1._find_recent_pivot(three_row_df, lookback=5, direction=TradeDirection.LONG)
    # Since we only have 2 usable rows, which is less than the minimum 3 required,
    # the function should return None, not the min of [10, 8]
    assert pivot_l_min is None
    
    # Test with 4 rows (which gives 3 usable rows - the minimum required)
    four_row_df = df[:4]
    pivot_l_four = signal_engine_v1._find_recent_pivot(four_row_df, lookback=5, direction=TradeDirection.LONG)
    # Now we have 3 usable rows with lows [10, 8, 9], so min is 8
    assert pivot_l_four == 8
    
    # Test with flat values
    flat_data = {
        "timestamp": range(5),
        "low": [10, 10, 10, 10, 10],
        "high": [20, 20, 20, 20, 20],
        "is_closed": [True]*5
    }
    flat_df = pd.DataFrame(flat_data).set_index("timestamp")
    pivot_l_flat = signal_engine_v1._find_recent_pivot(flat_df, lookback=3, direction=TradeDirection.LONG)
    assert pivot_l_flat == 10
    pivot_h_flat = signal_engine_v1._find_recent_pivot(flat_df, lookback=3, direction=TradeDirection.SHORT)
    assert pivot_h_flat == 20




================================================
FILE: .cursor/rules/projectrules.mdc
================================================
---
description: 
globs: 
alwaysApply: true
---
---
title: Binance Futures Trading Bot Rules
description: Guidelines for AI assistance with this trading bot project
---

# Project Overview
This is a Binance Futures Trading Bot that implements automated trading strategies for cryptocurrency futures markets. The bot connects to Binance API (both USDT-M and Coin-M perpetual futures), processes market data, generates trading signals based on technical indicators, and executes trades according to predefined risk management rules.

# Code Style
- Use Python 3.11+ compatible code
- Follow PEP 8 style guidelines
- Use type hints for all function parameters and return values
- Prefer async/await patterns for I/O operations
- Use descriptive variable and function names
- Add docstrings to all classes and public methods

# Architecture Guidelines
- Maintain clear separation between components (connectors, data processing, signal generation, order management)
- Use dependency injection for better testability
- Implement proper error handling and logging
- Ensure all external API calls have appropriate error handling and retry mechanisms
- Use configuration files for all adjustable parameters

# Trading Strategy Implementation
- The primary V1 strategy uses SMA 21 crossing SMA 200 on various timeframes
- Stop loss should be based on recent pivot points
- Take profit should be calculated using risk-reward ratio from config
- Implement buffer periods to avoid false signals
- Support both USDT-M and Coin-M contract types

# Security Considerations
- Never hardcode API keys or secrets
- Use environment variables or secure config files
- Implement proper error handling for API responses
- Validate all user inputs and configuration parameters
- Log sensitive operations but never log credentials

# Testing Requirements
- Write unit tests for all core components
- Mock external API calls in tests
- Include integration tests for critical workflows
- Test error handling and edge cases

# Documentation Standards
- Maintain comprehensive README with setup and usage instructions
- Document all configuration options
- Include architecture diagrams where helpful
- Provide troubleshooting guides for common issues

# Performance Considerations
- Optimize memory usage for long-running processes
- Implement connection pooling for API requests
- Use efficient data structures for time series data
- Consider resource usage when processing large datasets


